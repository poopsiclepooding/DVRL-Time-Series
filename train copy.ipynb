{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import math, copy, time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "%matplotlib inline\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import data_preprocess\n",
    "import generate_dataset\n",
    "import lstm_encoder_decoder\n",
    "import plotting \n",
    "import data_valuator\n",
    "import funtions_for_dvrl\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "\n",
    "\n",
    "#import plotting\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ DATASET HYPER PARAMETERS #################\n",
    "train_val_split = 0.9\n",
    "lookback = 30\n",
    "lookahead = 3\n",
    "step = 1\n",
    "batch_size = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (16208, 17), Data Type : object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, time_feature = data_preprocess.get_dataset()\n",
    "print(f\"Shape : {dataset.shape}, Data Type : {dataset.dtype}\")\n",
    "ith = 11                                                              # Decide Which Feature To Train On\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.plot(dataset[:,ith])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Of New Avg Dataset:  383\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[:, 0] = data_preprocess.time_feature_to_time(dataset[:,0])\n",
    "prev_batch = '01'\n",
    "new_data = []\n",
    "j = 0\n",
    "sums = 0\n",
    "for i, batch in enumerate(dataset[:,0]):\n",
    "    if batch == prev_batch:\n",
    "        sums += dataset[i,11]\n",
    "        j += 1\n",
    "        prev_batch = batch\n",
    "    elif batch != prev_batch:\n",
    "        new_data.append(sums/j)\n",
    "        sums = 0\n",
    "        j = 0\n",
    "        prev_batch = batch\n",
    "\n",
    "print(\"Length Of New Avg Dataset: \", len(new_data))\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(new_data)\n",
    "plt.show\n",
    "\n",
    "new_data_np = np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y -> Actual Dataset, t -> Timesteps for Plotting\n",
    "t_baseline, y_baseline = generate_dataset.synthetic_data(Nt=383)\n",
    "#new_data_np = data_preprocess.scale_data(new_data_np)\n",
    "t_train_baseline, data_train_baseline, t_val_baseline, data_val_baseline = generate_dataset.train_test_split(t_baseline, new_data_np[35:], split = train_val_split)\n",
    "\n",
    "# plot time series \n",
    "plt.figure(figsize = (9, 3))\n",
    "plt.plot(t_train_baseline, data_train_baseline, color = 'k', linewidth = 2)\n",
    "plt.xlim([t_train_baseline[0], t_train_baseline[-1]])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Data')\n",
    "plt.title('Data Time Series')\n",
    "plt.savefig('plots/synthetic_time_series.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset X Size : (280, 30, 1)\n",
      "Train Dataset Y Size : (280, 3, 1)\n",
      "Validation Dataset X Size : (2, 30, 1)\n",
      "Validation Dataset Y Size : (2, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_multi_baseline, y_train_multi_baseline = funtions_for_dvrl.multivariate_data(data_train_baseline, data_train_baseline, 0,\n",
    "                                                 None, lookback,\n",
    "                                                 lookahead, step)\n",
    "x_val_multi_baseline, y_val_multi_baseline = funtions_for_dvrl.multivariate_data(data_val_baseline, data_val_baseline,\n",
    "                                             0, None, lookback,\n",
    "                                             lookahead, step)\n",
    "\n",
    "print (\n",
    "       'Train Dataset X Size : {}'.format(x_train_multi_baseline.shape),\n",
    "       'Train Dataset Y Size : {}'.format(y_train_multi_baseline.shape),\n",
    "       'Validation Dataset X Size : {}'.format(x_val_multi_baseline.shape),\n",
    "       'Validation Dataset Y Size : {}'.format(y_val_multi_baseline.shape),\n",
    "       sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape : torch.Size([280, 30])\n",
      "Y Train Shape : torch.Size([280, 3])\n",
      "X Valid Shape : torch.Size([30, 2, 1])\n",
      "Y Valid Shape : torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#Extracting a single column for univariante time series\n",
    "x_train_baseline = torch.from_numpy(x_train_multi_baseline.squeeze(-1))\n",
    "y_train_baseline = torch.from_numpy(y_train_multi_baseline.squeeze(-1))\n",
    "x_valid_baseline = torch.from_numpy(x_val_multi_baseline)\n",
    "y_valid_baseline = torch.from_numpy(y_val_multi_baseline)\n",
    "\n",
    "x_valid_baseline = x_valid_baseline.transpose(1,0).float()\n",
    "y_valid_baseline = y_valid_baseline.transpose(1,0).float()\n",
    "print(f\"X Train Shape : {x_train_baseline.shape}\")\n",
    "print(f\"Y Train Shape : {y_train_baseline.shape}\")\n",
    "print(f\"X Valid Shape : {x_valid_baseline.shape}\")\n",
    "print(f\"Y Valid Shape : {y_valid_baseline.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_baseline = x_train_baseline.to(device)\n",
    "y_train_baseline = y_train_baseline.to(device)\n",
    "x_valid_baseline = x_valid_baseline.to(device)\n",
    "y_valid_baseline = y_valid_baseline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train_corrupt = data_train_baseline.copy()\n",
    "data_train_corrupt[150:155] += 20\n",
    "# data_train_corrupt[50] += 5\n",
    "plt.plot(data_train_corrupt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices : [ 64 155 151 215  56 103  84 195  95 153  32 245  74 140 126 267   8 270\n",
      "  40  95 108 190 264  82  98 274 113 234 214 118 130 246 230  41   6 254\n",
      "  53  83 183  41  66  40 133 253 167  94 168 267 185 119]\n",
      "Train Dataset X Size : (280, 30, 1)\n",
      "Train Dataset Y Size : (280, 3, 1)\n",
      "Validation Dataset X Size : (50, 30, 1)\n",
      "Validation Dataset Y Size : (50, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_multi, y_train_multi = funtions_for_dvrl.multivariate_data(data_train_corrupt, data_train_corrupt, 0,\n",
    "                                                 None, lookback,\n",
    "                                                 lookahead, step)\n",
    "index_val = np.random.randint(0, x_train_multi.shape[0], size=50)\n",
    "print(f\"Indices : {index_val}\")\n",
    "x_val_multi, y_val_multi = x_train_multi_baseline[index_val, :,:], y_train_multi_baseline[index_val, :, :]\n",
    "\n",
    "print (\n",
    "       'Train Dataset X Size : {}'.format(x_train_multi.shape),\n",
    "       'Train Dataset Y Size : {}'.format(y_train_multi.shape),\n",
    "       'Validation Dataset X Size : {}'.format(x_val_multi.shape),\n",
    "       'Validation Dataset Y Size : {}'.format(y_val_multi.shape),\n",
    "       sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape : torch.Size([280, 30])\n",
      "Y Train Shape : torch.Size([280, 3])\n",
      "X Valid Shape : torch.Size([30, 50, 1])\n",
      "Y Valid Shape : torch.Size([3, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "#Extracting a single column for univariante time series\n",
    "x_train_corrupt = torch.from_numpy(x_train_multi.squeeze(-1))\n",
    "y_train_corrupt = torch.from_numpy(y_train_multi.squeeze(-1))\n",
    "x_valid_corrupt = torch.from_numpy(x_val_multi)\n",
    "y_valid_corrupt = torch.from_numpy(y_val_multi)\n",
    "\n",
    "\n",
    "x_valid_corrupt = x_valid_corrupt.transpose(1,0).float()\n",
    "y_valid_corrupt = y_valid_corrupt.transpose(1,0).float()\n",
    "print(f\"X Train Shape : {x_train_corrupt.shape}\")\n",
    "print(f\"Y Train Shape : {y_train_corrupt.shape}\")\n",
    "print(f\"X Valid Shape : {x_valid_corrupt.shape}\")\n",
    "print(f\"Y Valid Shape : {y_valid_corrupt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_corrupt.to(device)\n",
    "y_train = y_train_corrupt.to(device)\n",
    "x_valid = x_valid_corrupt.to(device)\n",
    "y_valid = y_valid_corrupt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DVRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(lookback = lookback, lookahead = lookahead, datavaluator_hidden = 256):\n",
    "    \"Helper: Construct a model1 from hyperparameters.\"\n",
    "\n",
    "    model_1 = data_valuator.Data_Valuator_MLP(lookback+lookahead, datavaluator_hidden)\n",
    "\n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = make_model()\n",
    "model_1.to(device)\n",
    "moving_avg_loss = torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
       "============================================================================================================================================\n",
       "Data_Valuator_MLP                        [45, 33]                  [45, 1]                   --                        True\n",
       "Sequential: 1-1                        [45, 33]                  [45, 1]                   --                        True\n",
       "    Linear: 2-1                       [45, 33]                  [45, 256]                 8,704                     True\n",
       "    LeakyReLU: 2-2                    [45, 256]                 [45, 256]                 --                        --\n",
       "    Linear: 2-3                       [45, 256]                 [45, 128]                 32,896                    True\n",
       "    LeakyReLU: 2-4                    [45, 128]                 [45, 128]                 --                        --\n",
       "    Linear: 2-5                       [45, 128]                 [45, 64]                  8,256                     True\n",
       "    LeakyReLU: 2-6                    [45, 64]                  [45, 64]                  --                        --\n",
       "    Linear: 2-7                       [45, 64]                  [45, 32]                  2,080                     True\n",
       "    LeakyReLU: 2-8                    [45, 32]                  [45, 32]                  --                        --\n",
       "    Linear: 2-9                       [45, 32]                  [45, 16]                  528                       True\n",
       "    LeakyReLU: 2-10                   [45, 16]                  [45, 16]                  --                        --\n",
       "    Linear: 2-11                      [45, 16]                  [45, 1]                   17                        True\n",
       "Sigmoid: 1-2                           [45, 1]                   [45, 1]                   --                        --\n",
       "============================================================================================================================================\n",
       "Total params: 52,481\n",
       "Trainable params: 52,481\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.36\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.18\n",
       "Params size (MB): 0.21\n",
       "Estimated Total Size (MB): 0.40\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model_1, [(batch_size, lookback + lookahead)], dtypes=[torch.float64, torch.float64], col_names=[\"input_size\", \"output_size\", \n",
    "                                                                                                 \"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model_1.parameters():\n",
    "    p.requires_grad = True #False\n",
    "\n",
    "\n",
    "mov_avg_plot = []\n",
    "reward_plot = []\n",
    "val_loss_plot = []\n",
    "iteration = []\n",
    "mean_of_hidden = []\n",
    "mean_of_prob = []\n",
    "train_loss_plot = []\n",
    "lstm_predict_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP MODEL\n",
    "\n",
    "reward = 0\n",
    "model_4 = lstm_encoder_decoder.lstm_seq2seq(input_size = 1, hidden_size = 128)\n",
    "learning_rate_for_dve = 0.00001\n",
    "learning_rate_for_lstm = 0.0001\n",
    "time_window_size = 15\n",
    "reward = -10\n",
    "num_of_epochs = 100 \n",
    "iters = 0\n",
    "threshold = 0.9\n",
    "epsilon = 1e-8\n",
    "optim_for_dve = torch.optim.Adam(model_1.parameters(), lr=learning_rate_for_dve)\n",
    "optim_for_lstm = optim.Adam(model_4.parameters(), lr = learning_rate_for_lstm)\n",
    "criterion_for_lstm = funtions_for_dvrl.RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################\n",
      "Epoch = 0\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 24.860960006713867, dv_loss = tensor([191.6850], device='cuda:0', grad_fn=<AddBackward0>), reward = -22.860960006713867, iters = 1\n",
      "Epoch = 0\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 22.923561096191406, dv_loss = tensor([130.0191], device='cuda:0', grad_fn=<AddBackward0>), reward = -20.923561096191406, iters = 51\n",
      "Epoch = 0\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 19.34028434753418, dv_loss = tensor([127.6894], device='cuda:0', grad_fn=<AddBackward0>), reward = -17.34028434753418, iters = 101\n",
      "Epoch = 0\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 17.78485870361328, dv_loss = tensor([98.0224], device='cuda:0', grad_fn=<AddBackward0>), reward = -15.784858703613281, iters = 151\n",
      "Epoch = 0\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 16.74205780029297, dv_loss = tensor([125.1642], device='cuda:0', grad_fn=<AddBackward0>), reward = -14.742057800292969, iters = 201\n",
      "Epoch = 0\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 16.040239334106445, dv_loss = tensor([116.1939], device='cuda:0', grad_fn=<AddBackward0>), reward = -14.040239334106445, iters = 251\n",
      "###################################\n",
      "Epoch = 1\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 15.77746868133545, dv_loss = tensor([86.5098], device='cuda:0', grad_fn=<AddBackward0>), reward = -13.77746868133545, iters = 271\n",
      "Epoch = 1\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 15.12332820892334, dv_loss = tensor([136.0741], device='cuda:0', grad_fn=<AddBackward0>), reward = -13.12332820892334, iters = 321\n",
      "Epoch = 1\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 14.443901062011719, dv_loss = tensor([78.6709], device='cuda:0', grad_fn=<AddBackward0>), reward = -12.443901062011719, iters = 371\n",
      "Epoch = 1\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 13.798111915588379, dv_loss = tensor([85.4639], device='cuda:0', grad_fn=<AddBackward0>), reward = -11.798111915588379, iters = 421\n",
      "Epoch = 1\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 13.182415962219238, dv_loss = tensor([94.7093], device='cuda:0', grad_fn=<AddBackward0>), reward = -11.182415962219238, iters = 471\n",
      "Epoch = 1\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 12.701874732971191, dv_loss = tensor([88.5448], device='cuda:0', grad_fn=<AddBackward0>), reward = -10.701874732971191, iters = 521\n",
      "###################################\n",
      "Epoch = 2\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 12.51236343383789, dv_loss = tensor([65.9178], device='cuda:0', grad_fn=<AddBackward0>), reward = -10.51236343383789, iters = 541\n",
      "Epoch = 2\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 12.038774490356445, dv_loss = tensor([83.2889], device='cuda:0', grad_fn=<AddBackward0>), reward = -10.038774490356445, iters = 591\n",
      "Epoch = 2\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 11.510257720947266, dv_loss = tensor([59.8501], device='cuda:0', grad_fn=<AddBackward0>), reward = -9.510257720947266, iters = 641\n",
      "Epoch = 2\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 10.982550621032715, dv_loss = tensor([55.6756], device='cuda:0', grad_fn=<AddBackward0>), reward = -8.982550621032715, iters = 691\n",
      "Epoch = 2\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 10.475600242614746, dv_loss = tensor([98.9382], device='cuda:0', grad_fn=<AddBackward0>), reward = -8.475600242614746, iters = 741\n",
      "Epoch = 2\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 10.100357055664062, dv_loss = tensor([67.0346], device='cuda:0', grad_fn=<AddBackward0>), reward = -8.100357055664062, iters = 791\n",
      "###################################\n",
      "Epoch = 3\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 9.951266288757324, dv_loss = tensor([66.2605], device='cuda:0', grad_fn=<AddBackward0>), reward = -7.951266288757324, iters = 811\n",
      "Epoch = 3\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 9.571378707885742, dv_loss = tensor([86.2993], device='cuda:0', grad_fn=<AddBackward0>), reward = -7.571378707885742, iters = 861\n",
      "Epoch = 3\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 9.144194602966309, dv_loss = tensor([52.5630], device='cuda:0', grad_fn=<AddBackward0>), reward = -7.144194602966309, iters = 911\n",
      "Epoch = 3\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 8.711965560913086, dv_loss = tensor([62.4464], device='cuda:0', grad_fn=<AddBackward0>), reward = -6.711965560913086, iters = 961\n",
      "Epoch = 3\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 8.29499340057373, dv_loss = tensor([50.8749], device='cuda:0', grad_fn=<AddBackward0>), reward = -5.995800018310547, iters = 1011\n",
      "Epoch = 3\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 8.012855529785156, dv_loss = tensor([47.6314], device='cuda:0', grad_fn=<AddBackward0>), reward = -4.602831840515137, iters = 1061\n",
      "###################################\n",
      "Epoch = 4\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 7.906447887420654, dv_loss = tensor([47.8587], device='cuda:0', grad_fn=<AddBackward0>), reward = -4.173224449157715, iters = 1081\n",
      "Epoch = 4\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 7.622400283813477, dv_loss = tensor([30.6298], device='cuda:0', grad_fn=<AddBackward0>), reward = -3.2866973876953125, iters = 1131\n",
      "Epoch = 4\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 7.283183574676514, dv_loss = tensor([18.6593], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.5341620445251465, iters = 1181\n",
      "Epoch = 4\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.931138038635254, dv_loss = tensor([15.8223], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.914684772491455, iters = 1231\n",
      "Epoch = 4\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.60004997253418, dv_loss = tensor([10.3924], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.3982124328613281, iters = 1281\n",
      "Epoch = 4\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.411416053771973, dv_loss = tensor([6.7711], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.0901541709899902, iters = 1331\n",
      "###################################\n",
      "Epoch = 5\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.343047618865967, dv_loss = tensor([8.2216], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.9832067489624023, iters = 1351\n",
      "Epoch = 5\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.1534600257873535, dv_loss = tensor([5.9894], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.7222428321838379, iters = 1401\n",
      "Epoch = 5\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.899049758911133, dv_loss = tensor([1.7637], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.41909313201904297, iters = 1451\n",
      "Epoch = 5\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.632316589355469, dv_loss = tensor([0.6987], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.13519716262817383, iters = 1501\n",
      "Epoch = 5\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.39071798324585, dv_loss = tensor([0.4127], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.10987710952758789, iters = 1551\n",
      "Epoch = 5\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.284237384796143, dv_loss = tensor([0.7881], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.20424699783325195, iters = 1601\n",
      "###################################\n",
      "Epoch = 6\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.246488094329834, dv_loss = tensor([0.9038], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2367863655090332, iters = 1621\n",
      "Epoch = 6\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.133174896240234, dv_loss = tensor([1.4386], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3317146301269531, iters = 1671\n",
      "Epoch = 6\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.963589191436768, dv_loss = tensor([1.5961], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.48082447052001953, iters = 1721\n",
      "Epoch = 6\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.799546718597412, dv_loss = tensor([2.3741], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6138916015625, iters = 1771\n",
      "Epoch = 6\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.643131732940674, dv_loss = tensor([2.7759], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7381339073181152, iters = 1821\n",
      "Epoch = 6\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.59735631942749, dv_loss = tensor([2.8877], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7471857070922852, iters = 1871\n",
      "###################################\n",
      "Epoch = 7\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.581268787384033, dv_loss = tensor([4.3160], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7495956420898438, iters = 1891\n",
      "Epoch = 7\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.527199745178223, dv_loss = tensor([2.2204], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7686600685119629, iters = 1941\n",
      "Epoch = 7\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.423673152923584, dv_loss = tensor([2.7740], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8391842842102051, iters = 1991\n",
      "Epoch = 7\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.3242387771606445, dv_loss = tensor([1.7389], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9015913009643555, iters = 2041\n",
      "Epoch = 7\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.232131481170654, dv_loss = tensor([3.1483], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9580988883972168, iters = 2091\n",
      "Epoch = 7\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.226042747497559, dv_loss = tensor([3.5845], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9276609420776367, iters = 2141\n",
      "###################################\n",
      "Epoch = 8\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.226109981536865, dv_loss = tensor([3.4843], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9140667915344238, iters = 2161\n",
      "Epoch = 8\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.208535671234131, dv_loss = tensor([3.0318], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8983573913574219, iters = 2211\n",
      "Epoch = 8\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.150391578674316, dv_loss = tensor([3.9540], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9257111549377441, iters = 2261\n",
      "Epoch = 8\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.09004545211792, dv_loss = tensor([5.0669], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9536867141723633, iters = 2311\n",
      "Epoch = 8\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.040036678314209, dv_loss = tensor([5.0251], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9729785919189453, iters = 2361\n",
      "Epoch = 8\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.049217224121094, dv_loss = tensor([3.6081], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9333677291870117, iters = 2411\n",
      "###################################\n",
      "Epoch = 9\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.053994178771973, dv_loss = tensor([1.7600], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9172425270080566, iters = 2431\n",
      "Epoch = 9\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.055522918701172, dv_loss = tensor([2.9969], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8881216049194336, iters = 2481\n",
      "Epoch = 9\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.023374557495117, dv_loss = tensor([3.8108], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8947362899780273, iters = 2531\n",
      "Epoch = 9\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.994819164276123, dv_loss = tensor([3.0321], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.897395133972168, iters = 2581\n",
      "Epoch = 9\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9718432426452637, dv_loss = tensor([3.3596], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8958845138549805, iters = 2631\n",
      "Epoch = 9\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.98193621635437, dv_loss = tensor([2.0826], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8619439601898193, iters = 2681\n",
      "###################################\n",
      "Epoch = 10\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9873805046081543, dv_loss = tensor([3.2407], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.847496509552002, iters = 2701\n",
      "Epoch = 10\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9939799308776855, dv_loss = tensor([3.9480], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8190789222717285, iters = 2751\n",
      "Epoch = 10\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9776082038879395, dv_loss = tensor([2.6883], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.815150260925293, iters = 2801\n",
      "Epoch = 10\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.964146375656128, dv_loss = tensor([2.3436], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8083984851837158, iters = 2851\n",
      "Epoch = 10\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.954634189605713, dv_loss = tensor([3.7567], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.798731803894043, iters = 2901\n",
      "Epoch = 10\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9604737758636475, dv_loss = tensor([2.9929], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7743322849273682, iters = 2951\n",
      "###################################\n",
      "Epoch = 11\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9652559757232666, dv_loss = tensor([2.5462], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7624623775482178, iters = 2971\n",
      "Epoch = 11\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.971628189086914, dv_loss = tensor([2.4937], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7388877868652344, iters = 3021\n",
      "Epoch = 11\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.961928367614746, dv_loss = tensor([3.1127], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7324695587158203, iters = 3071\n",
      "Epoch = 11\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9542856216430664, dv_loss = tensor([2.7946], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7241754531860352, iters = 3121\n",
      "Epoch = 11\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9518067836761475, dv_loss = tensor([3.0122], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7114288806915283, iters = 3171\n",
      "Epoch = 11\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.953106641769409, dv_loss = tensor([2.6840], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6954538822174072, iters = 3221\n",
      "###################################\n",
      "Epoch = 12\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9563655853271484, dv_loss = tensor([3.2801], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.686525821685791, iters = 3241\n",
      "Epoch = 12\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9626147747039795, dv_loss = tensor([2.2450], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.666489839553833, iters = 3291\n",
      "Epoch = 12\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.956313371658325, dv_loss = tensor([1.8804], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6598246097564697, iters = 3341\n",
      "Epoch = 12\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9521548748016357, dv_loss = tensor([2.2068], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6511843204498291, iters = 3391\n",
      "Epoch = 12\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9529812335968018, dv_loss = tensor([3.2956], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6380565166473389, iters = 3441\n",
      "Epoch = 12\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.951084613800049, dv_loss = tensor([1.5124], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6281099319458008, iters = 3491\n",
      "###################################\n",
      "Epoch = 13\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9528818130493164, dv_loss = tensor([2.6851], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6216964721679688, iters = 3511\n",
      "Epoch = 13\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.958740234375, dv_loss = tensor([2.0401], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.604578971862793, iters = 3561\n",
      "Epoch = 13\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.953122854232788, dv_loss = tensor([1.9976], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5995452404022217, iters = 3611\n",
      "Epoch = 13\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9504261016845703, dv_loss = tensor([2.0035], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5917544364929199, iters = 3661\n",
      "Epoch = 13\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9545726776123047, dv_loss = tensor([2.7162], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5774660110473633, iters = 3711\n",
      "Epoch = 13\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.950063705444336, dv_loss = tensor([3.0417], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5722241401672363, iters = 3761\n",
      "###################################\n",
      "Epoch = 14\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9508302211761475, dv_loss = tensor([1.6223], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5676267147064209, iters = 3781\n",
      "Epoch = 14\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9542946815490723, dv_loss = tensor([2.4074], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5547943115234375, iters = 3831\n",
      "Epoch = 14\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.961531400680542, dv_loss = tensor([1.5311], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5397741794586182, iters = 3881\n",
      "Epoch = 14\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9512462615966797, dv_loss = tensor([1.3092], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5413122177124023, iters = 3931\n",
      "Epoch = 14\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.954350233078003, dv_loss = tensor([2.4865], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5297343730926514, iters = 3981\n",
      "Epoch = 14\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.951824188232422, dv_loss = tensor([1.2670], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5240688323974609, iters = 4031\n",
      "###################################\n",
      "Epoch = 15\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.952688217163086, dv_loss = tensor([2.2386], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.519989013671875, iters = 4051\n",
      "Epoch = 15\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9580249786376953, dv_loss = tensor([1.9537], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.506772518157959, iters = 4101\n",
      "Epoch = 15\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9506354331970215, dv_loss = tensor([2.3951], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5066771507263184, iters = 4151\n",
      "Epoch = 15\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.948995351791382, dv_loss = tensor([1.9377], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5008785724639893, iters = 4201\n",
      "Epoch = 15\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9514102935791016, dv_loss = tensor([2.0787], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.49121952056884766, iters = 4251\n",
      "Epoch = 15\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9465348720550537, dv_loss = tensor([2.5974], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.48908543586730957, iters = 4301\n",
      "###################################\n",
      "Epoch = 16\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9464478492736816, dv_loss = tensor([1.1652], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.48639822006225586, iters = 4321\n",
      "Epoch = 16\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9504878520965576, dv_loss = tensor([1.3730], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4755442142486572, iters = 4371\n",
      "Epoch = 16\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.949000358581543, dv_loss = tensor([1.7872], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.47075366973876953, iters = 4421\n",
      "Epoch = 16\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9487390518188477, dv_loss = tensor([1.5679], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.46463489532470703, iters = 4471\n",
      "Epoch = 16\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.953616142272949, dv_loss = tensor([1.7052], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.453524112701416, iters = 4521\n",
      "Epoch = 16\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9435505867004395, dv_loss = tensor([2.2111], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4575643539428711, iters = 4571\n",
      "###################################\n",
      "Epoch = 17\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9431986808776855, dv_loss = tensor([1.0881], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.45550107955932617, iters = 4591\n",
      "Epoch = 17\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9427812099456787, dv_loss = tensor([1.7356], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.44996142387390137, iters = 4641\n",
      "Epoch = 17\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.94608736038208, dv_loss = tensor([1.6745], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.44095706939697266, iters = 4691\n",
      "Epoch = 17\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.943908929824829, dv_loss = tensor([1.6898], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.437572717666626, iters = 4741\n",
      "Epoch = 17\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9478189945220947, dv_loss = tensor([2.2124], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4281599521636963, iters = 4791\n",
      "Epoch = 17\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9093806743621826, dv_loss = tensor([0.8903], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.46123194694519043, iters = 4841\n",
      "###################################\n",
      "Epoch = 18\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.8990187644958496, dv_loss = tensor([0.9008], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.46921682357788086, iters = 4861\n",
      "Epoch = 18\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.026484489440918, dv_loss = tensor([0.8098], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3363800048828125, iters = 4911\n",
      "Epoch = 18\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.948147773742676, dv_loss = tensor([1.5783], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4149308204650879, iters = 4961\n",
      "Epoch = 18\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.92971134185791, dv_loss = tensor([2.0683], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.42832088470458984, iters = 5011\n",
      "Epoch = 18\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9223287105560303, dv_loss = tensor([1.4161], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4306504726409912, iters = 5061\n",
      "Epoch = 18\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9056711196899414, dv_loss = tensor([1.7066], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4422459602355957, iters = 5111\n",
      "###################################\n",
      "Epoch = 19\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.894171714782715, dv_loss = tensor([2.3787], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4517207145690918, iters = 5131\n",
      "Epoch = 19\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.8906655311584473, dv_loss = tensor([1.5177], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4500846862792969, iters = 5181\n",
      "Epoch = 19\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.92508602142334, dv_loss = tensor([1.3598], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4110274314880371, iters = 5231\n",
      "Epoch = 19\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9292688369750977, dv_loss = tensor([1.3610], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4025874137878418, iters = 5281\n",
      "Epoch = 19\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9105947017669678, dv_loss = tensor([2.1491], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.41623759269714355, iters = 5331\n",
      "Epoch = 19\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.027411937713623, dv_loss = tensor([1.1373], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.29439878463745117, iters = 5381\n",
      "###################################\n",
      "Epoch = 20\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.740912675857544, dv_loss = tensor([2.4916], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5794298648834229, iters = 5401\n",
      "Epoch = 20\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.6256954669952393, dv_loss = tensor([2.9894], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6892521381378174, iters = 5451\n",
      "Epoch = 20\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.822248935699463, dv_loss = tensor([1.1496], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4869194030761719, iters = 5501\n",
      "Epoch = 20\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.4110212326049805, dv_loss = tensor([0.6639], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.1068577766418457, iters = 5551\n",
      "Epoch = 20\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.0369672775268555, dv_loss = tensor([1.2370], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2634267807006836, iters = 5601\n",
      "Epoch = 20\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.8827338218688965, dv_loss = tensor([1.8020], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.41463422775268555, iters = 5651\n",
      "###################################\n",
      "Epoch = 21\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.792631149291992, dv_loss = tensor([2.8887], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5027341842651367, iters = 5671\n",
      "Epoch = 21\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.815699338912964, dv_loss = tensor([2.5154], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.47460389137268066, iters = 5721\n",
      "Epoch = 21\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9010744094848633, dv_loss = tensor([1.2792], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3846454620361328, iters = 5771\n",
      "Epoch = 21\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.7484543323516846, dv_loss = tensor([1.8024], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5338947772979736, iters = 5821\n",
      "Epoch = 21\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.8516838550567627, dv_loss = tensor([1.9952], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4247753620147705, iters = 5871\n",
      "Epoch = 21\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.662006139755249, dv_loss = tensor([2.3564], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6092798709869385, iters = 5921\n",
      "###################################\n",
      "Epoch = 22\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.445561170578003, dv_loss = tensor([3.1594], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8235876560211182, iters = 5941\n",
      "Epoch = 22\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.5271966457366943, dv_loss = tensor([1.4175], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.73551344871521, iters = 5991\n",
      "Epoch = 22\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.7978241443634033, dv_loss = tensor([1.7457], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4599778652191162, iters = 6041\n",
      "Epoch = 22\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.300004005432129, dv_loss = tensor([3.2283], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9534096717834473, iters = 6091\n",
      "Epoch = 22\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.6888463497161865, dv_loss = tensor([3.1359], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5567653179168701, iters = 6141\n",
      "Epoch = 22\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.4097390174865723, dv_loss = tensor([3.9953], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8279237747192383, iters = 6191\n",
      "###################################\n",
      "Epoch = 23\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.9699583053588867, dv_loss = tensor([3.6326], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2637200355529785, iters = 6211\n",
      "Epoch = 23\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.7816715240478516, dv_loss = tensor([6.9474], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4410157203674316, iters = 6261\n",
      "Epoch = 23\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.005519390106201, dv_loss = tensor([3.4125], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2045798301696777, iters = 6311\n",
      "Epoch = 23\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.4813623428344727, dv_loss = tensor([3.1202], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7181487083435059, iters = 6361\n",
      "Epoch = 23\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.5160398483276367, dv_loss = tensor([3.1714], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6745333671569824, iters = 6411\n",
      "Epoch = 23\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.4542734622955322, dv_loss = tensor([6.6601], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.724229097366333, iters = 6461\n",
      "###################################\n",
      "Epoch = 24\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.536468505859375, dv_loss = tensor([7.0189], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6361947059631348, iters = 6481\n",
      "Epoch = 24\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.0702009201049805, dv_loss = tensor([5.0189], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.087266445159912, iters = 6531\n",
      "Epoch = 24\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.0946624279022217, dv_loss = tensor([8.7334], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0446488857269287, iters = 6581\n",
      "Epoch = 24\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.7686409950256348, dv_loss = tensor([3.2716], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3569564819335938, iters = 6631\n",
      "Epoch = 24\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.959066152572632, dv_loss = tensor([4.3369], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.154029130935669, iters = 6681\n",
      "Epoch = 24\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.7789760828018188, dv_loss = tensor([8.9713], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.321157455444336, iters = 6731\n",
      "###################################\n",
      "Epoch = 25\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8693864345550537, dv_loss = tensor([9.5896], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2231733798980713, iters = 6751\n",
      "Epoch = 25\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6623798608779907, dv_loss = tensor([8.1267], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.411144733428955, iters = 6801\n",
      "Epoch = 25\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6340618133544922, dv_loss = tensor([10.3224], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4195852279663086, iters = 6851\n",
      "Epoch = 25\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.6275672912597656, dv_loss = tensor([6.8142], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4123868942260742, iters = 6901\n",
      "Epoch = 25\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.507195234298706, dv_loss = tensor([7.1386], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5193874835968018, iters = 6951\n",
      "Epoch = 25\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.554455280303955, dv_loss = tensor([9.4962], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4584169387817383, iters = 7001\n",
      "###################################\n",
      "Epoch = 26\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.532831072807312, dv_loss = tensor([8.2883], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.472224235534668, iters = 7021\n",
      "Epoch = 26\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6494719982147217, dv_loss = tensor([5.6308], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.33674693107605, iters = 7071\n",
      "Epoch = 26\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.7551748752593994, dv_loss = tensor([7.3025], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2126235961914062, iters = 7121\n",
      "Epoch = 26\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.337689161300659, dv_loss = tensor([7.8032], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6147239208221436, iters = 7171\n",
      "Epoch = 26\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.2744035720825195, dv_loss = tensor([5.4859], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6640772819519043, iters = 7221\n",
      "Epoch = 26\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3920658826828003, dv_loss = tensor([7.3321], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5322723388671875, iters = 7271\n",
      "###################################\n",
      "Epoch = 27\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.358860969543457, dv_loss = tensor([8.5658], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5576179027557373, iters = 7291\n",
      "Epoch = 27\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8810139894485474, dv_loss = tensor([6.8093], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.018941879272461, iters = 7341\n",
      "Epoch = 27\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.126349687576294, dv_loss = tensor([7.5283], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7579987049102783, iters = 7391\n",
      "Epoch = 27\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.328118324279785, dv_loss = tensor([5.2194], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5436501502990723, iters = 7441\n",
      "Epoch = 27\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.1348698139190674, dv_loss = tensor([8.9132], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7241172790527344, iters = 7491\n",
      "Epoch = 27\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2637234926223755, dv_loss = tensor([12.4512], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.580373764038086, iters = 7541\n",
      "###################################\n",
      "Epoch = 28\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.146546721458435, dv_loss = tensor([12.8537], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.689769744873047, iters = 7561\n",
      "Epoch = 28\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5176005363464355, dv_loss = tensor([7.7529], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3009634017944336, iters = 7611\n",
      "Epoch = 28\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6975114345550537, dv_loss = tensor([12.9678], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1041066646575928, iters = 7661\n",
      "Epoch = 28\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.641700029373169, dv_loss = tensor([6.2195], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.145085334777832, iters = 7711\n",
      "Epoch = 28\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.7106914520263672, dv_loss = tensor([6.7702], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.062283515930176, iters = 7761\n",
      "Epoch = 28\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.28412663936615, dv_loss = tensor([10.7432], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.473209857940674, iters = 7811\n",
      "###################################\n",
      "Epoch = 29\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2853577136993408, dv_loss = tensor([10.6048], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.464872360229492, iters = 7831\n",
      "Epoch = 29\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2574832439422607, dv_loss = tensor([5.9712], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.475804090499878, iters = 7881\n",
      "Epoch = 29\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.760920524597168, dv_loss = tensor([11.0967], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.956812858581543, iters = 7931\n",
      "Epoch = 29\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6399153470993042, dv_loss = tensor([6.9850], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0633459091186523, iters = 7981\n",
      "Epoch = 29\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6216737031936646, dv_loss = tensor([8.7340], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0674681663513184, iters = 8031\n",
      "Epoch = 29\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9634546041488647, dv_loss = tensor([14.4072], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.710385322570801, iters = 8081\n",
      "###################################\n",
      "Epoch = 30\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8663661479949951, dv_loss = tensor([13.4156], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.799964427947998, iters = 8101\n",
      "Epoch = 30\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1317329406738281, dv_loss = tensor([13.3541], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5171120166778564, iters = 8151\n",
      "Epoch = 30\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3629872798919678, dv_loss = tensor([9.6332], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.269378185272217, iters = 8201\n",
      "Epoch = 30\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.7658218145370483, dv_loss = tensor([7.1551], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.853235125541687, iters = 8251\n",
      "Epoch = 30\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6477354764938354, dv_loss = tensor([6.4254], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9580031633377075, iters = 8301\n",
      "Epoch = 30\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9996404051780701, dv_loss = tensor([10.0198], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5922203063964844, iters = 8351\n",
      "###################################\n",
      "Epoch = 31\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1776272058486938, dv_loss = tensor([10.3617], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4075708389282227, iters = 8371\n",
      "Epoch = 31\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7606160044670105, dv_loss = tensor([10.8307], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.806767225265503, iters = 8421\n",
      "Epoch = 31\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7888692617416382, dv_loss = tensor([7.8341], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.7604379653930664, iters = 8471\n",
      "Epoch = 31\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.26106595993042, dv_loss = tensor([12.0716], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2739458084106445, iters = 8521\n",
      "Epoch = 31\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0904345512390137, dv_loss = tensor([10.2798], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4290099143981934, iters = 8571\n",
      "Epoch = 31\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9508978128433228, dv_loss = tensor([8.6300], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.552713394165039, iters = 8621\n",
      "###################################\n",
      "Epoch = 32\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.121540904045105, dv_loss = tensor([10.2331], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.375720977783203, iters = 8641\n",
      "Epoch = 32\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7036800980567932, dv_loss = tensor([12.0387], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.776569128036499, iters = 8691\n",
      "Epoch = 32\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7181538343429565, dv_loss = tensor([7.8235], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.74472713470459, iters = 8741\n",
      "Epoch = 32\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0669671297073364, dv_loss = tensor([11.5015], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3808188438415527, iters = 8791\n",
      "Epoch = 32\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0476523637771606, dv_loss = tensor([7.8378], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3848958015441895, iters = 8841\n",
      "Epoch = 32\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6154253482818604, dv_loss = tensor([6.7486], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.801905393600464, iters = 8891\n",
      "###################################\n",
      "Epoch = 33\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7957453727722168, dv_loss = tensor([7.4997], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.6149704456329346, iters = 8911\n",
      "Epoch = 33\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7405595779418945, dv_loss = tensor([12.7881], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.65386700630188, iters = 8961\n",
      "Epoch = 33\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7300466299057007, dv_loss = tensor([12.5309], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.648080348968506, iters = 9011\n",
      "Epoch = 33\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0839917659759521, dv_loss = tensor([6.6008], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2801318168640137, iters = 9061\n",
      "Epoch = 33\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7433985471725464, dv_loss = tensor([14.6801], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.605806827545166, iters = 9111\n",
      "Epoch = 33\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7553914189338684, dv_loss = tensor([13.6970], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5783045291900635, iters = 9161\n",
      "###################################\n",
      "Epoch = 34\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8886165022850037, dv_loss = tensor([9.3122], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.439218044281006, iters = 9181\n",
      "Epoch = 34\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6872219443321228, dv_loss = tensor([11.3896], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.625119686126709, iters = 9231\n",
      "Epoch = 34\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6006739139556885, dv_loss = tensor([7.6770], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.695845603942871, iters = 9281\n",
      "Epoch = 34\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7804732322692871, dv_loss = tensor([7.2450], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.502556085586548, iters = 9331\n",
      "Epoch = 34\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.794826328754425, dv_loss = tensor([9.3030], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4738712310791016, iters = 9381\n",
      "Epoch = 34\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6793022155761719, dv_loss = tensor([9.9248], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5753540992736816, iters = 9431\n",
      "###################################\n",
      "Epoch = 35\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7225366830825806, dv_loss = tensor([10.9077], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.526259422302246, iters = 9451\n",
      "Epoch = 35\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6545690894126892, dv_loss = tensor([11.1817], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5796847343444824, iters = 9501\n",
      "Epoch = 35\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.575653612613678, dv_loss = tensor([2.5128], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.643958806991577, iters = 9551\n",
      "Epoch = 35\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1793956756591797, dv_loss = tensor([7.8365], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0285022258758545, iters = 9601\n",
      "Epoch = 35\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7779405117034912, dv_loss = tensor([11.3530], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4172604084014893, iters = 9651\n",
      "Epoch = 35\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8034461140632629, dv_loss = tensor([6.9083], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.378455877304077, iters = 9701\n",
      "###################################\n",
      "Epoch = 36\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8801752328872681, dv_loss = tensor([9.8601], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2963948249816895, iters = 9721\n",
      "Epoch = 36\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5665619373321533, dv_loss = tensor([10.0045], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.5962440967559814, iters = 9771\n",
      "Epoch = 36\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5801929235458374, dv_loss = tensor([12.1415], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.568666458129883, iters = 9821\n",
      "Epoch = 36\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9847459197044373, dv_loss = tensor([7.2899], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1530063152313232, iters = 9871\n",
      "Epoch = 36\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7778026461601257, dv_loss = tensor([8.8099], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.347630023956299, iters = 9921\n",
      "Epoch = 36\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7674962878227234, dv_loss = tensor([7.9297], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3452565670013428, iters = 9971\n",
      "###################################\n",
      "Epoch = 37\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9659054279327393, dv_loss = tensor([7.1845], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1420235633850098, iters = 9991\n",
      "Epoch = 37\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6267417669296265, dv_loss = tensor([10.7017], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.468256950378418, iters = 10041\n",
      "Epoch = 37\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5984337329864502, dv_loss = tensor([9.3734], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4834108352661133, iters = 10091\n",
      "Epoch = 37\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4880409240722656, dv_loss = tensor([5.3558], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5851030349731445, iters = 10141\n",
      "Epoch = 37\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1656337976455688, dv_loss = tensor([8.9141], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.897548794746399, iters = 10191\n",
      "Epoch = 37\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.017107605934143, dv_loss = tensor([7.8547], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.036083698272705, iters = 10241\n",
      "###################################\n",
      "Epoch = 38\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0640467405319214, dv_loss = tensor([8.5706], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9848984479904175, iters = 10261\n",
      "Epoch = 38\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.952311635017395, dv_loss = tensor([8.0468], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0860352516174316, iters = 10311\n",
      "Epoch = 38\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.631201446056366, dv_loss = tensor([6.8278], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.395660161972046, iters = 10361\n",
      "Epoch = 38\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.785976231098175, dv_loss = tensor([11.8405], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2302539348602295, iters = 10411\n",
      "Epoch = 38\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7306837439537048, dv_loss = tensor([7.4832], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2736995220184326, iters = 10461\n",
      "Epoch = 38\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5829179883003235, dv_loss = tensor([10.4760], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4093480110168457, iters = 10511\n",
      "###################################\n",
      "Epoch = 39\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8200332522392273, dv_loss = tensor([8.2896], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.167687177658081, iters = 10531\n",
      "Epoch = 39\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6416344046592712, dv_loss = tensor([4.5015], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3346047401428223, iters = 10581\n",
      "Epoch = 39\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5918702483177185, dv_loss = tensor([10.1393], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3724920749664307, iters = 10631\n",
      "Epoch = 39\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0522058010101318, dv_loss = tensor([5.5075], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9034826755523682, iters = 10681\n",
      "Epoch = 39\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7736250162124634, dv_loss = tensor([10.1958], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1715264320373535, iters = 10731\n",
      "Epoch = 39\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6562533378601074, dv_loss = tensor([9.9044], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2778844833374023, iters = 10781\n",
      "###################################\n",
      "Epoch = 40\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8096286654472351, dv_loss = tensor([8.1447], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1201910972595215, iters = 10801\n",
      "Epoch = 40\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5650789737701416, dv_loss = tensor([9.0683], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.3533928394317627, iters = 10851\n",
      "Epoch = 40\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5064986348152161, dv_loss = tensor([7.9777], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.4002578258514404, iters = 10901\n",
      "Epoch = 40\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9384346604347229, dv_loss = tensor([9.4797], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9601688385009766, iters = 10951\n",
      "Epoch = 40\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7033940553665161, dv_loss = tensor([5.1442], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1850318908691406, iters = 11001\n",
      "Epoch = 40\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6982994675636292, dv_loss = tensor([5.2828], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1795291900634766, iters = 11051\n",
      "###################################\n",
      "Epoch = 41\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8439778089523315, dv_loss = tensor([7.7166], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.029844284057617, iters = 11071\n",
      "Epoch = 41\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7188282608985901, dv_loss = tensor([8.2648], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1447720527648926, iters = 11121\n",
      "Epoch = 41\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5716807842254639, dv_loss = tensor([4.3306], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.281174421310425, iters = 11171\n",
      "Epoch = 41\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.804237425327301, dv_loss = tensor([4.9310], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.041412591934204, iters = 11221\n",
      "Epoch = 41\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8164269924163818, dv_loss = tensor([5.6795], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0196914672851562, iters = 11271\n",
      "Epoch = 41\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7306168079376221, dv_loss = tensor([9.1181], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.096048355102539, iters = 11321\n",
      "###################################\n",
      "Epoch = 42\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7567871809005737, dv_loss = tensor([6.9391], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0659117698669434, iters = 11341\n",
      "Epoch = 42\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6322510838508606, dv_loss = tensor([11.5596], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.180246591567993, iters = 11391\n",
      "Epoch = 42\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5022439360618591, dv_loss = tensor([7.6358], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2999236583709717, iters = 11441\n",
      "Epoch = 42\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8977921605110168, dv_loss = tensor([5.5010], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8971467018127441, iters = 11491\n",
      "Epoch = 42\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7770971655845642, dv_loss = tensor([6.6210], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.008957624435425, iters = 11541\n",
      "Epoch = 42\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.704131543636322, dv_loss = tensor([7.9969], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0722193717956543, iters = 11591\n",
      "###################################\n",
      "Epoch = 43\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7968379259109497, dv_loss = tensor([8.5002], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9758130311965942, iters = 11611\n",
      "Epoch = 43\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8188186883926392, dv_loss = tensor([8.4288], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9444390535354614, iters = 11661\n",
      "Epoch = 43\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.4895835816860199, dv_loss = tensor([9.6654], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.2643184661865234, iters = 11711\n",
      "Epoch = 43\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9523642063140869, dv_loss = tensor([8.6762], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7952344417572021, iters = 11761\n",
      "Epoch = 43\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9065977931022644, dv_loss = tensor([10.3281], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8324403762817383, iters = 11811\n",
      "Epoch = 43\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7216885089874268, dv_loss = tensor([8.7474], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.008718252182007, iters = 11861\n",
      "###################################\n",
      "Epoch = 44\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8190270066261292, dv_loss = tensor([8.2172], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9078552722930908, iters = 11881\n",
      "Epoch = 44\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7452343106269836, dv_loss = tensor([7.6002], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9727299213409424, iters = 11931\n",
      "Epoch = 44\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5217371582984924, dv_loss = tensor([10.3571], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1867470741271973, iters = 11981\n",
      "Epoch = 44\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0549319982528687, dv_loss = tensor([6.3716], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6488627195358276, iters = 12031\n",
      "Epoch = 44\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8226855993270874, dv_loss = tensor([7.9201], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8735250234603882, iters = 12081\n",
      "Epoch = 44\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8404343128204346, dv_loss = tensor([8.0353], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8477048873901367, iters = 12131\n",
      "###################################\n",
      "Epoch = 45\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9387979507446289, dv_loss = tensor([3.3287], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7461884021759033, iters = 12151\n",
      "Epoch = 45\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6574641466140747, dv_loss = tensor([7.7834], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0187888145446777, iters = 12201\n",
      "Epoch = 45\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5263158679008484\n",
      "Prob Vector = tensor([[0.5186],\n",
      "        [0.5195],\n",
      "        [0.5209],\n",
      "        [0.5223],\n",
      "        [0.5235],\n",
      "        [0.5247],\n",
      "        [0.5260],\n",
      "        [0.5274],\n",
      "        [0.5284],\n",
      "        [0.5294],\n",
      "        [0.5301],\n",
      "        [0.5308],\n",
      "        [0.5309],\n",
      "        [0.5311],\n",
      "        [0.5311]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5444290041923523, dv_loss = tensor([8.0606], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1227481365203857, iters = 12251\n",
      "Epoch = 45\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5169780254364014\n",
      "Prob Vector = tensor([[0.5187],\n",
      "        [0.5209],\n",
      "        [0.5126],\n",
      "        [0.5168],\n",
      "        [0.5150],\n",
      "        [0.5183],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5173],\n",
      "        [0.5170],\n",
      "        [0.5166],\n",
      "        [0.5162],\n",
      "        [0.5159],\n",
      "        [0.5154]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3343783617019653, dv_loss = tensor([6.4089], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3273521661758423, iters = 12301\n",
      "Epoch = 45\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.530247151851654\n",
      "Prob Vector = tensor([[0.5252],\n",
      "        [0.5264],\n",
      "        [0.5276],\n",
      "        [0.5288],\n",
      "        [0.5295],\n",
      "        [0.5302],\n",
      "        [0.5307],\n",
      "        [0.5312],\n",
      "        [0.5315],\n",
      "        [0.5317],\n",
      "        [0.5320],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5319]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7061376571655273, dv_loss = tensor([4.5780], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9479570388793945, iters = 12351\n",
      "Epoch = 45\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5170855522155762\n",
      "Prob Vector = tensor([[0.5191],\n",
      "        [0.5190],\n",
      "        [0.5188],\n",
      "        [0.5186],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5180],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5170],\n",
      "        [0.5162],\n",
      "        [0.5155],\n",
      "        [0.5149],\n",
      "        [0.5141],\n",
      "        [0.5132]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7007444500923157, dv_loss = tensor([4.6890], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.945103406906128, iters = 12401\n",
      "###################################\n",
      "Epoch = 46\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.5215827822685242\n",
      "Prob Vector = tensor([[0.5136],\n",
      "        [0.5145],\n",
      "        [0.5156],\n",
      "        [0.5164],\n",
      "        [0.5174],\n",
      "        [0.5186],\n",
      "        [0.5199],\n",
      "        [0.5213],\n",
      "        [0.5229],\n",
      "        [0.5242],\n",
      "        [0.5254],\n",
      "        [0.5270],\n",
      "        [0.5282],\n",
      "        [0.5291],\n",
      "        [0.5296]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9050307869911194, dv_loss = tensor([10.8157], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7376079559326172, iters = 12421\n",
      "Epoch = 46\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5181315541267395\n",
      "Prob Vector = tensor([[0.5199],\n",
      "        [0.5197],\n",
      "        [0.5194],\n",
      "        [0.5191],\n",
      "        [0.5187],\n",
      "        [0.5185],\n",
      "        [0.5184],\n",
      "        [0.5182],\n",
      "        [0.5179],\n",
      "        [0.5177],\n",
      "        [0.5175],\n",
      "        [0.5172],\n",
      "        [0.5169],\n",
      "        [0.5166],\n",
      "        [0.5164]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7561511993408203, dv_loss = tensor([3.6204], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.879148006439209, iters = 12471\n",
      "Epoch = 46\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.5635766983032227\n",
      "Prob Vector = tensor([[0.5573],\n",
      "        [0.5581],\n",
      "        [0.5595],\n",
      "        [0.5609],\n",
      "        [0.5618],\n",
      "        [0.5628],\n",
      "        [0.5638],\n",
      "        [0.5648],\n",
      "        [0.5656],\n",
      "        [0.5662],\n",
      "        [0.5666],\n",
      "        [0.5670],\n",
      "        [0.5667],\n",
      "        [0.5665],\n",
      "        [0.5660]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7886499762535095, dv_loss = tensor([9.6445], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8392250537872314, iters = 12521\n",
      "Epoch = 46\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5698022246360779\n",
      "Prob Vector = tensor([[0.5767],\n",
      "        [0.5784],\n",
      "        [0.5724],\n",
      "        [0.5755],\n",
      "        [0.5701],\n",
      "        [0.5695],\n",
      "        [0.5691],\n",
      "        [0.5686],\n",
      "        [0.5681],\n",
      "        [0.5675],\n",
      "        [0.5672],\n",
      "        [0.5667],\n",
      "        [0.5663],\n",
      "        [0.5658],\n",
      "        [0.5652]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.887482225894928, dv_loss = tensor([8.9655], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7367994785308838, iters = 12571\n",
      "Epoch = 46\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.663325846195221\n",
      "Prob Vector = tensor([[0.6654],\n",
      "        [0.6660],\n",
      "        [0.6663],\n",
      "        [0.6664],\n",
      "        [0.6663],\n",
      "        [0.6660],\n",
      "        [0.6655],\n",
      "        [0.6648],\n",
      "        [0.6641],\n",
      "        [0.6632],\n",
      "        [0.6620],\n",
      "        [0.6607],\n",
      "        [0.6592],\n",
      "        [0.6577],\n",
      "        [0.6561]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.717637300491333, dv_loss = tensor([7.0313], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8992276191711426, iters = 12621\n",
      "Epoch = 46\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.6739867329597473\n",
      "Prob Vector = tensor([[0.6794],\n",
      "        [0.6784],\n",
      "        [0.6774],\n",
      "        [0.6762],\n",
      "        [0.6754],\n",
      "        [0.6746],\n",
      "        [0.6738],\n",
      "        [0.6730],\n",
      "        [0.6726],\n",
      "        [0.6721],\n",
      "        [0.6717],\n",
      "        [0.6715],\n",
      "        [0.6714],\n",
      "        [0.6712],\n",
      "        [0.6711]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5885142683982849, dv_loss = tensor([7.9055], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0197625160217285, iters = 12671\n",
      "###################################\n",
      "Epoch = 47\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.755979061126709\n",
      "Prob Vector = tensor([[0.7419],\n",
      "        [0.7448],\n",
      "        [0.7478],\n",
      "        [0.7503],\n",
      "        [0.7527],\n",
      "        [0.7548],\n",
      "        [0.7567],\n",
      "        [0.7581],\n",
      "        [0.7595],\n",
      "        [0.7607],\n",
      "        [0.7617],\n",
      "        [0.7623],\n",
      "        [0.7627],\n",
      "        [0.7630],\n",
      "        [0.7627]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7256983518600464, dv_loss = tensor([6.4322], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8793545961380005, iters = 12691\n",
      "Epoch = 47\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.7605680227279663\n",
      "Prob Vector = tensor([[0.7676],\n",
      "        [0.7665],\n",
      "        [0.7652],\n",
      "        [0.7641],\n",
      "        [0.7629],\n",
      "        [0.7619],\n",
      "        [0.7609],\n",
      "        [0.7600],\n",
      "        [0.7592],\n",
      "        [0.7584],\n",
      "        [0.7576],\n",
      "        [0.7569],\n",
      "        [0.7563],\n",
      "        [0.7558],\n",
      "        [0.7553]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7342621088027954, dv_loss = tensor([5.7998], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8628798723220825, iters = 12741\n",
      "Epoch = 47\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8870818018913269\n",
      "Prob Vector = tensor([[0.8831],\n",
      "        [0.8845],\n",
      "        [0.8858],\n",
      "        [0.8868],\n",
      "        [0.8875],\n",
      "        [0.8880],\n",
      "        [0.8885],\n",
      "        [0.8889],\n",
      "        [0.8891],\n",
      "        [0.8890],\n",
      "        [0.8887],\n",
      "        [0.8881],\n",
      "        [0.8872],\n",
      "        [0.8862],\n",
      "        [0.8849]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7078540921211243, dv_loss = tensor([2.9785], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8817784786224365, iters = 12791\n",
      "Epoch = 47\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8234562277793884\n",
      "Prob Vector = tensor([[0.8429],\n",
      "        [0.8427],\n",
      "        [0.8403],\n",
      "        [0.8321],\n",
      "        [0.8216],\n",
      "        [0.8212],\n",
      "        [0.8201],\n",
      "        [0.8190],\n",
      "        [0.8180],\n",
      "        [0.8170],\n",
      "        [0.8162],\n",
      "        [0.8156],\n",
      "        [0.8152],\n",
      "        [0.8149],\n",
      "        [0.8151]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7225126624107361, dv_loss = tensor([3.2849], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8650717735290527, iters = 12841\n",
      "Epoch = 47\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8871620893478394\n",
      "Prob Vector = tensor([[0.8880],\n",
      "        [0.8887],\n",
      "        [0.8891],\n",
      "        [0.8895],\n",
      "        [0.8897],\n",
      "        [0.8897],\n",
      "        [0.8893],\n",
      "        [0.8889],\n",
      "        [0.8883],\n",
      "        [0.8875],\n",
      "        [0.8866],\n",
      "        [0.8854],\n",
      "        [0.8839],\n",
      "        [0.8823],\n",
      "        [0.8806]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7666154503822327, dv_loss = tensor([2.4632], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.813199758529663, iters = 12891\n",
      "Epoch = 47\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8156505823135376\n",
      "Prob Vector = tensor([[0.8220],\n",
      "        [0.8206],\n",
      "        [0.8191],\n",
      "        [0.8176],\n",
      "        [0.8164],\n",
      "        [0.8154],\n",
      "        [0.8145],\n",
      "        [0.8138],\n",
      "        [0.8136],\n",
      "        [0.8132],\n",
      "        [0.8131],\n",
      "        [0.8132],\n",
      "        [0.8137],\n",
      "        [0.8140],\n",
      "        [0.8145]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6245496869087219, dv_loss = tensor([3.5946], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9471783638000488, iters = 12941\n",
      "###################################\n",
      "Epoch = 48\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8855204582214355\n",
      "Prob Vector = tensor([[0.8718],\n",
      "        [0.8748],\n",
      "        [0.8778],\n",
      "        [0.8803],\n",
      "        [0.8826],\n",
      "        [0.8845],\n",
      "        [0.8863],\n",
      "        [0.8876],\n",
      "        [0.8888],\n",
      "        [0.8899],\n",
      "        [0.8908],\n",
      "        [0.8914],\n",
      "        [0.8919],\n",
      "        [0.8922],\n",
      "        [0.8921]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8071283102035522, dv_loss = tensor([3.0250], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7616106271743774, iters = 12961\n",
      "Epoch = 48\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8398778438568115\n",
      "Prob Vector = tensor([[0.8473],\n",
      "        [0.8462],\n",
      "        [0.8449],\n",
      "        [0.8437],\n",
      "        [0.8425],\n",
      "        [0.8413],\n",
      "        [0.8403],\n",
      "        [0.8393],\n",
      "        [0.8384],\n",
      "        [0.8375],\n",
      "        [0.8367],\n",
      "        [0.8359],\n",
      "        [0.8353],\n",
      "        [0.8347],\n",
      "        [0.8342]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5843378305435181, dv_loss = tensor([4.7471], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9764567613601685, iters = 13011\n",
      "Epoch = 48\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8945067524909973\n",
      "Prob Vector = tensor([[0.8881],\n",
      "        [0.8898],\n",
      "        [0.8913],\n",
      "        [0.8925],\n",
      "        [0.8936],\n",
      "        [0.8945],\n",
      "        [0.8954],\n",
      "        [0.8961],\n",
      "        [0.8966],\n",
      "        [0.8970],\n",
      "        [0.8972],\n",
      "        [0.8971],\n",
      "        [0.8967],\n",
      "        [0.8962],\n",
      "        [0.8955]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.41579216718673706, dv_loss = tensor([3.1516], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.1367719173431396, iters = 13061\n",
      "Epoch = 48\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8129627704620361\n",
      "Prob Vector = tensor([[0.8417],\n",
      "        [0.8405],\n",
      "        [0.8357],\n",
      "        [0.8236],\n",
      "        [0.8107],\n",
      "        [0.8084],\n",
      "        [0.8073],\n",
      "        [0.8062],\n",
      "        [0.8051],\n",
      "        [0.8040],\n",
      "        [0.8032],\n",
      "        [0.8026],\n",
      "        [0.8021],\n",
      "        [0.8017],\n",
      "        [0.8016]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5472313761711121, dv_loss = tensor([4.5021], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.001213550567627, iters = 13111\n",
      "Epoch = 48\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8912591934204102\n",
      "Prob Vector = tensor([[0.8898],\n",
      "        [0.8910],\n",
      "        [0.8918],\n",
      "        [0.8923],\n",
      "        [0.8928],\n",
      "        [0.8930],\n",
      "        [0.8931],\n",
      "        [0.8931],\n",
      "        [0.8928],\n",
      "        [0.8924],\n",
      "        [0.8917],\n",
      "        [0.8908],\n",
      "        [0.8895],\n",
      "        [0.8881],\n",
      "        [0.8866]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5724011659622192, dv_loss = tensor([2.9953], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9681984186172485, iters = 13161\n",
      "Epoch = 48\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8333768844604492\n",
      "Prob Vector = tensor([[0.8400],\n",
      "        [0.8386],\n",
      "        [0.8371],\n",
      "        [0.8355],\n",
      "        [0.8343],\n",
      "        [0.8333],\n",
      "        [0.8324],\n",
      "        [0.8317],\n",
      "        [0.8314],\n",
      "        [0.8311],\n",
      "        [0.8308],\n",
      "        [0.8309],\n",
      "        [0.8311],\n",
      "        [0.8312],\n",
      "        [0.8314]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6176678538322449, dv_loss = tensor([4.4716], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9151318073272705, iters = 13211\n",
      "###################################\n",
      "Epoch = 49\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8989919424057007\n",
      "Prob Vector = tensor([[0.8842],\n",
      "        [0.8872],\n",
      "        [0.8902],\n",
      "        [0.8929],\n",
      "        [0.8953],\n",
      "        [0.8975],\n",
      "        [0.8994],\n",
      "        [0.9009],\n",
      "        [0.9024],\n",
      "        [0.9037],\n",
      "        [0.9048],\n",
      "        [0.9058],\n",
      "        [0.9065],\n",
      "        [0.9070],\n",
      "        [0.9072]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7139114737510681, dv_loss = tensor([2.2251], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8158750534057617, iters = 13231\n",
      "Epoch = 49\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8251174092292786\n",
      "Prob Vector = tensor([[0.8331],\n",
      "        [0.8319],\n",
      "        [0.8306],\n",
      "        [0.8293],\n",
      "        [0.8280],\n",
      "        [0.8267],\n",
      "        [0.8256],\n",
      "        [0.8245],\n",
      "        [0.8234],\n",
      "        [0.8225],\n",
      "        [0.8216],\n",
      "        [0.8208],\n",
      "        [0.8202],\n",
      "        [0.8196],\n",
      "        [0.8190]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7203747630119324, dv_loss = tensor([3.7731], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8021857738494873, iters = 13281\n",
      "Epoch = 49\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8973630666732788\n",
      "Prob Vector = tensor([[0.8896],\n",
      "        [0.8914],\n",
      "        [0.8930],\n",
      "        [0.8945],\n",
      "        [0.8957],\n",
      "        [0.8967],\n",
      "        [0.8979],\n",
      "        [0.8989],\n",
      "        [0.8997],\n",
      "        [0.9004],\n",
      "        [0.9008],\n",
      "        [0.9009],\n",
      "        [0.9007],\n",
      "        [0.9005],\n",
      "        [0.8999]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.60813307762146, dv_loss = tensor([2.7418], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.90743088722229, iters = 13331\n",
      "Epoch = 49\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8232415914535522\n",
      "Prob Vector = tensor([[0.8555],\n",
      "        [0.8538],\n",
      "        [0.8480],\n",
      "        [0.8350],\n",
      "        [0.8203],\n",
      "        [0.8178],\n",
      "        [0.8167],\n",
      "        [0.8156],\n",
      "        [0.8145],\n",
      "        [0.8134],\n",
      "        [0.8126],\n",
      "        [0.8120],\n",
      "        [0.8115],\n",
      "        [0.8111],\n",
      "        [0.8108]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1710494756698608, dv_loss = tensor([2.5674], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3431118726730347, iters = 13381\n",
      "Epoch = 49\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8960289359092712\n",
      "Prob Vector = tensor([[0.8934],\n",
      "        [0.8947],\n",
      "        [0.8957],\n",
      "        [0.8964],\n",
      "        [0.8972],\n",
      "        [0.8976],\n",
      "        [0.8977],\n",
      "        [0.8979],\n",
      "        [0.8977],\n",
      "        [0.8975],\n",
      "        [0.8970],\n",
      "        [0.8962],\n",
      "        [0.8951],\n",
      "        [0.8939],\n",
      "        [0.8925]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.48320385813713074, dv_loss = tensor([3.1575], device='cuda:0', grad_fn=<AddBackward0>), reward = 2.0245919227600098, iters = 13431\n",
      "Epoch = 49\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8354923725128174\n",
      "Prob Vector = tensor([[0.8421],\n",
      "        [0.8407],\n",
      "        [0.8392],\n",
      "        [0.8376],\n",
      "        [0.8364],\n",
      "        [0.8353],\n",
      "        [0.8344],\n",
      "        [0.8337],\n",
      "        [0.8335],\n",
      "        [0.8332],\n",
      "        [0.8330],\n",
      "        [0.8330],\n",
      "        [0.8333],\n",
      "        [0.8334],\n",
      "        [0.8336]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5257840156555176, dv_loss = tensor([4.2269], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9740655422210693, iters = 13481\n",
      "###################################\n",
      "Epoch = 50\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8986979126930237\n",
      "Prob Vector = tensor([[0.8839],\n",
      "        [0.8869],\n",
      "        [0.8899],\n",
      "        [0.8926],\n",
      "        [0.8950],\n",
      "        [0.8971],\n",
      "        [0.8991],\n",
      "        [0.9006],\n",
      "        [0.9020],\n",
      "        [0.9033],\n",
      "        [0.9045],\n",
      "        [0.9054],\n",
      "        [0.9062],\n",
      "        [0.9069],\n",
      "        [0.9070]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6213783025741577, dv_loss = tensor([2.4848], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8755518198013306, iters = 13501\n",
      "Epoch = 50\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.825989842414856\n",
      "Prob Vector = tensor([[0.8340],\n",
      "        [0.8328],\n",
      "        [0.8315],\n",
      "        [0.8302],\n",
      "        [0.8289],\n",
      "        [0.8276],\n",
      "        [0.8265],\n",
      "        [0.8254],\n",
      "        [0.8243],\n",
      "        [0.8234],\n",
      "        [0.8225],\n",
      "        [0.8216],\n",
      "        [0.8210],\n",
      "        [0.8204],\n",
      "        [0.8198]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5723040103912354, dv_loss = tensor([5.0043], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9172594547271729, iters = 13551\n",
      "Epoch = 50\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8982396125793457\n",
      "Prob Vector = tensor([[0.8904],\n",
      "        [0.8922],\n",
      "        [0.8938],\n",
      "        [0.8953],\n",
      "        [0.8965],\n",
      "        [0.8975],\n",
      "        [0.8987],\n",
      "        [0.8997],\n",
      "        [0.9005],\n",
      "        [0.9012],\n",
      "        [0.9017],\n",
      "        [0.9020],\n",
      "        [0.9018],\n",
      "        [0.9015],\n",
      "        [0.9010]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5426777601242065, dv_loss = tensor([2.7702], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9393996000289917, iters = 13601\n",
      "Epoch = 50\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8235912919044495\n",
      "Prob Vector = tensor([[0.8571],\n",
      "        [0.8547],\n",
      "        [0.8482],\n",
      "        [0.8348],\n",
      "        [0.8204],\n",
      "        [0.8180],\n",
      "        [0.8168],\n",
      "        [0.8157],\n",
      "        [0.8146],\n",
      "        [0.8136],\n",
      "        [0.8128],\n",
      "        [0.8122],\n",
      "        [0.8119],\n",
      "        [0.8116],\n",
      "        [0.8114]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4782153367996216, dv_loss = tensor([1.9303], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0032473802566528, iters = 13651\n",
      "Epoch = 50\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8937034606933594\n",
      "Prob Vector = tensor([[0.8906],\n",
      "        [0.8921],\n",
      "        [0.8930],\n",
      "        [0.8938],\n",
      "        [0.8946],\n",
      "        [0.8951],\n",
      "        [0.8954],\n",
      "        [0.8956],\n",
      "        [0.8955],\n",
      "        [0.8953],\n",
      "        [0.8949],\n",
      "        [0.8941],\n",
      "        [0.8931],\n",
      "        [0.8919],\n",
      "        [0.8905]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6995461583137512, dv_loss = tensor([2.8338], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7773120403289795, iters = 13701\n",
      "Epoch = 50\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8323436379432678\n",
      "Prob Vector = tensor([[0.8390],\n",
      "        [0.8375],\n",
      "        [0.8360],\n",
      "        [0.8344],\n",
      "        [0.8332],\n",
      "        [0.8322],\n",
      "        [0.8313],\n",
      "        [0.8306],\n",
      "        [0.8303],\n",
      "        [0.8300],\n",
      "        [0.8298],\n",
      "        [0.8299],\n",
      "        [0.8302],\n",
      "        [0.8303],\n",
      "        [0.8305]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6140353083610535, dv_loss = tensor([4.6664], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8555407524108887, iters = 13751\n",
      "###################################\n",
      "Epoch = 51\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8949702978134155\n",
      "Prob Vector = tensor([[0.8801],\n",
      "        [0.8830],\n",
      "        [0.8861],\n",
      "        [0.8887],\n",
      "        [0.8912],\n",
      "        [0.8933],\n",
      "        [0.8952],\n",
      "        [0.8968],\n",
      "        [0.8982],\n",
      "        [0.8996],\n",
      "        [0.9008],\n",
      "        [0.9018],\n",
      "        [0.9027],\n",
      "        [0.9034],\n",
      "        [0.9036]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7323610186576843, dv_loss = tensor([2.3621], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7344682216644287, iters = 13771\n",
      "Epoch = 51\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8293192982673645\n",
      "Prob Vector = tensor([[0.8374],\n",
      "        [0.8362],\n",
      "        [0.8348],\n",
      "        [0.8336],\n",
      "        [0.8322],\n",
      "        [0.8310],\n",
      "        [0.8298],\n",
      "        [0.8287],\n",
      "        [0.8276],\n",
      "        [0.8267],\n",
      "        [0.8258],\n",
      "        [0.8249],\n",
      "        [0.8243],\n",
      "        [0.8237],\n",
      "        [0.8231]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.643643319606781, dv_loss = tensor([4.3473], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.816094160079956, iters = 13821\n",
      "Epoch = 51\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.9002549052238464\n",
      "Prob Vector = tensor([[0.8927],\n",
      "        [0.8944],\n",
      "        [0.8960],\n",
      "        [0.8975],\n",
      "        [0.8987],\n",
      "        [0.8997],\n",
      "        [0.9007],\n",
      "        [0.9017],\n",
      "        [0.9024],\n",
      "        [0.9031],\n",
      "        [0.9035],\n",
      "        [0.9037],\n",
      "        [0.9035],\n",
      "        [0.9033],\n",
      "        [0.9028]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5344216823577881, dv_loss = tensor([2.5610], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.918294906616211, iters = 13871\n",
      "Epoch = 51\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8076125383377075\n",
      "Prob Vector = tensor([[0.8384],\n",
      "        [0.8352],\n",
      "        [0.8263],\n",
      "        [0.8179],\n",
      "        [0.8046],\n",
      "        [0.8029],\n",
      "        [0.8018],\n",
      "        [0.8007],\n",
      "        [0.7996],\n",
      "        [0.7986],\n",
      "        [0.7980],\n",
      "        [0.7976],\n",
      "        [0.7975],\n",
      "        [0.7974],\n",
      "        [0.7975]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.7514841556549072, dv_loss = tensor([25.1571], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.2947971820831299, iters = 13921\n",
      "Epoch = 51\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.818568229675293\n",
      "Prob Vector = tensor([[0.8128],\n",
      "        [0.8148],\n",
      "        [0.8161],\n",
      "        [0.8176],\n",
      "        [0.8187],\n",
      "        [0.8196],\n",
      "        [0.8202],\n",
      "        [0.8208],\n",
      "        [0.8210],\n",
      "        [0.8212],\n",
      "        [0.8210],\n",
      "        [0.8205],\n",
      "        [0.8193],\n",
      "        [0.8182],\n",
      "        [0.8167]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3761529922485352, dv_loss = tensor([2.1639], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.082733154296875, iters = 13971\n",
      "Epoch = 51\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7879180312156677\n",
      "Prob Vector = tensor([[0.7936],\n",
      "        [0.7923],\n",
      "        [0.7908],\n",
      "        [0.7893],\n",
      "        [0.7883],\n",
      "        [0.7873],\n",
      "        [0.7867],\n",
      "        [0.7862],\n",
      "        [0.7863],\n",
      "        [0.7862],\n",
      "        [0.7860],\n",
      "        [0.7862],\n",
      "        [0.7864],\n",
      "        [0.7866],\n",
      "        [0.7865]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.167259693145752, dv_loss = tensor([2.1851], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2865684032440186, iters = 14021\n",
      "###################################\n",
      "Epoch = 52\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8564238548278809\n",
      "Prob Vector = tensor([[0.8391],\n",
      "        [0.8427],\n",
      "        [0.8462],\n",
      "        [0.8494],\n",
      "        [0.8523],\n",
      "        [0.8548],\n",
      "        [0.8570],\n",
      "        [0.8585],\n",
      "        [0.8600],\n",
      "        [0.8615],\n",
      "        [0.8628],\n",
      "        [0.8640],\n",
      "        [0.8653],\n",
      "        [0.8662],\n",
      "        [0.8666]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1895263195037842, dv_loss = tensor([2.1878], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2623419761657715, iters = 14041\n",
      "Epoch = 52\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8214117884635925\n",
      "Prob Vector = tensor([[0.8294],\n",
      "        [0.8282],\n",
      "        [0.8268],\n",
      "        [0.8256],\n",
      "        [0.8243],\n",
      "        [0.8231],\n",
      "        [0.8219],\n",
      "        [0.8209],\n",
      "        [0.8198],\n",
      "        [0.8188],\n",
      "        [0.8179],\n",
      "        [0.8170],\n",
      "        [0.8164],\n",
      "        [0.8158],\n",
      "        [0.8153]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6545257568359375, dv_loss = tensor([4.1708], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.792506217956543, iters = 14091\n",
      "Epoch = 52\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8952608704566956\n",
      "Prob Vector = tensor([[0.8876],\n",
      "        [0.8893],\n",
      "        [0.8910],\n",
      "        [0.8925],\n",
      "        [0.8937],\n",
      "        [0.8947],\n",
      "        [0.8957],\n",
      "        [0.8967],\n",
      "        [0.8974],\n",
      "        [0.8981],\n",
      "        [0.8985],\n",
      "        [0.8988],\n",
      "        [0.8986],\n",
      "        [0.8984],\n",
      "        [0.8979]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6986982226371765, dv_loss = tensor([2.7364], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7417471408843994, iters = 14141\n",
      "Epoch = 52\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8187651634216309\n",
      "Prob Vector = tensor([[0.8474],\n",
      "        [0.8465],\n",
      "        [0.8397],\n",
      "        [0.8265],\n",
      "        [0.8169],\n",
      "        [0.8145],\n",
      "        [0.8133],\n",
      "        [0.8122],\n",
      "        [0.8111],\n",
      "        [0.8101],\n",
      "        [0.8094],\n",
      "        [0.8089],\n",
      "        [0.8085],\n",
      "        [0.8082],\n",
      "        [0.8082]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.281457781791687, dv_loss = tensor([2.9292], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1574550867080688, iters = 14191\n",
      "Epoch = 52\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8923920392990112\n",
      "Prob Vector = tensor([[0.8896],\n",
      "        [0.8910],\n",
      "        [0.8917],\n",
      "        [0.8925],\n",
      "        [0.8932],\n",
      "        [0.8936],\n",
      "        [0.8939],\n",
      "        [0.8942],\n",
      "        [0.8941],\n",
      "        [0.8939],\n",
      "        [0.8936],\n",
      "        [0.8929],\n",
      "        [0.8918],\n",
      "        [0.8907],\n",
      "        [0.8893]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6631624102592468, dv_loss = tensor([2.4772], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.770538091659546, iters = 14241\n",
      "Epoch = 52\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8317677974700928\n",
      "Prob Vector = tensor([[0.8384],\n",
      "        [0.8370],\n",
      "        [0.8355],\n",
      "        [0.8338],\n",
      "        [0.8326],\n",
      "        [0.8316],\n",
      "        [0.8307],\n",
      "        [0.8301],\n",
      "        [0.8298],\n",
      "        [0.8295],\n",
      "        [0.8293],\n",
      "        [0.8293],\n",
      "        [0.8294],\n",
      "        [0.8296],\n",
      "        [0.8298]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5492346882820129, dv_loss = tensor([4.1096], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.877929925918579, iters = 14291\n",
      "###################################\n",
      "Epoch = 53\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8945466876029968\n",
      "Prob Vector = tensor([[0.8798],\n",
      "        [0.8829],\n",
      "        [0.8859],\n",
      "        [0.8885],\n",
      "        [0.8908],\n",
      "        [0.8929],\n",
      "        [0.8949],\n",
      "        [0.8964],\n",
      "        [0.8978],\n",
      "        [0.8992],\n",
      "        [0.9004],\n",
      "        [0.9013],\n",
      "        [0.9021],\n",
      "        [0.9026],\n",
      "        [0.9028]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7444766163825989, dv_loss = tensor([2.2940], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.680004358291626, iters = 14311\n",
      "Epoch = 53\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8351393938064575\n",
      "Prob Vector = tensor([[0.8430],\n",
      "        [0.8418],\n",
      "        [0.8404],\n",
      "        [0.8392],\n",
      "        [0.8379],\n",
      "        [0.8367],\n",
      "        [0.8356],\n",
      "        [0.8346],\n",
      "        [0.8336],\n",
      "        [0.8326],\n",
      "        [0.8317],\n",
      "        [0.8309],\n",
      "        [0.8303],\n",
      "        [0.8297],\n",
      "        [0.8292]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7617450952529907, dv_loss = tensor([4.0965], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6565402746200562, iters = 14361\n",
      "Epoch = 53\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.9005293846130371\n",
      "Prob Vector = tensor([[0.8934],\n",
      "        [0.8951],\n",
      "        [0.8966],\n",
      "        [0.8979],\n",
      "        [0.8990],\n",
      "        [0.8998],\n",
      "        [0.9008],\n",
      "        [0.9018],\n",
      "        [0.9025],\n",
      "        [0.9032],\n",
      "        [0.9036],\n",
      "        [0.9039],\n",
      "        [0.9037],\n",
      "        [0.9036],\n",
      "        [0.9031]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5339899659156799, dv_loss = tensor([3.3320], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8783624172210693, iters = 14411\n",
      "Epoch = 53\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8090233206748962\n",
      "Prob Vector = tensor([[0.8392],\n",
      "        [0.8369],\n",
      "        [0.8286],\n",
      "        [0.8188],\n",
      "        [0.8070],\n",
      "        [0.8044],\n",
      "        [0.8032],\n",
      "        [0.8021],\n",
      "        [0.8010],\n",
      "        [0.8000],\n",
      "        [0.7993],\n",
      "        [0.7989],\n",
      "        [0.7987],\n",
      "        [0.7986],\n",
      "        [0.7987]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.277505874633789, dv_loss = tensor([2.1333], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1345419883728027, iters = 14461\n",
      "Epoch = 53\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.884917676448822\n",
      "Prob Vector = tensor([[0.8814],\n",
      "        [0.8828],\n",
      "        [0.8838],\n",
      "        [0.8847],\n",
      "        [0.8854],\n",
      "        [0.8859],\n",
      "        [0.8863],\n",
      "        [0.8866],\n",
      "        [0.8867],\n",
      "        [0.8867],\n",
      "        [0.8864],\n",
      "        [0.8858],\n",
      "        [0.8849],\n",
      "        [0.8838],\n",
      "        [0.8824]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.56474769115448, dv_loss = tensor([2.5408], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8418463468551636, iters = 14511\n",
      "Epoch = 53\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8262356519699097\n",
      "Prob Vector = tensor([[0.8327],\n",
      "        [0.8312],\n",
      "        [0.8297],\n",
      "        [0.8280],\n",
      "        [0.8268],\n",
      "        [0.8259],\n",
      "        [0.8250],\n",
      "        [0.8245],\n",
      "        [0.8243],\n",
      "        [0.8241],\n",
      "        [0.8241],\n",
      "        [0.8242],\n",
      "        [0.8243],\n",
      "        [0.8243],\n",
      "        [0.8245]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5943008065223694, dv_loss = tensor([3.1207], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8052988052368164, iters = 14561\n",
      "###################################\n",
      "Epoch = 54\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8884614706039429\n",
      "Prob Vector = tensor([[0.8737],\n",
      "        [0.8767],\n",
      "        [0.8798],\n",
      "        [0.8824],\n",
      "        [0.8847],\n",
      "        [0.8868],\n",
      "        [0.8888],\n",
      "        [0.8903],\n",
      "        [0.8916],\n",
      "        [0.8930],\n",
      "        [0.8942],\n",
      "        [0.8952],\n",
      "        [0.8961],\n",
      "        [0.8967],\n",
      "        [0.8970]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6085753440856934, dv_loss = tensor([2.9921], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7884094715118408, iters = 14581\n",
      "Epoch = 54\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8459807634353638\n",
      "Prob Vector = tensor([[0.8538],\n",
      "        [0.8526],\n",
      "        [0.8513],\n",
      "        [0.8501],\n",
      "        [0.8488],\n",
      "        [0.8476],\n",
      "        [0.8465],\n",
      "        [0.8454],\n",
      "        [0.8444],\n",
      "        [0.8434],\n",
      "        [0.8425],\n",
      "        [0.8417],\n",
      "        [0.8411],\n",
      "        [0.8405],\n",
      "        [0.8400]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6105319857597351, dv_loss = tensor([3.8349], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.779810905456543, iters = 14631\n",
      "Epoch = 54\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.894369900226593\n",
      "Prob Vector = tensor([[0.8866],\n",
      "        [0.8884],\n",
      "        [0.8899],\n",
      "        [0.8913],\n",
      "        [0.8924],\n",
      "        [0.8934],\n",
      "        [0.8945],\n",
      "        [0.8956],\n",
      "        [0.8964],\n",
      "        [0.8972],\n",
      "        [0.8977],\n",
      "        [0.8981],\n",
      "        [0.8981],\n",
      "        [0.8981],\n",
      "        [0.8978]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.4833926856517792, dv_loss = tensor([3.0113], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.9005162715911865, iters = 14681\n",
      "Epoch = 54\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7797954082489014\n",
      "Prob Vector = tensor([[0.8037],\n",
      "        [0.8032],\n",
      "        [0.7941],\n",
      "        [0.7868],\n",
      "        [0.7794],\n",
      "        [0.7765],\n",
      "        [0.7754],\n",
      "        [0.7743],\n",
      "        [0.7733],\n",
      "        [0.7723],\n",
      "        [0.7717],\n",
      "        [0.7714],\n",
      "        [0.7713],\n",
      "        [0.7716],\n",
      "        [0.7720]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.4265379905700684, dv_loss = tensor([17.8333], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.0381672382354736, iters = 14731\n",
      "Epoch = 54\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.824582576751709\n",
      "Prob Vector = tensor([[0.8191],\n",
      "        [0.8208],\n",
      "        [0.8219],\n",
      "        [0.8234],\n",
      "        [0.8246],\n",
      "        [0.8255],\n",
      "        [0.8260],\n",
      "        [0.8264],\n",
      "        [0.8266],\n",
      "        [0.8268],\n",
      "        [0.8269],\n",
      "        [0.8266],\n",
      "        [0.8258],\n",
      "        [0.8248],\n",
      "        [0.8236]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7695021629333496, dv_loss = tensor([3.6840], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6181907653808594, iters = 14781\n",
      "Epoch = 54\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7959503531455994\n",
      "Prob Vector = tensor([[0.8018],\n",
      "        [0.8004],\n",
      "        [0.7988],\n",
      "        [0.7971],\n",
      "        [0.7960],\n",
      "        [0.7951],\n",
      "        [0.7944],\n",
      "        [0.7940],\n",
      "        [0.7941],\n",
      "        [0.7942],\n",
      "        [0.7942],\n",
      "        [0.7943],\n",
      "        [0.7947],\n",
      "        [0.7949],\n",
      "        [0.7951]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7343413829803467, dv_loss = tensor([3.3648], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6474318504333496, iters = 14831\n",
      "###################################\n",
      "Epoch = 55\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8587157130241394\n",
      "Prob Vector = tensor([[0.8416],\n",
      "        [0.8451],\n",
      "        [0.8486],\n",
      "        [0.8518],\n",
      "        [0.8546],\n",
      "        [0.8571],\n",
      "        [0.8593],\n",
      "        [0.8607],\n",
      "        [0.8622],\n",
      "        [0.8637],\n",
      "        [0.8650],\n",
      "        [0.8662],\n",
      "        [0.8675],\n",
      "        [0.8684],\n",
      "        [0.8689]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6943862438201904, dv_loss = tensor([3.0913], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6849992275238037, iters = 14851\n",
      "Epoch = 55\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8209022879600525\n",
      "Prob Vector = tensor([[0.8291],\n",
      "        [0.8279],\n",
      "        [0.8265],\n",
      "        [0.8252],\n",
      "        [0.8239],\n",
      "        [0.8226],\n",
      "        [0.8214],\n",
      "        [0.8203],\n",
      "        [0.8192],\n",
      "        [0.8182],\n",
      "        [0.8173],\n",
      "        [0.8164],\n",
      "        [0.8158],\n",
      "        [0.8152],\n",
      "        [0.8147]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6730235815048218, dv_loss = tensor([3.9476], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7001482248306274, iters = 14901\n",
      "Epoch = 55\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8926758766174316\n",
      "Prob Vector = tensor([[0.8847],\n",
      "        [0.8865],\n",
      "        [0.8881],\n",
      "        [0.8894],\n",
      "        [0.8906],\n",
      "        [0.8916],\n",
      "        [0.8927],\n",
      "        [0.8939],\n",
      "        [0.8948],\n",
      "        [0.8957],\n",
      "        [0.8962],\n",
      "        [0.8966],\n",
      "        [0.8966],\n",
      "        [0.8966],\n",
      "        [0.8963]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5807709097862244, dv_loss = tensor([2.2895], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7862706184387207, iters = 14951\n",
      "Epoch = 55\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.8211157321929932\n",
      "Prob Vector = tensor([[0.8381],\n",
      "        [0.8389],\n",
      "        [0.8324],\n",
      "        [0.8195],\n",
      "        [0.8157],\n",
      "        [0.8211],\n",
      "        [0.8199],\n",
      "        [0.8188],\n",
      "        [0.8177],\n",
      "        [0.8167],\n",
      "        [0.8160],\n",
      "        [0.8156],\n",
      "        [0.8154],\n",
      "        [0.8154],\n",
      "        [0.8155]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.444704294204712, dv_loss = tensor([1.7393], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.07561278343200684, iters = 15001\n",
      "Epoch = 55\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8907275795936584\n",
      "Prob Vector = tensor([[0.8865],\n",
      "        [0.8880],\n",
      "        [0.8889],\n",
      "        [0.8901],\n",
      "        [0.8910],\n",
      "        [0.8916],\n",
      "        [0.8921],\n",
      "        [0.8927],\n",
      "        [0.8929],\n",
      "        [0.8930],\n",
      "        [0.8927],\n",
      "        [0.8921],\n",
      "        [0.8910],\n",
      "        [0.8899],\n",
      "        [0.8884]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7418911457061768, dv_loss = tensor([2.1260], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6253230571746826, iters = 15051\n",
      "Epoch = 55\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.833152711391449\n",
      "Prob Vector = tensor([[0.8400],\n",
      "        [0.8385],\n",
      "        [0.8370],\n",
      "        [0.8353],\n",
      "        [0.8341],\n",
      "        [0.8330],\n",
      "        [0.8321],\n",
      "        [0.8315],\n",
      "        [0.8312],\n",
      "        [0.8309],\n",
      "        [0.8307],\n",
      "        [0.8307],\n",
      "        [0.8308],\n",
      "        [0.8307],\n",
      "        [0.8308]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6300995349884033, dv_loss = tensor([3.7594], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7307803630828857, iters = 15101\n",
      "###################################\n",
      "Epoch = 56\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8935283422470093\n",
      "Prob Vector = tensor([[0.8780],\n",
      "        [0.8812],\n",
      "        [0.8844],\n",
      "        [0.8872],\n",
      "        [0.8896],\n",
      "        [0.8918],\n",
      "        [0.8939],\n",
      "        [0.8955],\n",
      "        [0.8969],\n",
      "        [0.8983],\n",
      "        [0.8995],\n",
      "        [0.9005],\n",
      "        [0.9015],\n",
      "        [0.9023],\n",
      "        [0.9025]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6755291223526001, dv_loss = tensor([2.6878], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.682973027229309, iters = 15121\n",
      "Epoch = 56\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8342227935791016\n",
      "Prob Vector = tensor([[0.8423],\n",
      "        [0.8411],\n",
      "        [0.8397],\n",
      "        [0.8385],\n",
      "        [0.8372],\n",
      "        [0.8359],\n",
      "        [0.8347],\n",
      "        [0.8336],\n",
      "        [0.8326],\n",
      "        [0.8316],\n",
      "        [0.8306],\n",
      "        [0.8298],\n",
      "        [0.8291],\n",
      "        [0.8286],\n",
      "        [0.8280]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9798606038093567, dv_loss = tensor([2.2728], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3735854625701904, iters = 15171\n",
      "Epoch = 56\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.9011259078979492\n",
      "Prob Vector = tensor([[0.8935],\n",
      "        [0.8953],\n",
      "        [0.8968],\n",
      "        [0.8981],\n",
      "        [0.8992],\n",
      "        [0.9001],\n",
      "        [0.9012],\n",
      "        [0.9023],\n",
      "        [0.9032],\n",
      "        [0.9040],\n",
      "        [0.9045],\n",
      "        [0.9048],\n",
      "        [0.9048],\n",
      "        [0.9047],\n",
      "        [0.9043]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5245786309242249, dv_loss = tensor([3.2918], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.8236873149871826, iters = 15221\n",
      "Epoch = 56\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7999945282936096\n",
      "Prob Vector = tensor([[0.8140],\n",
      "        [0.8155],\n",
      "        [0.8074],\n",
      "        [0.7979],\n",
      "        [0.7958],\n",
      "        [0.8006],\n",
      "        [0.7995],\n",
      "        [0.7983],\n",
      "        [0.7973],\n",
      "        [0.7963],\n",
      "        [0.7957],\n",
      "        [0.7954],\n",
      "        [0.7953],\n",
      "        [0.7954],\n",
      "        [0.7956]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.7457047700881958, dv_loss = tensor([1.4664], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6037181615829468, iters = 15271\n",
      "Epoch = 56\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8791911005973816\n",
      "Prob Vector = tensor([[0.8748],\n",
      "        [0.8764],\n",
      "        [0.8774],\n",
      "        [0.8785],\n",
      "        [0.8794],\n",
      "        [0.8801],\n",
      "        [0.8805],\n",
      "        [0.8810],\n",
      "        [0.8810],\n",
      "        [0.8811],\n",
      "        [0.8810],\n",
      "        [0.8805],\n",
      "        [0.8797],\n",
      "        [0.8787],\n",
      "        [0.8776]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8036493062973022, dv_loss = tensor([2.6121], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5426260232925415, iters = 15321\n",
      "Epoch = 56\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8205693960189819\n",
      "Prob Vector = tensor([[0.8270],\n",
      "        [0.8255],\n",
      "        [0.8239],\n",
      "        [0.8222],\n",
      "        [0.8210],\n",
      "        [0.8201],\n",
      "        [0.8193],\n",
      "        [0.8187],\n",
      "        [0.8185],\n",
      "        [0.8184],\n",
      "        [0.8183],\n",
      "        [0.8185],\n",
      "        [0.8188],\n",
      "        [0.8190],\n",
      "        [0.8192]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9085831642150879, dv_loss = tensor([2.8269], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4326152801513672, iters = 15371\n",
      "###################################\n",
      "Epoch = 57\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8805995583534241\n",
      "Prob Vector = tensor([[0.8651],\n",
      "        [0.8683],\n",
      "        [0.8715],\n",
      "        [0.8743],\n",
      "        [0.8767],\n",
      "        [0.8788],\n",
      "        [0.8808],\n",
      "        [0.8823],\n",
      "        [0.8837],\n",
      "        [0.8852],\n",
      "        [0.8865],\n",
      "        [0.8876],\n",
      "        [0.8887],\n",
      "        [0.8896],\n",
      "        [0.8900]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.859544575214386, dv_loss = tensor([2.2996], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4796786308288574, iters = 15391\n",
      "Epoch = 57\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.839690625667572\n",
      "Prob Vector = tensor([[0.8477],\n",
      "        [0.8465],\n",
      "        [0.8452],\n",
      "        [0.8440],\n",
      "        [0.8426],\n",
      "        [0.8414],\n",
      "        [0.8402],\n",
      "        [0.8391],\n",
      "        [0.8380],\n",
      "        [0.8370],\n",
      "        [0.8361],\n",
      "        [0.8353],\n",
      "        [0.8346],\n",
      "        [0.8341],\n",
      "        [0.8335]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6795232892036438, dv_loss = tensor([3.1999], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.654238224029541, iters = 15441\n",
      "Epoch = 57\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8983274698257446\n",
      "Prob Vector = tensor([[0.8905],\n",
      "        [0.8922],\n",
      "        [0.8938],\n",
      "        [0.8951],\n",
      "        [0.8963],\n",
      "        [0.8972],\n",
      "        [0.8983],\n",
      "        [0.8995],\n",
      "        [0.9003],\n",
      "        [0.9012],\n",
      "        [0.9019],\n",
      "        [0.9023],\n",
      "        [0.9022],\n",
      "        [0.9022],\n",
      "        [0.9019]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5309228301048279, dv_loss = tensor([2.3653], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.797196865081787, iters = 15491\n",
      "Epoch = 57\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7548730373382568\n",
      "Prob Vector = tensor([[0.7541],\n",
      "        [0.7560],\n",
      "        [0.7579],\n",
      "        [0.7488],\n",
      "        [0.7484],\n",
      "        [0.7589],\n",
      "        [0.7578],\n",
      "        [0.7568],\n",
      "        [0.7559],\n",
      "        [0.7550],\n",
      "        [0.7545],\n",
      "        [0.7545],\n",
      "        [0.7545],\n",
      "        [0.7550],\n",
      "        [0.7552]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.00256609916687, dv_loss = tensor([15.1779], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.6702172756195068, iters = 15541\n",
      "Epoch = 57\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7753998041152954\n",
      "Prob Vector = tensor([[0.7707],\n",
      "        [0.7723],\n",
      "        [0.7736],\n",
      "        [0.7753],\n",
      "        [0.7764],\n",
      "        [0.7772],\n",
      "        [0.7775],\n",
      "        [0.7780],\n",
      "        [0.7783],\n",
      "        [0.7783],\n",
      "        [0.7780],\n",
      "        [0.7768],\n",
      "        [0.7748],\n",
      "        [0.7731],\n",
      "        [0.7708]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.125081181526184, dv_loss = tensor([2.4388], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2073897123336792, iters = 15591\n",
      "Epoch = 57\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7770330309867859\n",
      "Prob Vector = tensor([[0.7820],\n",
      "        [0.7806],\n",
      "        [0.7791],\n",
      "        [0.7775],\n",
      "        [0.7767],\n",
      "        [0.7760],\n",
      "        [0.7757],\n",
      "        [0.7755],\n",
      "        [0.7759],\n",
      "        [0.7762],\n",
      "        [0.7760],\n",
      "        [0.7759],\n",
      "        [0.7761],\n",
      "        [0.7762],\n",
      "        [0.7762]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1866906881332397, dv_loss = tensor([3.3075], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1418331861495972, iters = 15641\n",
      "###################################\n",
      "Epoch = 58\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8411077260971069\n",
      "Prob Vector = tensor([[0.8239],\n",
      "        [0.8274],\n",
      "        [0.8308],\n",
      "        [0.8342],\n",
      "        [0.8369],\n",
      "        [0.8395],\n",
      "        [0.8416],\n",
      "        [0.8432],\n",
      "        [0.8446],\n",
      "        [0.8461],\n",
      "        [0.8475],\n",
      "        [0.8486],\n",
      "        [0.8499],\n",
      "        [0.8509],\n",
      "        [0.8515]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2299216985702515, dv_loss = tensor([2.1035], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0970653295516968, iters = 15661\n",
      "Epoch = 58\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8170779347419739\n",
      "Prob Vector = tensor([[0.8253],\n",
      "        [0.8241],\n",
      "        [0.8227],\n",
      "        [0.8215],\n",
      "        [0.8201],\n",
      "        [0.8188],\n",
      "        [0.8176],\n",
      "        [0.8165],\n",
      "        [0.8154],\n",
      "        [0.8143],\n",
      "        [0.8134],\n",
      "        [0.8125],\n",
      "        [0.8119],\n",
      "        [0.8113],\n",
      "        [0.8108]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.874788761138916, dv_loss = tensor([2.9367], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4472935199737549, iters = 15711\n",
      "Epoch = 58\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8871853351593018\n",
      "Prob Vector = tensor([[0.8788],\n",
      "        [0.8806],\n",
      "        [0.8822],\n",
      "        [0.8836],\n",
      "        [0.8848],\n",
      "        [0.8859],\n",
      "        [0.8870],\n",
      "        [0.8883],\n",
      "        [0.8892],\n",
      "        [0.8902],\n",
      "        [0.8910],\n",
      "        [0.8916],\n",
      "        [0.8916],\n",
      "        [0.8916],\n",
      "        [0.8913]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5254979729652405, dv_loss = tensor([2.8376], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.7916078567504883, iters = 15761\n",
      "Epoch = 58\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7799416184425354\n",
      "Prob Vector = tensor([[0.7754],\n",
      "        [0.7797],\n",
      "        [0.7810],\n",
      "        [0.7725],\n",
      "        [0.7721],\n",
      "        [0.7854],\n",
      "        [0.7843],\n",
      "        [0.7832],\n",
      "        [0.7822],\n",
      "        [0.7813],\n",
      "        [0.7807],\n",
      "        [0.7804],\n",
      "        [0.7803],\n",
      "        [0.7803],\n",
      "        [0.7802]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.2764337062835693, dv_loss = tensor([20.8587], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.9554245471954346, iters = 15811\n",
      "Epoch = 58\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7778160572052002\n",
      "Prob Vector = tensor([[0.7713],\n",
      "        [0.7734],\n",
      "        [0.7753],\n",
      "        [0.7773],\n",
      "        [0.7787],\n",
      "        [0.7798],\n",
      "        [0.7805],\n",
      "        [0.7812],\n",
      "        [0.7813],\n",
      "        [0.7812],\n",
      "        [0.7808],\n",
      "        [0.7795],\n",
      "        [0.7777],\n",
      "        [0.7758],\n",
      "        [0.7734]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.129188895225525, dv_loss = tensor([2.3775], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.192973256111145, iters = 15861\n",
      "Epoch = 58\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7702308297157288\n",
      "Prob Vector = tensor([[0.7760],\n",
      "        [0.7747],\n",
      "        [0.7734],\n",
      "        [0.7719],\n",
      "        [0.7711],\n",
      "        [0.7703],\n",
      "        [0.7698],\n",
      "        [0.7695],\n",
      "        [0.7695],\n",
      "        [0.7693],\n",
      "        [0.7686],\n",
      "        [0.7681],\n",
      "        [0.7677],\n",
      "        [0.7671],\n",
      "        [0.7664]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.360813856124878, dv_loss = tensor([2.4175], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9581353664398193, iters = 15911\n",
      "###################################\n",
      "Epoch = 59\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8400072455406189\n",
      "Prob Vector = tensor([[0.8210],\n",
      "        [0.8249],\n",
      "        [0.8289],\n",
      "        [0.8325],\n",
      "        [0.8355],\n",
      "        [0.8383],\n",
      "        [0.8406],\n",
      "        [0.8423],\n",
      "        [0.8440],\n",
      "        [0.8455],\n",
      "        [0.8469],\n",
      "        [0.8482],\n",
      "        [0.8497],\n",
      "        [0.8506],\n",
      "        [0.8513]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3115578889846802, dv_loss = tensor([1.4558], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0061246156692505, iters = 15931\n",
      "Epoch = 59\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8232278823852539\n",
      "Prob Vector = tensor([[0.8315],\n",
      "        [0.8303],\n",
      "        [0.8289],\n",
      "        [0.8277],\n",
      "        [0.8263],\n",
      "        [0.8249],\n",
      "        [0.8238],\n",
      "        [0.8226],\n",
      "        [0.8215],\n",
      "        [0.8205],\n",
      "        [0.8195],\n",
      "        [0.8187],\n",
      "        [0.8180],\n",
      "        [0.8174],\n",
      "        [0.8169]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8480094075202942, dv_loss = tensor([2.3458], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4651365280151367, iters = 15981\n",
      "Epoch = 59\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.892807126045227\n",
      "Prob Vector = tensor([[0.8844],\n",
      "        [0.8863],\n",
      "        [0.8879],\n",
      "        [0.8894],\n",
      "        [0.8906],\n",
      "        [0.8916],\n",
      "        [0.8927],\n",
      "        [0.8939],\n",
      "        [0.8949],\n",
      "        [0.8958],\n",
      "        [0.8966],\n",
      "        [0.8971],\n",
      "        [0.8971],\n",
      "        [0.8971],\n",
      "        [0.8967]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8962894678115845, dv_loss = tensor([2.2719], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.412939190864563, iters = 16031\n",
      "Epoch = 59\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7776262164115906\n",
      "Prob Vector = tensor([[0.7634],\n",
      "        [0.7712],\n",
      "        [0.7761],\n",
      "        [0.7694],\n",
      "        [0.7685],\n",
      "        [0.7855],\n",
      "        [0.7843],\n",
      "        [0.7832],\n",
      "        [0.7822],\n",
      "        [0.7811],\n",
      "        [0.7804],\n",
      "        [0.7801],\n",
      "        [0.7798],\n",
      "        [0.7798],\n",
      "        [0.7795]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.767989158630371, dv_loss = tensor([8.4857], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.45485401153564453, iters = 16081\n",
      "Epoch = 59\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8302212357521057\n",
      "Prob Vector = tensor([[0.8243],\n",
      "        [0.8263],\n",
      "        [0.8280],\n",
      "        [0.8300],\n",
      "        [0.8313],\n",
      "        [0.8323],\n",
      "        [0.8328],\n",
      "        [0.8334],\n",
      "        [0.8336],\n",
      "        [0.8335],\n",
      "        [0.8329],\n",
      "        [0.8317],\n",
      "        [0.8299],\n",
      "        [0.8279],\n",
      "        [0.8254]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8329616785049438, dv_loss = tensor([3.2726], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4795750379562378, iters = 16131\n",
      "Epoch = 59\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8071414232254028\n",
      "Prob Vector = tensor([[0.8136],\n",
      "        [0.8122],\n",
      "        [0.8107],\n",
      "        [0.8091],\n",
      "        [0.8082],\n",
      "        [0.8073],\n",
      "        [0.8067],\n",
      "        [0.8063],\n",
      "        [0.8062],\n",
      "        [0.8058],\n",
      "        [0.8052],\n",
      "        [0.8047],\n",
      "        [0.8043],\n",
      "        [0.8036],\n",
      "        [0.8030]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3414372205734253, dv_loss = tensor([2.2375], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9674950838088989, iters = 16181\n",
      "###################################\n",
      "Epoch = 60\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8667628169059753\n",
      "Prob Vector = tensor([[0.8476],\n",
      "        [0.8515],\n",
      "        [0.8554],\n",
      "        [0.8589],\n",
      "        [0.8619],\n",
      "        [0.8646],\n",
      "        [0.8669],\n",
      "        [0.8687],\n",
      "        [0.8706],\n",
      "        [0.8723],\n",
      "        [0.8739],\n",
      "        [0.8754],\n",
      "        [0.8768],\n",
      "        [0.8780],\n",
      "        [0.8788]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1101655960083008, dv_loss = tensor([2.2198], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1973586082458496, iters = 16201\n",
      "Epoch = 60\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.836079478263855\n",
      "Prob Vector = tensor([[0.8441],\n",
      "        [0.8429],\n",
      "        [0.8415],\n",
      "        [0.8403],\n",
      "        [0.8390],\n",
      "        [0.8377],\n",
      "        [0.8366],\n",
      "        [0.8355],\n",
      "        [0.8344],\n",
      "        [0.8334],\n",
      "        [0.8325],\n",
      "        [0.8317],\n",
      "        [0.8310],\n",
      "        [0.8305],\n",
      "        [0.8299]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8428985476493835, dv_loss = tensor([3.1142], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4601759910583496, iters = 16251\n",
      "Epoch = 60\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8977829217910767\n",
      "Prob Vector = tensor([[0.8892],\n",
      "        [0.8911],\n",
      "        [0.8928],\n",
      "        [0.8942],\n",
      "        [0.8954],\n",
      "        [0.8965],\n",
      "        [0.8977],\n",
      "        [0.8990],\n",
      "        [0.8999],\n",
      "        [0.9009],\n",
      "        [0.9017],\n",
      "        [0.9022],\n",
      "        [0.9022],\n",
      "        [0.9021],\n",
      "        [0.9018]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6939365267753601, dv_loss = tensor([1.8063], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.604217767715454, iters = 16301\n",
      "Epoch = 60\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7186839580535889\n",
      "Prob Vector = tensor([[0.6795],\n",
      "        [0.6923],\n",
      "        [0.7075],\n",
      "        [0.7079],\n",
      "        [0.7089],\n",
      "        [0.7313],\n",
      "        [0.7302],\n",
      "        [0.7293],\n",
      "        [0.7285],\n",
      "        [0.7278],\n",
      "        [0.7273],\n",
      "        [0.7274],\n",
      "        [0.7273],\n",
      "        [0.7276],\n",
      "        [0.7275]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.17710542678833, dv_loss = tensor([45.4492], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.872788906097412, iters = 16351\n",
      "Epoch = 60\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.5261155962944031\n",
      "Prob Vector = tensor([[0.5209],\n",
      "        [0.5233],\n",
      "        [0.5253],\n",
      "        [0.5270],\n",
      "        [0.5279],\n",
      "        [0.5289],\n",
      "        [0.5291],\n",
      "        [0.5296],\n",
      "        [0.5294],\n",
      "        [0.5288],\n",
      "        [0.5278],\n",
      "        [0.5259],\n",
      "        [0.5243],\n",
      "        [0.5229],\n",
      "        [0.5206]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8136353492736816, dv_loss = tensor([2.5820], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.49524927139282227, iters = 16401\n",
      "Epoch = 60\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.5289534330368042\n",
      "Prob Vector = tensor([[0.5287],\n",
      "        [0.5287],\n",
      "        [0.5289],\n",
      "        [0.5287],\n",
      "        [0.5294],\n",
      "        [0.5297],\n",
      "        [0.5301],\n",
      "        [0.5305],\n",
      "        [0.5309],\n",
      "        [0.5309],\n",
      "        [0.5302],\n",
      "        [0.5292],\n",
      "        [0.5278],\n",
      "        [0.5262],\n",
      "        [0.5243]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.054630756378174, dv_loss = tensor([1.0732], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2531116008758545, iters = 16451\n",
      "###################################\n",
      "Epoch = 61\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.540323793888092\n",
      "Prob Vector = tensor([[0.5243],\n",
      "        [0.5264],\n",
      "        [0.5290],\n",
      "        [0.5315],\n",
      "        [0.5337],\n",
      "        [0.5359],\n",
      "        [0.5378],\n",
      "        [0.5396],\n",
      "        [0.5419],\n",
      "        [0.5446],\n",
      "        [0.5474],\n",
      "        [0.5504],\n",
      "        [0.5525],\n",
      "        [0.5542],\n",
      "        [0.5555]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8032419681549072, dv_loss = tensor([2.0853], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5039935111999512, iters = 16471\n",
      "Epoch = 61\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5669512748718262\n",
      "Prob Vector = tensor([[0.5699],\n",
      "        [0.5695],\n",
      "        [0.5688],\n",
      "        [0.5685],\n",
      "        [0.5679],\n",
      "        [0.5674],\n",
      "        [0.5671],\n",
      "        [0.5667],\n",
      "        [0.5663],\n",
      "        [0.5660],\n",
      "        [0.5657],\n",
      "        [0.5654],\n",
      "        [0.5653],\n",
      "        [0.5650],\n",
      "        [0.5647]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4202051162719727, dv_loss = tensor([2.3008], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.885427713394165, iters = 16521\n",
      "Epoch = 61\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.6563456654548645\n",
      "Prob Vector = tensor([[0.6420],\n",
      "        [0.6442],\n",
      "        [0.6462],\n",
      "        [0.6484],\n",
      "        [0.6502],\n",
      "        [0.6525],\n",
      "        [0.6550],\n",
      "        [0.6582],\n",
      "        [0.6607],\n",
      "        [0.6626],\n",
      "        [0.6642],\n",
      "        [0.6651],\n",
      "        [0.6654],\n",
      "        [0.6656],\n",
      "        [0.6648]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1291780471801758, dv_loss = tensor([4.0374], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1731719970703125, iters = 16571\n",
      "Epoch = 61\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.4805828332901001\n",
      "Prob Vector = tensor([[0.4421],\n",
      "        [0.4471],\n",
      "        [0.4596],\n",
      "        [0.4602],\n",
      "        [0.4760],\n",
      "        [0.4913],\n",
      "        [0.4913],\n",
      "        [0.4914],\n",
      "        [0.4915],\n",
      "        [0.4916],\n",
      "        [0.4919],\n",
      "        [0.4926],\n",
      "        [0.4933],\n",
      "        [0.4943],\n",
      "        [0.4945]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.4031453132629395, dv_loss = tensor([7.9219], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.095750570297241, iters = 16621\n",
      "Epoch = 61\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.4010654091835022\n",
      "Prob Vector = tensor([[0.4013],\n",
      "        [0.4015],\n",
      "        [0.4016],\n",
      "        [0.4018],\n",
      "        [0.4017],\n",
      "        [0.4018],\n",
      "        [0.4017],\n",
      "        [0.4016],\n",
      "        [0.4012],\n",
      "        [0.4010],\n",
      "        [0.4009],\n",
      "        [0.4004],\n",
      "        [0.4000],\n",
      "        [0.3999],\n",
      "        [0.3996]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6420379877090454, dv_loss = tensor([2.8028], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6685305833816528, iters = 16671\n",
      "Epoch = 61\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.4282172918319702\n",
      "Prob Vector = tensor([[0.4257],\n",
      "        [0.4261],\n",
      "        [0.4267],\n",
      "        [0.4271],\n",
      "        [0.4277],\n",
      "        [0.4282],\n",
      "        [0.4288],\n",
      "        [0.4292],\n",
      "        [0.4296],\n",
      "        [0.4298],\n",
      "        [0.4297],\n",
      "        [0.4294],\n",
      "        [0.4290],\n",
      "        [0.4286],\n",
      "        [0.4276]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.202026844024658, dv_loss = tensor([0.4926], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.10770106315612793, iters = 16721\n",
      "###################################\n",
      "Epoch = 62\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.4106428623199463\n",
      "Prob Vector = tensor([[0.4099],\n",
      "        [0.4096],\n",
      "        [0.4096],\n",
      "        [0.4095],\n",
      "        [0.4096],\n",
      "        [0.4097],\n",
      "        [0.4099],\n",
      "        [0.4100],\n",
      "        [0.4102],\n",
      "        [0.4106],\n",
      "        [0.4113],\n",
      "        [0.4120],\n",
      "        [0.4124],\n",
      "        [0.4128],\n",
      "        [0.4127]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.0744407176971436, dv_loss = tensor([0.1385], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2348463535308838, iters = 16741\n",
      "Epoch = 62\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.4257521331310272\n",
      "Prob Vector = tensor([[0.4237],\n",
      "        [0.4240],\n",
      "        [0.4241],\n",
      "        [0.4244],\n",
      "        [0.4247],\n",
      "        [0.4249],\n",
      "        [0.4254],\n",
      "        [0.4258],\n",
      "        [0.4261],\n",
      "        [0.4266],\n",
      "        [0.4269],\n",
      "        [0.4271],\n",
      "        [0.4274],\n",
      "        [0.4276],\n",
      "        [0.4277]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3502171039581299, dv_loss = tensor([2.2018], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9588179588317871, iters = 16791\n",
      "Epoch = 62\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.4369031488895416\n",
      "Prob Vector = tensor([[0.4357],\n",
      "        [0.4359],\n",
      "        [0.4358],\n",
      "        [0.4359],\n",
      "        [0.4361],\n",
      "        [0.4367],\n",
      "        [0.4372],\n",
      "        [0.4379],\n",
      "        [0.4380],\n",
      "        [0.4384],\n",
      "        [0.4384],\n",
      "        [0.4381],\n",
      "        [0.4373],\n",
      "        [0.4365],\n",
      "        [0.4356]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9239203929901123, dv_loss = tensor([4.6716], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3816983699798584, iters = 16841\n",
      "Epoch = 62\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.41518211364746094\n",
      "Prob Vector = tensor([[0.3813],\n",
      "        [0.3849],\n",
      "        [0.3935],\n",
      "        [0.3968],\n",
      "        [0.4115],\n",
      "        [0.4242],\n",
      "        [0.4245],\n",
      "        [0.4248],\n",
      "        [0.4252],\n",
      "        [0.4256],\n",
      "        [0.4260],\n",
      "        [0.4266],\n",
      "        [0.4271],\n",
      "        [0.4277],\n",
      "        [0.4279]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.2999725341796875, dv_loss = tensor([4.9637], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.9909167289733887, iters = 16891\n",
      "Epoch = 62\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3423948287963867\n",
      "Prob Vector = tensor([[0.3441],\n",
      "        [0.3440],\n",
      "        [0.3437],\n",
      "        [0.3434],\n",
      "        [0.3429],\n",
      "        [0.3427],\n",
      "        [0.3424],\n",
      "        [0.3422],\n",
      "        [0.3419],\n",
      "        [0.3419],\n",
      "        [0.3418],\n",
      "        [0.3414],\n",
      "        [0.3412],\n",
      "        [0.3412],\n",
      "        [0.3411]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4250434637069702, dv_loss = tensor([3.5013], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8870812654495239, iters = 16941\n",
      "Epoch = 62\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.38674020767211914\n",
      "Prob Vector = tensor([[0.3832],\n",
      "        [0.3837],\n",
      "        [0.3845],\n",
      "        [0.3852],\n",
      "        [0.3860],\n",
      "        [0.3866],\n",
      "        [0.3872],\n",
      "        [0.3877],\n",
      "        [0.3883],\n",
      "        [0.3886],\n",
      "        [0.3887],\n",
      "        [0.3884],\n",
      "        [0.3881],\n",
      "        [0.3878],\n",
      "        [0.3872]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8026930093765259, dv_loss = tensor([1.8686], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5080291032791138, iters = 16991\n",
      "###################################\n",
      "Epoch = 63\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.35862359404563904\n",
      "Prob Vector = tensor([[0.3611],\n",
      "        [0.3603],\n",
      "        [0.3595],\n",
      "        [0.3589],\n",
      "        [0.3585],\n",
      "        [0.3583],\n",
      "        [0.3580],\n",
      "        [0.3580],\n",
      "        [0.3582],\n",
      "        [0.3580],\n",
      "        [0.3581],\n",
      "        [0.3584],\n",
      "        [0.3583],\n",
      "        [0.3581],\n",
      "        [0.3578]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9578970670700073, dv_loss = tensor([1.8067], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.352164626121521, iters = 17011\n",
      "Epoch = 63\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.39364364743232727\n",
      "Prob Vector = tensor([[0.3904],\n",
      "        [0.3910],\n",
      "        [0.3914],\n",
      "        [0.3918],\n",
      "        [0.3923],\n",
      "        [0.3928],\n",
      "        [0.3933],\n",
      "        [0.3938],\n",
      "        [0.3943],\n",
      "        [0.3948],\n",
      "        [0.3952],\n",
      "        [0.3955],\n",
      "        [0.3959],\n",
      "        [0.3960],\n",
      "        [0.3962]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5026724338531494, dv_loss = tensor([3.4202], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.805919885635376, iters = 17061\n",
      "Epoch = 63\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.3828127980232239\n",
      "Prob Vector = tensor([[0.3838],\n",
      "        [0.3836],\n",
      "        [0.3832],\n",
      "        [0.3830],\n",
      "        [0.3829],\n",
      "        [0.3831],\n",
      "        [0.3831],\n",
      "        [0.3833],\n",
      "        [0.3832],\n",
      "        [0.3833],\n",
      "        [0.3830],\n",
      "        [0.3825],\n",
      "        [0.3819],\n",
      "        [0.3814],\n",
      "        [0.3810]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8590153455734253, dv_loss = tensor([3.5735], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4463752508163452, iters = 17111\n",
      "Epoch = 63\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3811129331588745\n",
      "Prob Vector = tensor([[0.3470],\n",
      "        [0.3506],\n",
      "        [0.3585],\n",
      "        [0.3634],\n",
      "        [0.3764],\n",
      "        [0.3897],\n",
      "        [0.3904],\n",
      "        [0.3908],\n",
      "        [0.3913],\n",
      "        [0.3918],\n",
      "        [0.3923],\n",
      "        [0.3929],\n",
      "        [0.3934],\n",
      "        [0.3939],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.059715509414673, dv_loss = tensor([4.0070], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.7518913745880127, iters = 17161\n",
      "Epoch = 63\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3380734324455261\n",
      "Prob Vector = tensor([[0.3405],\n",
      "        [0.3405],\n",
      "        [0.3402],\n",
      "        [0.3398],\n",
      "        [0.3392],\n",
      "        [0.3388],\n",
      "        [0.3383],\n",
      "        [0.3379],\n",
      "        [0.3373],\n",
      "        [0.3370],\n",
      "        [0.3368],\n",
      "        [0.3364],\n",
      "        [0.3361],\n",
      "        [0.3361],\n",
      "        [0.3361]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.052546739578247, dv_loss = tensor([4.9867], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2554264068603516, iters = 17211\n",
      "Epoch = 63\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.39771443605422974\n",
      "Prob Vector = tensor([[0.3946],\n",
      "        [0.3951],\n",
      "        [0.3959],\n",
      "        [0.3965],\n",
      "        [0.3972],\n",
      "        [0.3977],\n",
      "        [0.3983],\n",
      "        [0.3989],\n",
      "        [0.3991],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3990],\n",
      "        [0.3987],\n",
      "        [0.3984],\n",
      "        [0.3978]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0543328523635864, dv_loss = tensor([3.0102], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2501219511032104, iters = 17261\n",
      "###################################\n",
      "Epoch = 64\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.38010865449905396\n",
      "Prob Vector = tensor([[0.3813],\n",
      "        [0.3809],\n",
      "        [0.3806],\n",
      "        [0.3803],\n",
      "        [0.3801],\n",
      "        [0.3800],\n",
      "        [0.3799],\n",
      "        [0.3798],\n",
      "        [0.3798],\n",
      "        [0.3798],\n",
      "        [0.3798],\n",
      "        [0.3800],\n",
      "        [0.3801],\n",
      "        [0.3798],\n",
      "        [0.3794]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0909206867218018, dv_loss = tensor([4.5095], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2119848728179932, iters = 17281\n",
      "Epoch = 64\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.42425382137298584\n",
      "Prob Vector = tensor([[0.4220],\n",
      "        [0.4224],\n",
      "        [0.4226],\n",
      "        [0.4229],\n",
      "        [0.4232],\n",
      "        [0.4236],\n",
      "        [0.4239],\n",
      "        [0.4243],\n",
      "        [0.4247],\n",
      "        [0.4251],\n",
      "        [0.4255],\n",
      "        [0.4257],\n",
      "        [0.4259],\n",
      "        [0.4260],\n",
      "        [0.4261]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1775100231170654, dv_loss = tensor([3.2323], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.121962308883667, iters = 17331\n",
      "Epoch = 64\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.43158793449401855\n",
      "Prob Vector = tensor([[0.4314],\n",
      "        [0.4316],\n",
      "        [0.4315],\n",
      "        [0.4314],\n",
      "        [0.4315],\n",
      "        [0.4318],\n",
      "        [0.4321],\n",
      "        [0.4324],\n",
      "        [0.4323],\n",
      "        [0.4324],\n",
      "        [0.4321],\n",
      "        [0.4318],\n",
      "        [0.4311],\n",
      "        [0.4305],\n",
      "        [0.4297]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.180214762687683, dv_loss = tensor([4.4382], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.115942120552063, iters = 17381\n",
      "Epoch = 64\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.40935754776000977\n",
      "Prob Vector = tensor([[0.3679],\n",
      "        [0.3732],\n",
      "        [0.3834],\n",
      "        [0.3892],\n",
      "        [0.4001],\n",
      "        [0.4211],\n",
      "        [0.4215],\n",
      "        [0.4218],\n",
      "        [0.4222],\n",
      "        [0.4226],\n",
      "        [0.4229],\n",
      "        [0.4233],\n",
      "        [0.4235],\n",
      "        [0.4239],\n",
      "        [0.4238]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.9245002269744873, dv_loss = tensor([6.7033], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.6250386238098145, iters = 17431\n",
      "Epoch = 64\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3465230464935303\n",
      "Prob Vector = tensor([[0.3491],\n",
      "        [0.3492],\n",
      "        [0.3490],\n",
      "        [0.3486],\n",
      "        [0.3480],\n",
      "        [0.3476],\n",
      "        [0.3471],\n",
      "        [0.3465],\n",
      "        [0.3459],\n",
      "        [0.3454],\n",
      "        [0.3451],\n",
      "        [0.3446],\n",
      "        [0.3441],\n",
      "        [0.3439],\n",
      "        [0.3436]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3124126195907593, dv_loss = tensor([4.5266], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9887262582778931, iters = 17481\n",
      "Epoch = 64\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3973577916622162\n",
      "Prob Vector = tensor([[0.3943],\n",
      "        [0.3948],\n",
      "        [0.3956],\n",
      "        [0.3963],\n",
      "        [0.3971],\n",
      "        [0.3976],\n",
      "        [0.3982],\n",
      "        [0.3987],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3988],\n",
      "        [0.3983],\n",
      "        [0.3980],\n",
      "        [0.3977],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3067686557769775, dv_loss = tensor([3.5872], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9918439388275146, iters = 17531\n",
      "###################################\n",
      "Epoch = 65\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.37978002429008484\n",
      "Prob Vector = tensor([[0.3795],\n",
      "        [0.3793],\n",
      "        [0.3792],\n",
      "        [0.3790],\n",
      "        [0.3789],\n",
      "        [0.3790],\n",
      "        [0.3792],\n",
      "        [0.3793],\n",
      "        [0.3797],\n",
      "        [0.3800],\n",
      "        [0.3805],\n",
      "        [0.3810],\n",
      "        [0.3810],\n",
      "        [0.3808],\n",
      "        [0.3805]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3340446949005127, dv_loss = tensor([2.9865], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9631645679473877, iters = 17551\n",
      "Epoch = 65\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.4243927299976349\n",
      "Prob Vector = tensor([[0.4220],\n",
      "        [0.4224],\n",
      "        [0.4226],\n",
      "        [0.4230],\n",
      "        [0.4233],\n",
      "        [0.4237],\n",
      "        [0.4241],\n",
      "        [0.4245],\n",
      "        [0.4248],\n",
      "        [0.4253],\n",
      "        [0.4257],\n",
      "        [0.4259],\n",
      "        [0.4262],\n",
      "        [0.4263],\n",
      "        [0.4264]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0029376745224, dv_loss = tensor([4.4605], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2916594743728638, iters = 17601\n",
      "Epoch = 65\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.4376406669616699\n",
      "Prob Vector = tensor([[0.4376],\n",
      "        [0.4377],\n",
      "        [0.4378],\n",
      "        [0.4378],\n",
      "        [0.4379],\n",
      "        [0.4382],\n",
      "        [0.4383],\n",
      "        [0.4385],\n",
      "        [0.4383],\n",
      "        [0.4383],\n",
      "        [0.4380],\n",
      "        [0.4376],\n",
      "        [0.4370],\n",
      "        [0.4362],\n",
      "        [0.4353]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8005739450454712, dv_loss = tensor([3.3517], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4901264905929565, iters = 17651\n",
      "Epoch = 65\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.40892186760902405\n",
      "Prob Vector = tensor([[0.3632],\n",
      "        [0.3694],\n",
      "        [0.3810],\n",
      "        [0.3878],\n",
      "        [0.3980],\n",
      "        [0.4214],\n",
      "        [0.4218],\n",
      "        [0.4222],\n",
      "        [0.4227],\n",
      "        [0.4231],\n",
      "        [0.4236],\n",
      "        [0.4242],\n",
      "        [0.4246],\n",
      "        [0.4252],\n",
      "        [0.4255]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.402865886688232, dv_loss = tensor([10.3119], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.108865261077881, iters = 17701\n",
      "Epoch = 65\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3116278350353241\n",
      "Prob Vector = tensor([[0.3134],\n",
      "        [0.3133],\n",
      "        [0.3130],\n",
      "        [0.3128],\n",
      "        [0.3122],\n",
      "        [0.3120],\n",
      "        [0.3115],\n",
      "        [0.3111],\n",
      "        [0.3108],\n",
      "        [0.3106],\n",
      "        [0.3107],\n",
      "        [0.3105],\n",
      "        [0.3105],\n",
      "        [0.3108],\n",
      "        [0.3112]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.692370891571045, dv_loss = tensor([2.0873], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6056733131408691, iters = 17751\n",
      "Epoch = 65\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.35919463634490967\n",
      "Prob Vector = tensor([[0.3546],\n",
      "        [0.3554],\n",
      "        [0.3564],\n",
      "        [0.3574],\n",
      "        [0.3585],\n",
      "        [0.3593],\n",
      "        [0.3601],\n",
      "        [0.3608],\n",
      "        [0.3612],\n",
      "        [0.3614],\n",
      "        [0.3612],\n",
      "        [0.3608],\n",
      "        [0.3606],\n",
      "        [0.3603],\n",
      "        [0.3598]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.928412914276123, dv_loss = tensor([1.4137], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3682260513305664, iters = 17801\n",
      "###################################\n",
      "Epoch = 66\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.3242761194705963\n",
      "Prob Vector = tensor([[0.3285],\n",
      "        [0.3274],\n",
      "        [0.3263],\n",
      "        [0.3255],\n",
      "        [0.3247],\n",
      "        [0.3240],\n",
      "        [0.3234],\n",
      "        [0.3230],\n",
      "        [0.3231],\n",
      "        [0.3230],\n",
      "        [0.3232],\n",
      "        [0.3233],\n",
      "        [0.3231],\n",
      "        [0.3229],\n",
      "        [0.3226]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.555054783821106, dv_loss = tensor([2.5020], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.740601658821106, iters = 17821\n",
      "Epoch = 66\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.3688907325267792\n",
      "Prob Vector = tensor([[0.3645],\n",
      "        [0.3652],\n",
      "        [0.3658],\n",
      "        [0.3665],\n",
      "        [0.3671],\n",
      "        [0.3678],\n",
      "        [0.3685],\n",
      "        [0.3692],\n",
      "        [0.3699],\n",
      "        [0.3704],\n",
      "        [0.3710],\n",
      "        [0.3714],\n",
      "        [0.3718],\n",
      "        [0.3719],\n",
      "        [0.3723]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4319370985031128, dv_loss = tensor([4.9042], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8622549772262573, iters = 17871\n",
      "Epoch = 66\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.35954833030700684\n",
      "Prob Vector = tensor([[0.3611],\n",
      "        [0.3610],\n",
      "        [0.3606],\n",
      "        [0.3604],\n",
      "        [0.3604],\n",
      "        [0.3606],\n",
      "        [0.3603],\n",
      "        [0.3601],\n",
      "        [0.3597],\n",
      "        [0.3596],\n",
      "        [0.3593],\n",
      "        [0.3588],\n",
      "        [0.3578],\n",
      "        [0.3570],\n",
      "        [0.3564]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8711439967155457, dv_loss = tensor([9.0941], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4197940826416016, iters = 17921\n",
      "Epoch = 66\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3731977641582489\n",
      "Prob Vector = tensor([[0.3268],\n",
      "        [0.3340],\n",
      "        [0.3428],\n",
      "        [0.3545],\n",
      "        [0.3644],\n",
      "        [0.3849],\n",
      "        [0.3855],\n",
      "        [0.3860],\n",
      "        [0.3867],\n",
      "        [0.3873],\n",
      "        [0.3879],\n",
      "        [0.3885],\n",
      "        [0.3891],\n",
      "        [0.3897],\n",
      "        [0.3900]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6347811222076416, dv_loss = tensor([1.2757], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6567206382751465, iters = 17971\n",
      "Epoch = 66\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3706934154033661\n",
      "Prob Vector = tensor([[0.3744],\n",
      "        [0.3746],\n",
      "        [0.3744],\n",
      "        [0.3738],\n",
      "        [0.3730],\n",
      "        [0.3724],\n",
      "        [0.3717],\n",
      "        [0.3709],\n",
      "        [0.3700],\n",
      "        [0.3692],\n",
      "        [0.3686],\n",
      "        [0.3678],\n",
      "        [0.3670],\n",
      "        [0.3665],\n",
      "        [0.3661]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4321751594543457, dv_loss = tensor([2.6883], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.856940507888794, iters = 18021\n",
      "Epoch = 66\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.4368848204612732\n",
      "Prob Vector = tensor([[0.4340],\n",
      "        [0.4344],\n",
      "        [0.4351],\n",
      "        [0.4355],\n",
      "        [0.4362],\n",
      "        [0.4367],\n",
      "        [0.4373],\n",
      "        [0.4379],\n",
      "        [0.4383],\n",
      "        [0.4385],\n",
      "        [0.4385],\n",
      "        [0.4383],\n",
      "        [0.4381],\n",
      "        [0.4376],\n",
      "        [0.4370]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9140797257423401, dv_loss = tensor([2.3178], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.371225357055664, iters = 18071\n",
      "###################################\n",
      "Epoch = 67\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.437845379114151\n",
      "Prob Vector = tensor([[0.4332],\n",
      "        [0.4337],\n",
      "        [0.4345],\n",
      "        [0.4353],\n",
      "        [0.4360],\n",
      "        [0.4368],\n",
      "        [0.4375],\n",
      "        [0.4382],\n",
      "        [0.4390],\n",
      "        [0.4395],\n",
      "        [0.4402],\n",
      "        [0.4410],\n",
      "        [0.4412],\n",
      "        [0.4410],\n",
      "        [0.4406]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0216819047927856, dv_loss = tensor([4.9613], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2620974779129028, iters = 18091\n",
      "Epoch = 67\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5328969359397888\n",
      "Prob Vector = tensor([[0.5341],\n",
      "        [0.5339],\n",
      "        [0.5336],\n",
      "        [0.5335],\n",
      "        [0.5332],\n",
      "        [0.5329],\n",
      "        [0.5328],\n",
      "        [0.5327],\n",
      "        [0.5326],\n",
      "        [0.5325],\n",
      "        [0.5325],\n",
      "        [0.5324],\n",
      "        [0.5324],\n",
      "        [0.5322],\n",
      "        [0.5323]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8213753700256348, dv_loss = tensor([6.1290], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4582951068878174, iters = 18141\n",
      "Epoch = 67\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.7027295231819153\n",
      "Prob Vector = tensor([[0.6941],\n",
      "        [0.6957],\n",
      "        [0.6967],\n",
      "        [0.6980],\n",
      "        [0.6988],\n",
      "        [0.7000],\n",
      "        [0.7014],\n",
      "        [0.7034],\n",
      "        [0.7054],\n",
      "        [0.7070],\n",
      "        [0.7080],\n",
      "        [0.7087],\n",
      "        [0.7088],\n",
      "        [0.7083],\n",
      "        [0.7067]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8251575231552124, dv_loss = tensor([4.7588], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4502683877944946, iters = 18191\n",
      "Epoch = 67\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.5260834097862244\n",
      "Prob Vector = tensor([[0.4352],\n",
      "        [0.4551],\n",
      "        [0.4725],\n",
      "        [0.4882],\n",
      "        [0.5146],\n",
      "        [0.5516],\n",
      "        [0.5513],\n",
      "        [0.5513],\n",
      "        [0.5516],\n",
      "        [0.5518],\n",
      "        [0.5524],\n",
      "        [0.5531],\n",
      "        [0.5537],\n",
      "        [0.5545],\n",
      "        [0.5544]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.348977088928223, dv_loss = tensor([12.9070], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.07081937789917, iters = 18241\n",
      "Epoch = 67\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.36512261629104614\n",
      "Prob Vector = tensor([[0.3668],\n",
      "        [0.3673],\n",
      "        [0.3672],\n",
      "        [0.3669],\n",
      "        [0.3664],\n",
      "        [0.3662],\n",
      "        [0.3657],\n",
      "        [0.3654],\n",
      "        [0.3649],\n",
      "        [0.3645],\n",
      "        [0.3642],\n",
      "        [0.3634],\n",
      "        [0.3628],\n",
      "        [0.3626],\n",
      "        [0.3625]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.392129421234131, dv_loss = tensor([0.4010], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.10974478721618652, iters = 18291\n",
      "Epoch = 67\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.38906726241111755\n",
      "Prob Vector = tensor([[0.3845],\n",
      "        [0.3853],\n",
      "        [0.3863],\n",
      "        [0.3871],\n",
      "        [0.3881],\n",
      "        [0.3889],\n",
      "        [0.3896],\n",
      "        [0.3903],\n",
      "        [0.3908],\n",
      "        [0.3912],\n",
      "        [0.3913],\n",
      "        [0.3910],\n",
      "        [0.3908],\n",
      "        [0.3906],\n",
      "        [0.3902]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.212933301925659, dv_loss = tensor([0.2967], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.06939268112182617, iters = 18341\n",
      "###################################\n",
      "Epoch = 68\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.35792574286460876\n",
      "Prob Vector = tensor([[0.3579],\n",
      "        [0.3575],\n",
      "        [0.3573],\n",
      "        [0.3572],\n",
      "        [0.3573],\n",
      "        [0.3574],\n",
      "        [0.3574],\n",
      "        [0.3576],\n",
      "        [0.3582],\n",
      "        [0.3586],\n",
      "        [0.3589],\n",
      "        [0.3591],\n",
      "        [0.3586],\n",
      "        [0.3581],\n",
      "        [0.3577]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6543400287628174, dv_loss = tensor([1.6118], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6271753311157227, iters = 18361\n",
      "Epoch = 68\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.39967411756515503\n",
      "Prob Vector = tensor([[0.3959],\n",
      "        [0.3966],\n",
      "        [0.3971],\n",
      "        [0.3977],\n",
      "        [0.3982],\n",
      "        [0.3989],\n",
      "        [0.3994],\n",
      "        [0.4001],\n",
      "        [0.4005],\n",
      "        [0.4010],\n",
      "        [0.4014],\n",
      "        [0.4017],\n",
      "        [0.4020],\n",
      "        [0.4022],\n",
      "        [0.4025]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.211021900177002, dv_loss = tensor([3.2079], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0690996646881104, iters = 18411\n",
      "Epoch = 68\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.40052279829978943\n",
      "Prob Vector = tensor([[0.3988],\n",
      "        [0.3994],\n",
      "        [0.3997],\n",
      "        [0.4002],\n",
      "        [0.4007],\n",
      "        [0.4016],\n",
      "        [0.4018],\n",
      "        [0.4020],\n",
      "        [0.4018],\n",
      "        [0.4016],\n",
      "        [0.4012],\n",
      "        [0.4008],\n",
      "        [0.4002],\n",
      "        [0.3994],\n",
      "        [0.3985]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7232560515403748, dv_loss = tensor([6.5207], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.553830623626709, iters = 18461\n",
      "Epoch = 68\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.38846996426582336\n",
      "Prob Vector = tensor([[0.3375],\n",
      "        [0.3450],\n",
      "        [0.3525],\n",
      "        [0.3674],\n",
      "        [0.3778],\n",
      "        [0.4020],\n",
      "        [0.4026],\n",
      "        [0.4031],\n",
      "        [0.4038],\n",
      "        [0.4044],\n",
      "        [0.4050],\n",
      "        [0.4057],\n",
      "        [0.4062],\n",
      "        [0.4068],\n",
      "        [0.4072]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.231804370880127, dv_loss = tensor([6.1755], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.9523212909698486, iters = 18511\n",
      "Epoch = 68\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.29480308294296265\n",
      "Prob Vector = tensor([[0.2970],\n",
      "        [0.2968],\n",
      "        [0.2965],\n",
      "        [0.2961],\n",
      "        [0.2953],\n",
      "        [0.2947],\n",
      "        [0.2942],\n",
      "        [0.2939],\n",
      "        [0.2937],\n",
      "        [0.2937],\n",
      "        [0.2938],\n",
      "        [0.2937],\n",
      "        [0.2937],\n",
      "        [0.2942],\n",
      "        [0.2948]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2636324167251587, dv_loss = tensor([2.8700], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0191856622695923, iters = 18561\n",
      "Epoch = 68\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3546038568019867\n",
      "Prob Vector = tensor([[0.3497],\n",
      "        [0.3506],\n",
      "        [0.3517],\n",
      "        [0.3527],\n",
      "        [0.3538],\n",
      "        [0.3546],\n",
      "        [0.3555],\n",
      "        [0.3562],\n",
      "        [0.3566],\n",
      "        [0.3569],\n",
      "        [0.3569],\n",
      "        [0.3565],\n",
      "        [0.3562],\n",
      "        [0.3558],\n",
      "        [0.3553]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4205809831619263, dv_loss = tensor([3.8784], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8598631620407104, iters = 18611\n",
      "###################################\n",
      "Epoch = 69\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.3204081952571869\n",
      "Prob Vector = tensor([[0.3229],\n",
      "        [0.3221],\n",
      "        [0.3215],\n",
      "        [0.3208],\n",
      "        [0.3204],\n",
      "        [0.3201],\n",
      "        [0.3197],\n",
      "        [0.3196],\n",
      "        [0.3200],\n",
      "        [0.3202],\n",
      "        [0.3204],\n",
      "        [0.3204],\n",
      "        [0.3200],\n",
      "        [0.3194],\n",
      "        [0.3188]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3213295936584473, dv_loss = tensor([4.5567], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9578773975372314, iters = 18631\n",
      "Epoch = 69\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.3740397095680237\n",
      "Prob Vector = tensor([[0.3695],\n",
      "        [0.3703],\n",
      "        [0.3709],\n",
      "        [0.3717],\n",
      "        [0.3723],\n",
      "        [0.3731],\n",
      "        [0.3738],\n",
      "        [0.3745],\n",
      "        [0.3750],\n",
      "        [0.3756],\n",
      "        [0.3761],\n",
      "        [0.3765],\n",
      "        [0.3769],\n",
      "        [0.3771],\n",
      "        [0.3774]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.332931637763977, dv_loss = tensor([3.5493], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9439579248428345, iters = 18681\n",
      "Epoch = 69\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.3658059537410736\n",
      "Prob Vector = tensor([[0.3651],\n",
      "        [0.3653],\n",
      "        [0.3654],\n",
      "        [0.3657],\n",
      "        [0.3662],\n",
      "        [0.3670],\n",
      "        [0.3671],\n",
      "        [0.3671],\n",
      "        [0.3668],\n",
      "        [0.3666],\n",
      "        [0.3663],\n",
      "        [0.3659],\n",
      "        [0.3651],\n",
      "        [0.3641],\n",
      "        [0.3634]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.701549768447876, dv_loss = tensor([4.9905], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5721895694732666, iters = 18731\n",
      "Epoch = 69\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.35463327169418335\n",
      "Prob Vector = tensor([[0.3056],\n",
      "        [0.3119],\n",
      "        [0.3210],\n",
      "        [0.3360],\n",
      "        [0.3460],\n",
      "        [0.3666],\n",
      "        [0.3673],\n",
      "        [0.3680],\n",
      "        [0.3688],\n",
      "        [0.3696],\n",
      "        [0.3704],\n",
      "        [0.3712],\n",
      "        [0.3718],\n",
      "        [0.3725],\n",
      "        [0.3728]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.493922710418701, dv_loss = tensor([3.5946], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.2168443202972412, iters = 18781\n",
      "Epoch = 69\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.29079726338386536\n",
      "Prob Vector = tensor([[0.2933],\n",
      "        [0.2931],\n",
      "        [0.2927],\n",
      "        [0.2923],\n",
      "        [0.2915],\n",
      "        [0.2908],\n",
      "        [0.2902],\n",
      "        [0.2899],\n",
      "        [0.2898],\n",
      "        [0.2897],\n",
      "        [0.2897],\n",
      "        [0.2895],\n",
      "        [0.2895],\n",
      "        [0.2898],\n",
      "        [0.2903]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.263067364692688, dv_loss = tensor([2.1621], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0151175260543823, iters = 18831\n",
      "Epoch = 69\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3543078601360321\n",
      "Prob Vector = tensor([[0.3492],\n",
      "        [0.3501],\n",
      "        [0.3512],\n",
      "        [0.3523],\n",
      "        [0.3534],\n",
      "        [0.3543],\n",
      "        [0.3553],\n",
      "        [0.3560],\n",
      "        [0.3564],\n",
      "        [0.3567],\n",
      "        [0.3566],\n",
      "        [0.3563],\n",
      "        [0.3560],\n",
      "        [0.3557],\n",
      "        [0.3551]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1645060777664185, dv_loss = tensor([2.8810], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1110607385635376, iters = 18881\n",
      "###################################\n",
      "Epoch = 70\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.322449654340744\n",
      "Prob Vector = tensor([[0.3244],\n",
      "        [0.3236],\n",
      "        [0.3231],\n",
      "        [0.3225],\n",
      "        [0.3221],\n",
      "        [0.3220],\n",
      "        [0.3218],\n",
      "        [0.3218],\n",
      "        [0.3224],\n",
      "        [0.3227],\n",
      "        [0.3229],\n",
      "        [0.3228],\n",
      "        [0.3223],\n",
      "        [0.3215],\n",
      "        [0.3209]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4676467180252075, dv_loss = tensor([3.2810], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8066340684890747, iters = 18901\n",
      "Epoch = 70\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.38373076915740967\n",
      "Prob Vector = tensor([[0.3793],\n",
      "        [0.3801],\n",
      "        [0.3807],\n",
      "        [0.3815],\n",
      "        [0.3821],\n",
      "        [0.3829],\n",
      "        [0.3835],\n",
      "        [0.3842],\n",
      "        [0.3847],\n",
      "        [0.3852],\n",
      "        [0.3857],\n",
      "        [0.3860],\n",
      "        [0.3864],\n",
      "        [0.3866],\n",
      "        [0.3870]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9751372337341309, dv_loss = tensor([2.3955], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.295987844467163, iters = 18951\n",
      "Epoch = 70\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.39284804463386536\n",
      "Prob Vector = tensor([[0.3911],\n",
      "        [0.3918],\n",
      "        [0.3923],\n",
      "        [0.3927],\n",
      "        [0.3934],\n",
      "        [0.3944],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3944],\n",
      "        [0.3939],\n",
      "        [0.3935],\n",
      "        [0.3930],\n",
      "        [0.3921],\n",
      "        [0.3909],\n",
      "        [0.3895]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8516806960105896, dv_loss = tensor([4.2975], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4157812595367432, iters = 19001\n",
      "Epoch = 70\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3709010183811188\n",
      "Prob Vector = tensor([[0.3144],\n",
      "        [0.3228],\n",
      "        [0.3338],\n",
      "        [0.3496],\n",
      "        [0.3612],\n",
      "        [0.3851],\n",
      "        [0.3858],\n",
      "        [0.3864],\n",
      "        [0.3871],\n",
      "        [0.3878],\n",
      "        [0.3885],\n",
      "        [0.3893],\n",
      "        [0.3899],\n",
      "        [0.3907],\n",
      "        [0.3911]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.9593913555145264, dv_loss = tensor([1.6108], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.6892576217651367, iters = 19051\n",
      "Epoch = 70\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.32870885729789734\n",
      "Prob Vector = tensor([[0.3338],\n",
      "        [0.3337],\n",
      "        [0.3332],\n",
      "        [0.3323],\n",
      "        [0.3312],\n",
      "        [0.3303],\n",
      "        [0.3292],\n",
      "        [0.3283],\n",
      "        [0.3275],\n",
      "        [0.3267],\n",
      "        [0.3263],\n",
      "        [0.3253],\n",
      "        [0.3245],\n",
      "        [0.3242],\n",
      "        [0.3240]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.90427827835083, dv_loss = tensor([0.9856], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3663148880004883, iters = 19101\n",
      "Epoch = 70\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3831050395965576\n",
      "Prob Vector = tensor([[0.3779],\n",
      "        [0.3787],\n",
      "        [0.3798],\n",
      "        [0.3808],\n",
      "        [0.3819],\n",
      "        [0.3828],\n",
      "        [0.3838],\n",
      "        [0.3845],\n",
      "        [0.3852],\n",
      "        [0.3857],\n",
      "        [0.3856],\n",
      "        [0.3854],\n",
      "        [0.3852],\n",
      "        [0.3850],\n",
      "        [0.3842]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9482144117355347, dv_loss = tensor([1.1845], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3205920457839966, iters = 19151\n",
      "###################################\n",
      "Epoch = 71\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.3568335175514221\n",
      "Prob Vector = tensor([[0.3561],\n",
      "        [0.3559],\n",
      "        [0.3559],\n",
      "        [0.3559],\n",
      "        [0.3560],\n",
      "        [0.3563],\n",
      "        [0.3566],\n",
      "        [0.3569],\n",
      "        [0.3576],\n",
      "        [0.3583],\n",
      "        [0.3586],\n",
      "        [0.3585],\n",
      "        [0.3577],\n",
      "        [0.3565],\n",
      "        [0.3557]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1884665489196777, dv_loss = tensor([3.4707], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0793447494506836, iters = 19171\n",
      "Epoch = 71\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.41841140389442444\n",
      "Prob Vector = tensor([[0.4145],\n",
      "        [0.4153],\n",
      "        [0.4158],\n",
      "        [0.4164],\n",
      "        [0.4170],\n",
      "        [0.4176],\n",
      "        [0.4181],\n",
      "        [0.4187],\n",
      "        [0.4192],\n",
      "        [0.4196],\n",
      "        [0.4201],\n",
      "        [0.4204],\n",
      "        [0.4208],\n",
      "        [0.4211],\n",
      "        [0.4215]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8140837550163269, dv_loss = tensor([6.7561], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4505436420440674, iters = 19221\n",
      "Epoch = 71\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.4781339168548584\n",
      "Prob Vector = tensor([[0.4742],\n",
      "        [0.4758],\n",
      "        [0.4772],\n",
      "        [0.4783],\n",
      "        [0.4789],\n",
      "        [0.4798],\n",
      "        [0.4806],\n",
      "        [0.4815],\n",
      "        [0.4813],\n",
      "        [0.4806],\n",
      "        [0.4797],\n",
      "        [0.4787],\n",
      "        [0.4772],\n",
      "        [0.4755],\n",
      "        [0.4726]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.250365972518921, dv_loss = tensor([4.2271], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0105113983154297, iters = 19271\n",
      "Epoch = 71\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.40956294536590576\n",
      "Prob Vector = tensor([[0.3370],\n",
      "        [0.3466],\n",
      "        [0.3632],\n",
      "        [0.3810],\n",
      "        [0.3953],\n",
      "        [0.4285],\n",
      "        [0.4290],\n",
      "        [0.4296],\n",
      "        [0.4304],\n",
      "        [0.4312],\n",
      "        [0.4321],\n",
      "        [0.4333],\n",
      "        [0.4345],\n",
      "        [0.4356],\n",
      "        [0.4362]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 5.165426254272461, dv_loss = tensor([12.2605], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.9011971950531006, iters = 19321\n",
      "Epoch = 71\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.2526712417602539\n",
      "Prob Vector = tensor([[0.2550],\n",
      "        [0.2542],\n",
      "        [0.2537],\n",
      "        [0.2532],\n",
      "        [0.2524],\n",
      "        [0.2521],\n",
      "        [0.2517],\n",
      "        [0.2515],\n",
      "        [0.2515],\n",
      "        [0.2516],\n",
      "        [0.2519],\n",
      "        [0.2520],\n",
      "        [0.2524],\n",
      "        [0.2530],\n",
      "        [0.2539]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.2720115184783936, dv_loss = tensor([2.5312], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.0009338855743408, iters = 19371\n",
      "Epoch = 71\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2851993441581726\n",
      "Prob Vector = tensor([[0.2780],\n",
      "        [0.2791],\n",
      "        [0.2805],\n",
      "        [0.2819],\n",
      "        [0.2833],\n",
      "        [0.2845],\n",
      "        [0.2857],\n",
      "        [0.2868],\n",
      "        [0.2877],\n",
      "        [0.2884],\n",
      "        [0.2887],\n",
      "        [0.2887],\n",
      "        [0.2885],\n",
      "        [0.2883],\n",
      "        [0.2879]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.433868408203125, dv_loss = tensor([2.6439], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.1600208282470703, iters = 19421\n",
      "###################################\n",
      "Epoch = 72\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.22131307423114777\n",
      "Prob Vector = tensor([[0.2339],\n",
      "        [0.2315],\n",
      "        [0.2290],\n",
      "        [0.2266],\n",
      "        [0.2244],\n",
      "        [0.2225],\n",
      "        [0.2209],\n",
      "        [0.2197],\n",
      "        [0.2186],\n",
      "        [0.2174],\n",
      "        [0.2165],\n",
      "        [0.2156],\n",
      "        [0.2148],\n",
      "        [0.2142],\n",
      "        [0.2140]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.0542259216308594, dv_loss = tensor([0.3498], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.7795741558074951, iters = 19441\n",
      "Epoch = 72\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.25043800473213196\n",
      "Prob Vector = tensor([[0.2430],\n",
      "        [0.2442],\n",
      "        [0.2453],\n",
      "        [0.2465],\n",
      "        [0.2477],\n",
      "        [0.2488],\n",
      "        [0.2499],\n",
      "        [0.2510],\n",
      "        [0.2520],\n",
      "        [0.2528],\n",
      "        [0.2537],\n",
      "        [0.2544],\n",
      "        [0.2552],\n",
      "        [0.2557],\n",
      "        [0.2564]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.6045966148376465, dv_loss = tensor([0.6639], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.3275623321533203, iters = 19491\n",
      "Epoch = 72\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.18316231667995453\n",
      "Prob Vector = tensor([[0.1899],\n",
      "        [0.1884],\n",
      "        [0.1870],\n",
      "        [0.1859],\n",
      "        [0.1848],\n",
      "        [0.1839],\n",
      "        [0.1827],\n",
      "        [0.1818],\n",
      "        [0.1811],\n",
      "        [0.1805],\n",
      "        [0.1802],\n",
      "        [0.1801],\n",
      "        [0.1801],\n",
      "        [0.1803],\n",
      "        [0.1806]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5171165466308594, dv_loss = tensor([3.1087], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7603919506072998, iters = 19541\n",
      "Epoch = 72\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.22494438290596008\n",
      "Prob Vector = tensor([[0.1717],\n",
      "        [0.1792],\n",
      "        [0.1907],\n",
      "        [0.2052],\n",
      "        [0.2191],\n",
      "        [0.2362],\n",
      "        [0.2373],\n",
      "        [0.2383],\n",
      "        [0.2395],\n",
      "        [0.2404],\n",
      "        [0.2414],\n",
      "        [0.2425],\n",
      "        [0.2435],\n",
      "        [0.2444],\n",
      "        [0.2449]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5140434503555298, dv_loss = tensor([2.3194], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7644883394241333, iters = 19591\n",
      "Epoch = 72\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.17963388562202454\n",
      "Prob Vector = tensor([[0.1831],\n",
      "        [0.1819],\n",
      "        [0.1810],\n",
      "        [0.1802],\n",
      "        [0.1792],\n",
      "        [0.1786],\n",
      "        [0.1783],\n",
      "        [0.1780],\n",
      "        [0.1780],\n",
      "        [0.1781],\n",
      "        [0.1783],\n",
      "        [0.1787],\n",
      "        [0.1794],\n",
      "        [0.1803],\n",
      "        [0.1814]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0943217277526855, dv_loss = tensor([2.9088], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1814026832580566, iters = 19641\n",
      "Epoch = 72\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.26457664370536804\n",
      "Prob Vector = tensor([[0.2571],\n",
      "        [0.2584],\n",
      "        [0.2599],\n",
      "        [0.2613],\n",
      "        [0.2627],\n",
      "        [0.2639],\n",
      "        [0.2651],\n",
      "        [0.2662],\n",
      "        [0.2670],\n",
      "        [0.2679],\n",
      "        [0.2683],\n",
      "        [0.2682],\n",
      "        [0.2680],\n",
      "        [0.2676],\n",
      "        [0.2671]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.006585717201233, dv_loss = tensor([4.6628], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2654739618301392, iters = 19691\n",
      "###################################\n",
      "Epoch = 73\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.21527530252933502\n",
      "Prob Vector = tensor([[0.2253],\n",
      "        [0.2231],\n",
      "        [0.2212],\n",
      "        [0.2195],\n",
      "        [0.2180],\n",
      "        [0.2165],\n",
      "        [0.2153],\n",
      "        [0.2143],\n",
      "        [0.2134],\n",
      "        [0.2124],\n",
      "        [0.2114],\n",
      "        [0.2107],\n",
      "        [0.2099],\n",
      "        [0.2092],\n",
      "        [0.2088]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7229330539703369, dv_loss = tensor([2.4067], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5476031303405762, iters = 19711\n",
      "Epoch = 73\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.28849291801452637\n",
      "Prob Vector = tensor([[0.2817],\n",
      "        [0.2828],\n",
      "        [0.2839],\n",
      "        [0.2850],\n",
      "        [0.2860],\n",
      "        [0.2870],\n",
      "        [0.2880],\n",
      "        [0.2890],\n",
      "        [0.2899],\n",
      "        [0.2907],\n",
      "        [0.2915],\n",
      "        [0.2921],\n",
      "        [0.2927],\n",
      "        [0.2932],\n",
      "        [0.2938]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7047892212867737, dv_loss = tensor([5.5599], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5615434646606445, iters = 19761\n",
      "Epoch = 73\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.26530998945236206\n",
      "Prob Vector = tensor([[0.2702],\n",
      "        [0.2691],\n",
      "        [0.2682],\n",
      "        [0.2678],\n",
      "        [0.2675],\n",
      "        [0.2669],\n",
      "        [0.2658],\n",
      "        [0.2652],\n",
      "        [0.2645],\n",
      "        [0.2637],\n",
      "        [0.2630],\n",
      "        [0.2624],\n",
      "        [0.2619],\n",
      "        [0.2617],\n",
      "        [0.2616]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.651852011680603, dv_loss = tensor([4.7277], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6103278398513794, iters = 19811\n",
      "Epoch = 73\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3094564378261566\n",
      "Prob Vector = tensor([[0.2514],\n",
      "        [0.2602],\n",
      "        [0.2739],\n",
      "        [0.2898],\n",
      "        [0.3019],\n",
      "        [0.3226],\n",
      "        [0.3234],\n",
      "        [0.3242],\n",
      "        [0.3252],\n",
      "        [0.3261],\n",
      "        [0.3270],\n",
      "        [0.3280],\n",
      "        [0.3288],\n",
      "        [0.3295],\n",
      "        [0.3299]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.5849785804748535, dv_loss = tensor([1.2467], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.32315802574157715, iters = 19861\n",
      "Epoch = 73\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.25942859053611755\n",
      "Prob Vector = tensor([[0.2636],\n",
      "        [0.2628],\n",
      "        [0.2621],\n",
      "        [0.2613],\n",
      "        [0.2603],\n",
      "        [0.2595],\n",
      "        [0.2588],\n",
      "        [0.2583],\n",
      "        [0.2582],\n",
      "        [0.2579],\n",
      "        [0.2577],\n",
      "        [0.2574],\n",
      "        [0.2575],\n",
      "        [0.2578],\n",
      "        [0.2582]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.044188380241394, dv_loss = tensor([0.9031], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.217711329460144, iters = 19911\n",
      "Epoch = 73\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3380580544471741\n",
      "Prob Vector = tensor([[0.3320],\n",
      "        [0.3331],\n",
      "        [0.3343],\n",
      "        [0.3355],\n",
      "        [0.3367],\n",
      "        [0.3378],\n",
      "        [0.3388],\n",
      "        [0.3396],\n",
      "        [0.3402],\n",
      "        [0.3408],\n",
      "        [0.3408],\n",
      "        [0.3407],\n",
      "        [0.3405],\n",
      "        [0.3403],\n",
      "        [0.3398]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9014719724655151, dv_loss = tensor([6.2820], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3570102453231812, iters = 19961\n",
      "###################################\n",
      "Epoch = 74\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.30635297298431396\n",
      "Prob Vector = tensor([[0.3108],\n",
      "        [0.3098],\n",
      "        [0.3089],\n",
      "        [0.3079],\n",
      "        [0.3071],\n",
      "        [0.3066],\n",
      "        [0.3062],\n",
      "        [0.3060],\n",
      "        [0.3061],\n",
      "        [0.3061],\n",
      "        [0.3058],\n",
      "        [0.3051],\n",
      "        [0.3040],\n",
      "        [0.3029],\n",
      "        [0.3022]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8927076458930969, dv_loss = tensor([2.8336], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3643252849578857, iters = 19981\n",
      "Epoch = 74\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.37722188234329224\n",
      "Prob Vector = tensor([[0.3723],\n",
      "        [0.3732],\n",
      "        [0.3739],\n",
      "        [0.3747],\n",
      "        [0.3755],\n",
      "        [0.3763],\n",
      "        [0.3770],\n",
      "        [0.3777],\n",
      "        [0.3783],\n",
      "        [0.3788],\n",
      "        [0.3794],\n",
      "        [0.3798],\n",
      "        [0.3802],\n",
      "        [0.3805],\n",
      "        [0.3809]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9067777395248413, dv_loss = tensor([5.0322], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3467000722885132, iters = 20031\n",
      "Epoch = 74\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.39904579520225525\n",
      "Prob Vector = tensor([[0.3992],\n",
      "        [0.3996],\n",
      "        [0.3997],\n",
      "        [0.3998],\n",
      "        [0.4000],\n",
      "        [0.4005],\n",
      "        [0.4010],\n",
      "        [0.4009],\n",
      "        [0.4003],\n",
      "        [0.3996],\n",
      "        [0.3990],\n",
      "        [0.3982],\n",
      "        [0.3974],\n",
      "        [0.3960],\n",
      "        [0.3944]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5444260239601135, dv_loss = tensor([6.1500], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.705343246459961, iters = 20081\n",
      "Epoch = 74\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3771989345550537\n",
      "Prob Vector = tensor([[0.3105],\n",
      "        [0.3214],\n",
      "        [0.3365],\n",
      "        [0.3524],\n",
      "        [0.3660],\n",
      "        [0.3939],\n",
      "        [0.3945],\n",
      "        [0.3951],\n",
      "        [0.3959],\n",
      "        [0.3966],\n",
      "        [0.3975],\n",
      "        [0.3984],\n",
      "        [0.3992],\n",
      "        [0.3999],\n",
      "        [0.4002]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.911109209060669, dv_loss = tensor([7.7107], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.6592364311218262, iters = 20131\n",
      "Epoch = 74\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.2770698666572571\n",
      "Prob Vector = tensor([[0.2811],\n",
      "        [0.2806],\n",
      "        [0.2801],\n",
      "        [0.2794],\n",
      "        [0.2783],\n",
      "        [0.2777],\n",
      "        [0.2769],\n",
      "        [0.2764],\n",
      "        [0.2760],\n",
      "        [0.2756],\n",
      "        [0.2753],\n",
      "        [0.2748],\n",
      "        [0.2745],\n",
      "        [0.2745],\n",
      "        [0.2748]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.2209532260894775, dv_loss = tensor([0.1480], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.034131765365600586, iters = 20181\n",
      "Epoch = 74\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3395126163959503\n",
      "Prob Vector = tensor([[0.3338],\n",
      "        [0.3348],\n",
      "        [0.3360],\n",
      "        [0.3372],\n",
      "        [0.3385],\n",
      "        [0.3395],\n",
      "        [0.3406],\n",
      "        [0.3414],\n",
      "        [0.3420],\n",
      "        [0.3424],\n",
      "        [0.3422],\n",
      "        [0.3418],\n",
      "        [0.3414],\n",
      "        [0.3409],\n",
      "        [0.3400]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4123276472091675, dv_loss = tensor([1.6596], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8407353162765503, iters = 20231\n",
      "###################################\n",
      "Epoch = 75\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.304416686296463\n",
      "Prob Vector = tensor([[0.3082],\n",
      "        [0.3072],\n",
      "        [0.3063],\n",
      "        [0.3055],\n",
      "        [0.3049],\n",
      "        [0.3044],\n",
      "        [0.3040],\n",
      "        [0.3039],\n",
      "        [0.3040],\n",
      "        [0.3040],\n",
      "        [0.3039],\n",
      "        [0.3035],\n",
      "        [0.3028],\n",
      "        [0.3020],\n",
      "        [0.3016]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4735013246536255, dv_loss = tensor([3.2487], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7785602807998657, iters = 20251\n",
      "Epoch = 75\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.36935141682624817\n",
      "Prob Vector = tensor([[0.3644],\n",
      "        [0.3652],\n",
      "        [0.3660],\n",
      "        [0.3668],\n",
      "        [0.3675],\n",
      "        [0.3684],\n",
      "        [0.3691],\n",
      "        [0.3698],\n",
      "        [0.3704],\n",
      "        [0.3710],\n",
      "        [0.3715],\n",
      "        [0.3720],\n",
      "        [0.3724],\n",
      "        [0.3727],\n",
      "        [0.3731]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9839568734169006, dv_loss = tensor([6.3817], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2655158042907715, iters = 20301\n",
      "Epoch = 75\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.3746803402900696\n",
      "Prob Vector = tensor([[0.3750],\n",
      "        [0.3753],\n",
      "        [0.3753],\n",
      "        [0.3755],\n",
      "        [0.3758],\n",
      "        [0.3763],\n",
      "        [0.3767],\n",
      "        [0.3764],\n",
      "        [0.3756],\n",
      "        [0.3749],\n",
      "        [0.3742],\n",
      "        [0.3737],\n",
      "        [0.3730],\n",
      "        [0.3720],\n",
      "        [0.3706]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8835260272026062, dv_loss = tensor([5.9643], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3627769947052002, iters = 20351\n",
      "Epoch = 75\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.37921106815338135\n",
      "Prob Vector = tensor([[0.3117],\n",
      "        [0.3223],\n",
      "        [0.3389],\n",
      "        [0.3548],\n",
      "        [0.3688],\n",
      "        [0.3963],\n",
      "        [0.3969],\n",
      "        [0.3975],\n",
      "        [0.3982],\n",
      "        [0.3989],\n",
      "        [0.3996],\n",
      "        [0.4004],\n",
      "        [0.4010],\n",
      "        [0.4015],\n",
      "        [0.4016]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.8786814212799072, dv_loss = tensor([3.3733], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.6316571235656738, iters = 20401\n",
      "Epoch = 75\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3435531258583069\n",
      "Prob Vector = tensor([[0.3492],\n",
      "        [0.3492],\n",
      "        [0.3486],\n",
      "        [0.3479],\n",
      "        [0.3468],\n",
      "        [0.3460],\n",
      "        [0.3449],\n",
      "        [0.3440],\n",
      "        [0.3429],\n",
      "        [0.3417],\n",
      "        [0.3407],\n",
      "        [0.3393],\n",
      "        [0.3381],\n",
      "        [0.3373],\n",
      "        [0.3366]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8729450702667236, dv_loss = tensor([0.7376], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.37428855895996094, iters = 20451\n",
      "Epoch = 75\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3991950750350952\n",
      "Prob Vector = tensor([[0.3946],\n",
      "        [0.3954],\n",
      "        [0.3964],\n",
      "        [0.3974],\n",
      "        [0.3985],\n",
      "        [0.3993],\n",
      "        [0.4003],\n",
      "        [0.4010],\n",
      "        [0.4015],\n",
      "        [0.4016],\n",
      "        [0.4013],\n",
      "        [0.4008],\n",
      "        [0.4004],\n",
      "        [0.4000],\n",
      "        [0.3994]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4371346235275269, dv_loss = tensor([3.8873], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8085204362869263, iters = 20501\n",
      "###################################\n",
      "Epoch = 76\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.3869435787200928\n",
      "Prob Vector = tensor([[0.3841],\n",
      "        [0.3844],\n",
      "        [0.3849],\n",
      "        [0.3852],\n",
      "        [0.3858],\n",
      "        [0.3864],\n",
      "        [0.3870],\n",
      "        [0.3875],\n",
      "        [0.3884],\n",
      "        [0.3890],\n",
      "        [0.3896],\n",
      "        [0.3897],\n",
      "        [0.3887],\n",
      "        [0.3873],\n",
      "        [0.3862]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1822589635849, dv_loss = tensor([5.2122], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0623053312301636, iters = 20521\n",
      "Epoch = 76\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.4648136496543884\n",
      "Prob Vector = tensor([[0.4617],\n",
      "        [0.4621],\n",
      "        [0.4624],\n",
      "        [0.4630],\n",
      "        [0.4634],\n",
      "        [0.4640],\n",
      "        [0.4647],\n",
      "        [0.4653],\n",
      "        [0.4657],\n",
      "        [0.4660],\n",
      "        [0.4664],\n",
      "        [0.4667],\n",
      "        [0.4669],\n",
      "        [0.4669],\n",
      "        [0.4670]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2080029249191284, dv_loss = tensor([3.3234], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0343536138534546, iters = 20571\n",
      "Epoch = 76\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.6244221329689026\n",
      "Prob Vector = tensor([[0.6213],\n",
      "        [0.6236],\n",
      "        [0.6244],\n",
      "        [0.6254],\n",
      "        [0.6258],\n",
      "        [0.6264],\n",
      "        [0.6273],\n",
      "        [0.6288],\n",
      "        [0.6287],\n",
      "        [0.6283],\n",
      "        [0.6267],\n",
      "        [0.6245],\n",
      "        [0.6216],\n",
      "        [0.6187],\n",
      "        [0.6147]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8115177154541016, dv_loss = tensor([6.9743], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.428105115890503, iters = 20621\n",
      "Epoch = 76\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.6417441964149475\n",
      "Prob Vector = tensor([[0.5229],\n",
      "        [0.5488],\n",
      "        [0.5812],\n",
      "        [0.5998],\n",
      "        [0.6322],\n",
      "        [0.6756],\n",
      "        [0.6749],\n",
      "        [0.6744],\n",
      "        [0.6739],\n",
      "        [0.6735],\n",
      "        [0.6733],\n",
      "        [0.6733],\n",
      "        [0.6735],\n",
      "        [0.6741],\n",
      "        [0.6748]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9629554748535156, dv_loss = tensor([0.8674], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2758488655090332, iters = 20671\n",
      "Epoch = 76\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8315272927284241\n",
      "Prob Vector = tensor([[0.8369],\n",
      "        [0.8379],\n",
      "        [0.8381],\n",
      "        [0.8385],\n",
      "        [0.8383],\n",
      "        [0.8379],\n",
      "        [0.8365],\n",
      "        [0.8350],\n",
      "        [0.8331],\n",
      "        [0.8310],\n",
      "        [0.8288],\n",
      "        [0.8257],\n",
      "        [0.8222],\n",
      "        [0.8184],\n",
      "        [0.8145]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9526621103286743, dv_loss = tensor([2.5994], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.284394383430481, iters = 20721\n",
      "Epoch = 76\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8531951308250427\n",
      "Prob Vector = tensor([[0.8597],\n",
      "        [0.8584],\n",
      "        [0.8570],\n",
      "        [0.8556],\n",
      "        [0.8544],\n",
      "        [0.8534],\n",
      "        [0.8525],\n",
      "        [0.8518],\n",
      "        [0.8514],\n",
      "        [0.8510],\n",
      "        [0.8506],\n",
      "        [0.8504],\n",
      "        [0.8505],\n",
      "        [0.8505],\n",
      "        [0.8509]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9157745242118835, dv_loss = tensor([2.3236], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3179936408996582, iters = 20771\n",
      "###################################\n",
      "Epoch = 77\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.931456983089447\n",
      "Prob Vector = tensor([[0.9200],\n",
      "        [0.9227],\n",
      "        [0.9254],\n",
      "        [0.9276],\n",
      "        [0.9294],\n",
      "        [0.9309],\n",
      "        [0.9323],\n",
      "        [0.9334],\n",
      "        [0.9344],\n",
      "        [0.9351],\n",
      "        [0.9357],\n",
      "        [0.9360],\n",
      "        [0.9362],\n",
      "        [0.9365],\n",
      "        [0.9363]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1410073041915894, dv_loss = tensor([32.5793], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.091561198234558, iters = 20791\n",
      "Epoch = 77\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.7836537957191467\n",
      "Prob Vector = tensor([[0.7912],\n",
      "        [0.7900],\n",
      "        [0.7887],\n",
      "        [0.7875],\n",
      "        [0.7862],\n",
      "        [0.7849],\n",
      "        [0.7840],\n",
      "        [0.7829],\n",
      "        [0.7820],\n",
      "        [0.7812],\n",
      "        [0.7804],\n",
      "        [0.7797],\n",
      "        [0.7792],\n",
      "        [0.7787],\n",
      "        [0.7782]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9010022878646851, dv_loss = tensor([3.4498], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3282603025436401, iters = 20841\n",
      "Epoch = 77\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8635174036026001\n",
      "Prob Vector = tensor([[0.8575],\n",
      "        [0.8591],\n",
      "        [0.8603],\n",
      "        [0.8614],\n",
      "        [0.8622],\n",
      "        [0.8631],\n",
      "        [0.8640],\n",
      "        [0.8651],\n",
      "        [0.8658],\n",
      "        [0.8662],\n",
      "        [0.8664],\n",
      "        [0.8662],\n",
      "        [0.8657],\n",
      "        [0.8653],\n",
      "        [0.8644]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6755412817001343, dv_loss = tensor([2.7483], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5502599477767944, iters = 20891\n",
      "Epoch = 77\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7769132256507874\n",
      "Prob Vector = tensor([[0.7187],\n",
      "        [0.7339],\n",
      "        [0.7546],\n",
      "        [0.7557],\n",
      "        [0.7691],\n",
      "        [0.7956],\n",
      "        [0.7945],\n",
      "        [0.7935],\n",
      "        [0.7925],\n",
      "        [0.7917],\n",
      "        [0.7910],\n",
      "        [0.7908],\n",
      "        [0.7906],\n",
      "        [0.7907],\n",
      "        [0.7909]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8397204875946045, dv_loss = tensor([0.7727], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.38584327697753906, iters = 20941\n",
      "Epoch = 77\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.872534990310669\n",
      "Prob Vector = tensor([[0.8719],\n",
      "        [0.8729],\n",
      "        [0.8736],\n",
      "        [0.8743],\n",
      "        [0.8745],\n",
      "        [0.8746],\n",
      "        [0.8745],\n",
      "        [0.8745],\n",
      "        [0.8742],\n",
      "        [0.8738],\n",
      "        [0.8730],\n",
      "        [0.8717],\n",
      "        [0.8701],\n",
      "        [0.8683],\n",
      "        [0.8663]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9940086603164673, dv_loss = tensor([1.8809], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2299052476882935, iters = 20991\n",
      "Epoch = 77\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8155387043952942\n",
      "Prob Vector = tensor([[0.8211],\n",
      "        [0.8196],\n",
      "        [0.8181],\n",
      "        [0.8166],\n",
      "        [0.8156],\n",
      "        [0.8147],\n",
      "        [0.8140],\n",
      "        [0.8137],\n",
      "        [0.8136],\n",
      "        [0.8137],\n",
      "        [0.8139],\n",
      "        [0.8140],\n",
      "        [0.8144],\n",
      "        [0.8148],\n",
      "        [0.8153]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8498305082321167, dv_loss = tensor([2.5187], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3709145784378052, iters = 21041\n",
      "###################################\n",
      "Epoch = 78\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.882433295249939\n",
      "Prob Vector = tensor([[0.8692],\n",
      "        [0.8722],\n",
      "        [0.8752],\n",
      "        [0.8777],\n",
      "        [0.8800],\n",
      "        [0.8817],\n",
      "        [0.8832],\n",
      "        [0.8843],\n",
      "        [0.8854],\n",
      "        [0.8864],\n",
      "        [0.8873],\n",
      "        [0.8880],\n",
      "        [0.8886],\n",
      "        [0.8888],\n",
      "        [0.8887]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8801256418228149, dv_loss = tensor([2.2126], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3392664194107056, iters = 21061\n",
      "Epoch = 78\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8407074213027954\n",
      "Prob Vector = tensor([[0.8483],\n",
      "        [0.8471],\n",
      "        [0.8458],\n",
      "        [0.8446],\n",
      "        [0.8434],\n",
      "        [0.8421],\n",
      "        [0.8411],\n",
      "        [0.8401],\n",
      "        [0.8391],\n",
      "        [0.8382],\n",
      "        [0.8374],\n",
      "        [0.8367],\n",
      "        [0.8361],\n",
      "        [0.8356],\n",
      "        [0.8351]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7942832708358765, dv_loss = tensor([2.6992], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4217075109481812, iters = 21111\n",
      "Epoch = 78\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8947844505310059\n",
      "Prob Vector = tensor([[0.8890],\n",
      "        [0.8905],\n",
      "        [0.8916],\n",
      "        [0.8927],\n",
      "        [0.8935],\n",
      "        [0.8943],\n",
      "        [0.8951],\n",
      "        [0.8961],\n",
      "        [0.8967],\n",
      "        [0.8973],\n",
      "        [0.8975],\n",
      "        [0.8975],\n",
      "        [0.8971],\n",
      "        [0.8968],\n",
      "        [0.8962]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.701508641242981, dv_loss = tensor([2.2208], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5109003782272339, iters = 21161\n",
      "Epoch = 78\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7538855671882629\n",
      "Prob Vector = tensor([[0.6674],\n",
      "        [0.6882],\n",
      "        [0.7112],\n",
      "        [0.7190],\n",
      "        [0.7404],\n",
      "        [0.7810],\n",
      "        [0.7798],\n",
      "        [0.7789],\n",
      "        [0.7782],\n",
      "        [0.7774],\n",
      "        [0.7772],\n",
      "        [0.7772],\n",
      "        [0.7771],\n",
      "        [0.7776],\n",
      "        [0.7778]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.2602105140686035, dv_loss = tensor([20.5499], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.0465259552001953, iters = 21211\n",
      "Epoch = 78\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7283173203468323\n",
      "Prob Vector = tensor([[0.7241],\n",
      "        [0.7267],\n",
      "        [0.7291],\n",
      "        [0.7319],\n",
      "        [0.7328],\n",
      "        [0.7341],\n",
      "        [0.7341],\n",
      "        [0.7340],\n",
      "        [0.7333],\n",
      "        [0.7320],\n",
      "        [0.7296],\n",
      "        [0.7266],\n",
      "        [0.7226],\n",
      "        [0.7188],\n",
      "        [0.7149]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4369419813156128, dv_loss = tensor([2.3308], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7776411771774292, iters = 21261\n",
      "Epoch = 78\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7543448805809021\n",
      "Prob Vector = tensor([[0.7594],\n",
      "        [0.7582],\n",
      "        [0.7570],\n",
      "        [0.7558],\n",
      "        [0.7555],\n",
      "        [0.7550],\n",
      "        [0.7548],\n",
      "        [0.7548],\n",
      "        [0.7548],\n",
      "        [0.7545],\n",
      "        [0.7534],\n",
      "        [0.7522],\n",
      "        [0.7510],\n",
      "        [0.7498],\n",
      "        [0.7489]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1967384815216064, dv_loss = tensor([3.2396], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0155117511749268, iters = 21311\n",
      "###################################\n",
      "Epoch = 79\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8327544331550598\n",
      "Prob Vector = tensor([[0.8118],\n",
      "        [0.8164],\n",
      "        [0.8208],\n",
      "        [0.8249],\n",
      "        [0.8286],\n",
      "        [0.8314],\n",
      "        [0.8336],\n",
      "        [0.8352],\n",
      "        [0.8369],\n",
      "        [0.8385],\n",
      "        [0.8401],\n",
      "        [0.8415],\n",
      "        [0.8432],\n",
      "        [0.8440],\n",
      "        [0.8446]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0868228673934937, dv_loss = tensor([2.2466], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.124294400215149, iters = 21331\n",
      "Epoch = 79\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8211928606033325\n",
      "Prob Vector = tensor([[0.8289],\n",
      "        [0.8277],\n",
      "        [0.8264],\n",
      "        [0.8252],\n",
      "        [0.8239],\n",
      "        [0.8226],\n",
      "        [0.8216],\n",
      "        [0.8205],\n",
      "        [0.8195],\n",
      "        [0.8186],\n",
      "        [0.8178],\n",
      "        [0.8171],\n",
      "        [0.8166],\n",
      "        [0.8160],\n",
      "        [0.8156]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1774487495422363, dv_loss = tensor([2.4089], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0311322212219238, iters = 21381\n",
      "Epoch = 79\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8937588930130005\n",
      "Prob Vector = tensor([[0.8873],\n",
      "        [0.8889],\n",
      "        [0.8901],\n",
      "        [0.8913],\n",
      "        [0.8923],\n",
      "        [0.8931],\n",
      "        [0.8940],\n",
      "        [0.8951],\n",
      "        [0.8958],\n",
      "        [0.8966],\n",
      "        [0.8968],\n",
      "        [0.8968],\n",
      "        [0.8965],\n",
      "        [0.8962],\n",
      "        [0.8956]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7743813991546631, dv_loss = tensor([1.6737], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4315459728240967, iters = 21431\n",
      "Epoch = 79\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7796184420585632\n",
      "Prob Vector = tensor([[0.6974],\n",
      "        [0.7167],\n",
      "        [0.7404],\n",
      "        [0.7463],\n",
      "        [0.7666],\n",
      "        [0.8058],\n",
      "        [0.8046],\n",
      "        [0.8036],\n",
      "        [0.8027],\n",
      "        [0.8019],\n",
      "        [0.8015],\n",
      "        [0.8015],\n",
      "        [0.8015],\n",
      "        [0.8018],\n",
      "        [0.8020]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.70955753326416, dv_loss = tensor([9.3758], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.5027563571929932, iters = 21481\n",
      "Epoch = 79\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.8616192936897278\n",
      "Prob Vector = tensor([[0.8590],\n",
      "        [0.8607],\n",
      "        [0.8618],\n",
      "        [0.8633],\n",
      "        [0.8639],\n",
      "        [0.8646],\n",
      "        [0.8647],\n",
      "        [0.8646],\n",
      "        [0.8645],\n",
      "        [0.8639],\n",
      "        [0.8629],\n",
      "        [0.8615],\n",
      "        [0.8590],\n",
      "        [0.8564],\n",
      "        [0.8536]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9977257251739502, dv_loss = tensor([1.6776], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.208582878112793, iters = 21531\n",
      "Epoch = 79\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8274704217910767\n",
      "Prob Vector = tensor([[0.8333],\n",
      "        [0.8318],\n",
      "        [0.8303],\n",
      "        [0.8288],\n",
      "        [0.8278],\n",
      "        [0.8269],\n",
      "        [0.8263],\n",
      "        [0.8260],\n",
      "        [0.8260],\n",
      "        [0.8259],\n",
      "        [0.8258],\n",
      "        [0.8258],\n",
      "        [0.8258],\n",
      "        [0.8258],\n",
      "        [0.8258]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9559923410415649, dv_loss = tensor([2.7947], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2476121187210083, iters = 21581\n",
      "###################################\n",
      "Epoch = 80\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8902254104614258\n",
      "Prob Vector = tensor([[0.8752],\n",
      "        [0.8787],\n",
      "        [0.8818],\n",
      "        [0.8845],\n",
      "        [0.8869],\n",
      "        [0.8889],\n",
      "        [0.8907],\n",
      "        [0.8922],\n",
      "        [0.8934],\n",
      "        [0.8946],\n",
      "        [0.8957],\n",
      "        [0.8966],\n",
      "        [0.8975],\n",
      "        [0.8982],\n",
      "        [0.8984]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.062238335609436, dv_loss = tensor([1.6109], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1401118040084839, iters = 21601\n",
      "Epoch = 80\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8516544699668884\n",
      "Prob Vector = tensor([[0.8592],\n",
      "        [0.8580],\n",
      "        [0.8567],\n",
      "        [0.8555],\n",
      "        [0.8543],\n",
      "        [0.8531],\n",
      "        [0.8521],\n",
      "        [0.8510],\n",
      "        [0.8501],\n",
      "        [0.8492],\n",
      "        [0.8483],\n",
      "        [0.8476],\n",
      "        [0.8471],\n",
      "        [0.8466],\n",
      "        [0.8461]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8246761560440063, dv_loss = tensor([2.6441], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3744012117385864, iters = 21651\n",
      "Epoch = 80\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8926087021827698\n",
      "Prob Vector = tensor([[0.8842],\n",
      "        [0.8859],\n",
      "        [0.8874],\n",
      "        [0.8888],\n",
      "        [0.8900],\n",
      "        [0.8913],\n",
      "        [0.8926],\n",
      "        [0.8940],\n",
      "        [0.8950],\n",
      "        [0.8961],\n",
      "        [0.8968],\n",
      "        [0.8971],\n",
      "        [0.8969],\n",
      "        [0.8967],\n",
      "        [0.8963]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6918655037879944, dv_loss = tensor([2.2631], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5038774013519287, iters = 21701\n",
      "Epoch = 80\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7147966027259827\n",
      "Prob Vector = tensor([[0.5830],\n",
      "        [0.6146],\n",
      "        [0.6482],\n",
      "        [0.6640],\n",
      "        [0.6950],\n",
      "        [0.7542],\n",
      "        [0.7531],\n",
      "        [0.7524],\n",
      "        [0.7518],\n",
      "        [0.7512],\n",
      "        [0.7509],\n",
      "        [0.7510],\n",
      "        [0.7508],\n",
      "        [0.7511],\n",
      "        [0.7508]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.0668954849243164, dv_loss = tensor([12.3419], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.8695588111877441, iters = 21751\n",
      "Epoch = 80\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7466270923614502\n",
      "Prob Vector = tensor([[0.7451],\n",
      "        [0.7474],\n",
      "        [0.7495],\n",
      "        [0.7520],\n",
      "        [0.7525],\n",
      "        [0.7530],\n",
      "        [0.7518],\n",
      "        [0.7516],\n",
      "        [0.7512],\n",
      "        [0.7495],\n",
      "        [0.7475],\n",
      "        [0.7445],\n",
      "        [0.7396],\n",
      "        [0.7347],\n",
      "        [0.7294]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3836753368377686, dv_loss = tensor([2.0619], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8137466907501221, iters = 21801\n",
      "Epoch = 80\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.7784304618835449\n",
      "Prob Vector = tensor([[0.7839],\n",
      "        [0.7826],\n",
      "        [0.7813],\n",
      "        [0.7801],\n",
      "        [0.7798],\n",
      "        [0.7794],\n",
      "        [0.7794],\n",
      "        [0.7794],\n",
      "        [0.7792],\n",
      "        [0.7785],\n",
      "        [0.7773],\n",
      "        [0.7757],\n",
      "        [0.7744],\n",
      "        [0.7731],\n",
      "        [0.7722]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.039211392402649, dv_loss = tensor([3.3290], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1558042764663696, iters = 21851\n",
      "###################################\n",
      "Epoch = 81\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8472058176994324\n",
      "Prob Vector = tensor([[0.8252],\n",
      "        [0.8302],\n",
      "        [0.8348],\n",
      "        [0.8387],\n",
      "        [0.8423],\n",
      "        [0.8452],\n",
      "        [0.8477],\n",
      "        [0.8498],\n",
      "        [0.8519],\n",
      "        [0.8535],\n",
      "        [0.8550],\n",
      "        [0.8564],\n",
      "        [0.8582],\n",
      "        [0.8592],\n",
      "        [0.8600]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.115235447883606, dv_loss = tensor([2.3051], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0786112546920776, iters = 21871\n",
      "Epoch = 81\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8276349902153015\n",
      "Prob Vector = tensor([[0.8354],\n",
      "        [0.8342],\n",
      "        [0.8329],\n",
      "        [0.8317],\n",
      "        [0.8304],\n",
      "        [0.8291],\n",
      "        [0.8281],\n",
      "        [0.8270],\n",
      "        [0.8260],\n",
      "        [0.8250],\n",
      "        [0.8242],\n",
      "        [0.8234],\n",
      "        [0.8229],\n",
      "        [0.8224],\n",
      "        [0.8219]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.006313681602478, dv_loss = tensor([2.6514], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1848779916763306, iters = 21921\n",
      "Epoch = 81\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8981762528419495\n",
      "Prob Vector = tensor([[0.8904],\n",
      "        [0.8921],\n",
      "        [0.8936],\n",
      "        [0.8950],\n",
      "        [0.8961],\n",
      "        [0.8971],\n",
      "        [0.8983],\n",
      "        [0.8995],\n",
      "        [0.9003],\n",
      "        [0.9012],\n",
      "        [0.9018],\n",
      "        [0.9021],\n",
      "        [0.9019],\n",
      "        [0.9018],\n",
      "        [0.9013]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7344409227371216, dv_loss = tensor([2.2205], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4538429975509644, iters = 21971\n",
      "Epoch = 81\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7368852496147156\n",
      "Prob Vector = tensor([[0.5994],\n",
      "        [0.6328],\n",
      "        [0.6689],\n",
      "        [0.6833],\n",
      "        [0.7148],\n",
      "        [0.7779],\n",
      "        [0.7768],\n",
      "        [0.7760],\n",
      "        [0.7754],\n",
      "        [0.7747],\n",
      "        [0.7746],\n",
      "        [0.7746],\n",
      "        [0.7745],\n",
      "        [0.7749],\n",
      "        [0.7746]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.936764717102051, dv_loss = tensor([11.3548], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.7469477653503418, iters = 22021\n",
      "Epoch = 81\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7923467755317688\n",
      "Prob Vector = tensor([[0.7887],\n",
      "        [0.7908],\n",
      "        [0.7929],\n",
      "        [0.7954],\n",
      "        [0.7965],\n",
      "        [0.7978],\n",
      "        [0.7974],\n",
      "        [0.7975],\n",
      "        [0.7971],\n",
      "        [0.7961],\n",
      "        [0.7944],\n",
      "        [0.7917],\n",
      "        [0.7872],\n",
      "        [0.7831],\n",
      "        [0.7785]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2510124444961548, dv_loss = tensor([2.3442], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.938705563545227, iters = 22071\n",
      "Epoch = 81\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.8014291524887085\n",
      "Prob Vector = tensor([[0.8068],\n",
      "        [0.8053],\n",
      "        [0.8039],\n",
      "        [0.8026],\n",
      "        [0.8022],\n",
      "        [0.8016],\n",
      "        [0.8014],\n",
      "        [0.8014],\n",
      "        [0.8019],\n",
      "        [0.8015],\n",
      "        [0.8007],\n",
      "        [0.7996],\n",
      "        [0.7984],\n",
      "        [0.7974],\n",
      "        [0.7967]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0238910913467407, dv_loss = tensor([2.3103], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1633788347244263, iters = 22121\n",
      "###################################\n",
      "Epoch = 82\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8634644150733948\n",
      "Prob Vector = tensor([[0.8439],\n",
      "        [0.8484],\n",
      "        [0.8526],\n",
      "        [0.8563],\n",
      "        [0.8595],\n",
      "        [0.8620],\n",
      "        [0.8641],\n",
      "        [0.8658],\n",
      "        [0.8675],\n",
      "        [0.8689],\n",
      "        [0.8702],\n",
      "        [0.8716],\n",
      "        [0.8730],\n",
      "        [0.8738],\n",
      "        [0.8744]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.171244740486145, dv_loss = tensor([1.5292], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0148550271987915, iters = 22141\n",
      "Epoch = 82\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8359164595603943\n",
      "Prob Vector = tensor([[0.8436],\n",
      "        [0.8424],\n",
      "        [0.8411],\n",
      "        [0.8399],\n",
      "        [0.8386],\n",
      "        [0.8374],\n",
      "        [0.8364],\n",
      "        [0.8353],\n",
      "        [0.8343],\n",
      "        [0.8334],\n",
      "        [0.8325],\n",
      "        [0.8318],\n",
      "        [0.8312],\n",
      "        [0.8307],\n",
      "        [0.8303]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.888727068901062, dv_loss = tensor([2.3406], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2945173978805542, iters = 22191\n",
      "Epoch = 82\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8967575430870056\n",
      "Prob Vector = tensor([[0.8892],\n",
      "        [0.8909],\n",
      "        [0.8923],\n",
      "        [0.8937],\n",
      "        [0.8947],\n",
      "        [0.8956],\n",
      "        [0.8968],\n",
      "        [0.8980],\n",
      "        [0.8988],\n",
      "        [0.8997],\n",
      "        [0.9003],\n",
      "        [0.9006],\n",
      "        [0.9005],\n",
      "        [0.9004],\n",
      "        [0.9000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6196585297584534, dv_loss = tensor([1.9297], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5604541301727295, iters = 22241\n",
      "Epoch = 82\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.6368724703788757\n",
      "Prob Vector = tensor([[0.4386],\n",
      "        [0.4775],\n",
      "        [0.5310],\n",
      "        [0.5629],\n",
      "        [0.6091],\n",
      "        [0.6930],\n",
      "        [0.6925],\n",
      "        [0.6922],\n",
      "        [0.6924],\n",
      "        [0.6923],\n",
      "        [0.6927],\n",
      "        [0.6939],\n",
      "        [0.6945],\n",
      "        [0.6954],\n",
      "        [0.6951]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.2998504638671875, dv_loss = tensor([28.6682], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.116590976715088, iters = 22291\n",
      "Epoch = 82\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.3760741055011749\n",
      "Prob Vector = tensor([[0.3843],\n",
      "        [0.3866],\n",
      "        [0.3870],\n",
      "        [0.3862],\n",
      "        [0.3837],\n",
      "        [0.3819],\n",
      "        [0.3797],\n",
      "        [0.3779],\n",
      "        [0.3763],\n",
      "        [0.3739],\n",
      "        [0.3701],\n",
      "        [0.3662],\n",
      "        [0.3638],\n",
      "        [0.3625],\n",
      "        [0.3611]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5168668031692505, dv_loss = tensor([2.1057], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6687988042831421, iters = 22341\n",
      "Epoch = 82\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.4537994861602783\n",
      "Prob Vector = tensor([[0.4439],\n",
      "        [0.4448],\n",
      "        [0.4466],\n",
      "        [0.4485],\n",
      "        [0.4509],\n",
      "        [0.4527],\n",
      "        [0.4553],\n",
      "        [0.4574],\n",
      "        [0.4591],\n",
      "        [0.4605],\n",
      "        [0.4594],\n",
      "        [0.4587],\n",
      "        [0.4581],\n",
      "        [0.4563],\n",
      "        [0.4548]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2130093574523926, dv_loss = tensor([4.2426], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9706692695617676, iters = 22391\n",
      "###################################\n",
      "Epoch = 83\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.46634340286254883\n",
      "Prob Vector = tensor([[0.4425],\n",
      "        [0.4461],\n",
      "        [0.4503],\n",
      "        [0.4544],\n",
      "        [0.4577],\n",
      "        [0.4610],\n",
      "        [0.4646],\n",
      "        [0.4678],\n",
      "        [0.4714],\n",
      "        [0.4755],\n",
      "        [0.4798],\n",
      "        [0.4822],\n",
      "        [0.4820],\n",
      "        [0.4809],\n",
      "        [0.4789]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.265086054801941, dv_loss = tensor([2.4249], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9175392389297485, iters = 22411\n",
      "Epoch = 83\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.5815504193305969\n",
      "Prob Vector = tensor([[0.5822],\n",
      "        [0.5823],\n",
      "        [0.5820],\n",
      "        [0.5819],\n",
      "        [0.5816],\n",
      "        [0.5818],\n",
      "        [0.5818],\n",
      "        [0.5821],\n",
      "        [0.5820],\n",
      "        [0.5817],\n",
      "        [0.5815],\n",
      "        [0.5811],\n",
      "        [0.5809],\n",
      "        [0.5803],\n",
      "        [0.5800]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0072405338287354, dv_loss = tensor([4.4194], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1731467247009277, iters = 22461\n",
      "Epoch = 83\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.7227799296379089\n",
      "Prob Vector = tensor([[0.7076],\n",
      "        [0.7110],\n",
      "        [0.7143],\n",
      "        [0.7166],\n",
      "        [0.7187],\n",
      "        [0.7208],\n",
      "        [0.7230],\n",
      "        [0.7260],\n",
      "        [0.7274],\n",
      "        [0.7284],\n",
      "        [0.7296],\n",
      "        [0.7306],\n",
      "        [0.7302],\n",
      "        [0.7294],\n",
      "        [0.7279]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7528470158576965, dv_loss = tensor([4.3305], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4248507022857666, iters = 22511\n",
      "Epoch = 83\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.6260913014411926\n",
      "Prob Vector = tensor([[0.4219],\n",
      "        [0.4590],\n",
      "        [0.5133],\n",
      "        [0.5488],\n",
      "        [0.5949],\n",
      "        [0.6862],\n",
      "        [0.6853],\n",
      "        [0.6848],\n",
      "        [0.6847],\n",
      "        [0.6845],\n",
      "        [0.6849],\n",
      "        [0.6857],\n",
      "        [0.6859],\n",
      "        [0.6861],\n",
      "        [0.6854]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.1871979236602783, dv_loss = tensor([0.1055], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.009282827377319336, iters = 22561\n",
      "Epoch = 83\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7701656818389893\n",
      "Prob Vector = tensor([[0.7675],\n",
      "        [0.7700],\n",
      "        [0.7719],\n",
      "        [0.7742],\n",
      "        [0.7751],\n",
      "        [0.7760],\n",
      "        [0.7756],\n",
      "        [0.7751],\n",
      "        [0.7749],\n",
      "        [0.7737],\n",
      "        [0.7715],\n",
      "        [0.7686],\n",
      "        [0.7637],\n",
      "        [0.7597],\n",
      "        [0.7548]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.024469017982483, dv_loss = tensor([3.4308], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.152072548866272, iters = 22611\n",
      "Epoch = 83\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.794098973274231\n",
      "Prob Vector = tensor([[0.7991],\n",
      "        [0.7975],\n",
      "        [0.7962],\n",
      "        [0.7950],\n",
      "        [0.7947],\n",
      "        [0.7944],\n",
      "        [0.7945],\n",
      "        [0.7948],\n",
      "        [0.7949],\n",
      "        [0.7946],\n",
      "        [0.7936],\n",
      "        [0.7924],\n",
      "        [0.7913],\n",
      "        [0.7899],\n",
      "        [0.7889]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8331072926521301, dv_loss = tensor([2.7576], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3405036926269531, iters = 22661\n",
      "###################################\n",
      "Epoch = 84\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8540606498718262\n",
      "Prob Vector = tensor([[0.8341],\n",
      "        [0.8390],\n",
      "        [0.8433],\n",
      "        [0.8468],\n",
      "        [0.8499],\n",
      "        [0.8524],\n",
      "        [0.8545],\n",
      "        [0.8562],\n",
      "        [0.8578],\n",
      "        [0.8595],\n",
      "        [0.8610],\n",
      "        [0.8624],\n",
      "        [0.8639],\n",
      "        [0.8648],\n",
      "        [0.8655]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7556185722351074, dv_loss = tensor([3.1012], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.416642665863037, iters = 22681\n",
      "Epoch = 84\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8304377794265747\n",
      "Prob Vector = tensor([[0.8381],\n",
      "        [0.8369],\n",
      "        [0.8356],\n",
      "        [0.8344],\n",
      "        [0.8331],\n",
      "        [0.8319],\n",
      "        [0.8309],\n",
      "        [0.8298],\n",
      "        [0.8288],\n",
      "        [0.8278],\n",
      "        [0.8270],\n",
      "        [0.8262],\n",
      "        [0.8257],\n",
      "        [0.8253],\n",
      "        [0.8248]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5607993006706238, dv_loss = tensor([3.2895], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.607947587966919, iters = 22731\n",
      "Epoch = 84\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8996216058731079\n",
      "Prob Vector = tensor([[0.8924],\n",
      "        [0.8940],\n",
      "        [0.8954],\n",
      "        [0.8967],\n",
      "        [0.8977],\n",
      "        [0.8986],\n",
      "        [0.8997],\n",
      "        [0.9008],\n",
      "        [0.9016],\n",
      "        [0.9025],\n",
      "        [0.9030],\n",
      "        [0.9032],\n",
      "        [0.9030],\n",
      "        [0.9030],\n",
      "        [0.9026]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6856836676597595, dv_loss = tensor([2.2275], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4794011116027832, iters = 22781\n",
      "Epoch = 84\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.7279950380325317\n",
      "Prob Vector = tensor([[0.5405],\n",
      "        [0.5835],\n",
      "        [0.6352],\n",
      "        [0.6607],\n",
      "        [0.6985],\n",
      "        [0.7824],\n",
      "        [0.7811],\n",
      "        [0.7802],\n",
      "        [0.7797],\n",
      "        [0.7794],\n",
      "        [0.7796],\n",
      "        [0.7801],\n",
      "        [0.7797],\n",
      "        [0.7799],\n",
      "        [0.7795]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.061387777328491, dv_loss = tensor([13.7056], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.8949778079986572, iters = 22831\n",
      "Epoch = 84\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.7709537744522095\n",
      "Prob Vector = tensor([[0.7639],\n",
      "        [0.7668],\n",
      "        [0.7696],\n",
      "        [0.7720],\n",
      "        [0.7729],\n",
      "        [0.7747],\n",
      "        [0.7750],\n",
      "        [0.7759],\n",
      "        [0.7766],\n",
      "        [0.7764],\n",
      "        [0.7756],\n",
      "        [0.7730],\n",
      "        [0.7684],\n",
      "        [0.7640],\n",
      "        [0.7594]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.815269112586975, dv_loss = tensor([0.8804], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3516947031021118, iters = 22881\n",
      "Epoch = 84\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.769941508769989\n",
      "Prob Vector = tensor([[0.7747],\n",
      "        [0.7731],\n",
      "        [0.7719],\n",
      "        [0.7709],\n",
      "        [0.7709],\n",
      "        [0.7706],\n",
      "        [0.7711],\n",
      "        [0.7716],\n",
      "        [0.7717],\n",
      "        [0.7707],\n",
      "        [0.7696],\n",
      "        [0.7680],\n",
      "        [0.7663],\n",
      "        [0.7647],\n",
      "        [0.7635]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2896848917007446, dv_loss = tensor([2.4229], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8755186796188354, iters = 22931\n",
      "###################################\n",
      "Epoch = 85\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.8252555727958679\n",
      "Prob Vector = tensor([[0.8010],\n",
      "        [0.8066],\n",
      "        [0.8118],\n",
      "        [0.8162],\n",
      "        [0.8204],\n",
      "        [0.8237],\n",
      "        [0.8263],\n",
      "        [0.8280],\n",
      "        [0.8300],\n",
      "        [0.8320],\n",
      "        [0.8340],\n",
      "        [0.8356],\n",
      "        [0.8370],\n",
      "        [0.8378],\n",
      "        [0.8384]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1587423086166382, dv_loss = tensor([1.9516], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.005454182624817, iters = 22951\n",
      "Epoch = 85\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.8221242427825928\n",
      "Prob Vector = tensor([[0.8299],\n",
      "        [0.8288],\n",
      "        [0.8275],\n",
      "        [0.8263],\n",
      "        [0.8250],\n",
      "        [0.8237],\n",
      "        [0.8226],\n",
      "        [0.8215],\n",
      "        [0.8204],\n",
      "        [0.8194],\n",
      "        [0.8186],\n",
      "        [0.8178],\n",
      "        [0.8173],\n",
      "        [0.8169],\n",
      "        [0.8165]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1521224975585938, dv_loss = tensor([2.3260], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0098881721496582, iters = 23001\n",
      "Epoch = 85\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.8892765045166016\n",
      "Prob Vector = tensor([[0.8818],\n",
      "        [0.8834],\n",
      "        [0.8848],\n",
      "        [0.8860],\n",
      "        [0.8870],\n",
      "        [0.8880],\n",
      "        [0.8892],\n",
      "        [0.8904],\n",
      "        [0.8913],\n",
      "        [0.8921],\n",
      "        [0.8928],\n",
      "        [0.8932],\n",
      "        [0.8931],\n",
      "        [0.8932],\n",
      "        [0.8928]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.899044930934906, dv_loss = tensor([1.9541], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2606818675994873, iters = 23051\n",
      "Epoch = 85\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.6999137997627258\n",
      "Prob Vector = tensor([[0.4752],\n",
      "        [0.5196],\n",
      "        [0.5851],\n",
      "        [0.6214],\n",
      "        [0.6669],\n",
      "        [0.7649],\n",
      "        [0.7637],\n",
      "        [0.7631],\n",
      "        [0.7628],\n",
      "        [0.7626],\n",
      "        [0.7627],\n",
      "        [0.7631],\n",
      "        [0.7629],\n",
      "        [0.7628],\n",
      "        [0.7620]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.185612201690674, dv_loss = tensor([23.7155], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.0236682891845703, iters = 23101\n",
      "Epoch = 85\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.4518086910247803\n",
      "Prob Vector = tensor([[0.4501],\n",
      "        [0.4542],\n",
      "        [0.4585],\n",
      "        [0.4620],\n",
      "        [0.4627],\n",
      "        [0.4629],\n",
      "        [0.4598],\n",
      "        [0.4579],\n",
      "        [0.4566],\n",
      "        [0.4543],\n",
      "        [0.4508],\n",
      "        [0.4458],\n",
      "        [0.4388],\n",
      "        [0.4337],\n",
      "        [0.4290]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8554069995880127, dv_loss = tensor([1.5290], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.30931544303894043, iters = 23151\n",
      "Epoch = 85\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.3681979775428772\n",
      "Prob Vector = tensor([[0.3576],\n",
      "        [0.3585],\n",
      "        [0.3601],\n",
      "        [0.3617],\n",
      "        [0.3635],\n",
      "        [0.3650],\n",
      "        [0.3674],\n",
      "        [0.3700],\n",
      "        [0.3724],\n",
      "        [0.3745],\n",
      "        [0.3751],\n",
      "        [0.3749],\n",
      "        [0.3750],\n",
      "        [0.3743],\n",
      "        [0.3730]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.642481565475464, dv_loss = tensor([7.6366], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.4754407405853271, iters = 23201\n",
      "###################################\n",
      "Epoch = 86\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.29284390807151794\n",
      "Prob Vector = tensor([[0.2935],\n",
      "        [0.2933],\n",
      "        [0.2933],\n",
      "        [0.2933],\n",
      "        [0.2931],\n",
      "        [0.2931],\n",
      "        [0.2931],\n",
      "        [0.2932],\n",
      "        [0.2938],\n",
      "        [0.2942],\n",
      "        [0.2944],\n",
      "        [0.2935],\n",
      "        [0.2917],\n",
      "        [0.2903],\n",
      "        [0.2890]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.660595178604126, dv_loss = tensor([7.0104], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.4925367832183838, iters = 23221\n",
      "Epoch = 86\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.2726376950740814\n",
      "Prob Vector = tensor([[0.2635],\n",
      "        [0.2649],\n",
      "        [0.2661],\n",
      "        [0.2674],\n",
      "        [0.2688],\n",
      "        [0.2703],\n",
      "        [0.2718],\n",
      "        [0.2733],\n",
      "        [0.2746],\n",
      "        [0.2757],\n",
      "        [0.2769],\n",
      "        [0.2777],\n",
      "        [0.2787],\n",
      "        [0.2794],\n",
      "        [0.2803]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.740645408630371, dv_loss = tensor([1.7326], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.5694806575775146, iters = 23271\n",
      "Epoch = 86\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.17687058448791504\n",
      "Prob Vector = tensor([[0.1835],\n",
      "        [0.1824],\n",
      "        [0.1814],\n",
      "        [0.1804],\n",
      "        [0.1798],\n",
      "        [0.1792],\n",
      "        [0.1777],\n",
      "        [0.1768],\n",
      "        [0.1758],\n",
      "        [0.1749],\n",
      "        [0.1739],\n",
      "        [0.1731],\n",
      "        [0.1722],\n",
      "        [0.1714],\n",
      "        [0.1706]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.774660587310791, dv_loss = tensor([1.8561], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.60052227973938, iters = 23321\n",
      "Epoch = 86\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.1910335123538971\n",
      "Prob Vector = tensor([[0.1303],\n",
      "        [0.1356],\n",
      "        [0.1443],\n",
      "        [0.1624],\n",
      "        [0.1813],\n",
      "        [0.2056],\n",
      "        [0.2067],\n",
      "        [0.2079],\n",
      "        [0.2092],\n",
      "        [0.2104],\n",
      "        [0.2117],\n",
      "        [0.2131],\n",
      "        [0.2145],\n",
      "        [0.2158],\n",
      "        [0.2167]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.701595664024353, dv_loss = tensor([1.5040], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4764658212661743, iters = 23371\n",
      "Epoch = 86\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.145027294754982\n",
      "Prob Vector = tensor([[0.1512],\n",
      "        [0.1498],\n",
      "        [0.1487],\n",
      "        [0.1476],\n",
      "        [0.1463],\n",
      "        [0.1455],\n",
      "        [0.1446],\n",
      "        [0.1437],\n",
      "        [0.1431],\n",
      "        [0.1426],\n",
      "        [0.1422],\n",
      "        [0.1420],\n",
      "        [0.1422],\n",
      "        [0.1426],\n",
      "        [0.1433]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5827420949935913, dv_loss = tensor([4.0958], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5929864645004272, iters = 23421\n",
      "Epoch = 86\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2298029214143753\n",
      "Prob Vector = tensor([[0.2198],\n",
      "        [0.2213],\n",
      "        [0.2230],\n",
      "        [0.2248],\n",
      "        [0.2266],\n",
      "        [0.2281],\n",
      "        [0.2299],\n",
      "        [0.2315],\n",
      "        [0.2328],\n",
      "        [0.2342],\n",
      "        [0.2351],\n",
      "        [0.2353],\n",
      "        [0.2353],\n",
      "        [0.2351],\n",
      "        [0.2344]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5768779516220093, dv_loss = tensor([1.2239], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5952249765396118, iters = 23471\n",
      "###################################\n",
      "Epoch = 87\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.17804253101348877\n",
      "Prob Vector = tensor([[0.1873],\n",
      "        [0.1855],\n",
      "        [0.1838],\n",
      "        [0.1823],\n",
      "        [0.1808],\n",
      "        [0.1793],\n",
      "        [0.1781],\n",
      "        [0.1772],\n",
      "        [0.1768],\n",
      "        [0.1760],\n",
      "        [0.1748],\n",
      "        [0.1738],\n",
      "        [0.1726],\n",
      "        [0.1717],\n",
      "        [0.1708]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6368423700332642, dv_loss = tensor([5.0343], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.5338598489761353, iters = 23491\n",
      "Epoch = 87\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.24886231124401093\n",
      "Prob Vector = tensor([[0.2400],\n",
      "        [0.2414],\n",
      "        [0.2427],\n",
      "        [0.2440],\n",
      "        [0.2453],\n",
      "        [0.2468],\n",
      "        [0.2482],\n",
      "        [0.2496],\n",
      "        [0.2508],\n",
      "        [0.2518],\n",
      "        [0.2529],\n",
      "        [0.2537],\n",
      "        [0.2545],\n",
      "        [0.2553],\n",
      "        [0.2560]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.4976179599761963, dv_loss = tensor([1.2646], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.669816255569458, iters = 23541\n",
      "Epoch = 87\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.22020137310028076\n",
      "Prob Vector = tensor([[0.2260],\n",
      "        [0.2254],\n",
      "        [0.2249],\n",
      "        [0.2243],\n",
      "        [0.2239],\n",
      "        [0.2237],\n",
      "        [0.2219],\n",
      "        [0.2207],\n",
      "        [0.2195],\n",
      "        [0.2185],\n",
      "        [0.2174],\n",
      "        [0.2163],\n",
      "        [0.2150],\n",
      "        [0.2136],\n",
      "        [0.2121]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.46564981341362, dv_loss = tensor([6.6328], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.698028564453125, iters = 23591\n",
      "Epoch = 87\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.23343542218208313\n",
      "Prob Vector = tensor([[0.1539],\n",
      "        [0.1615],\n",
      "        [0.1761],\n",
      "        [0.2020],\n",
      "        [0.2205],\n",
      "        [0.2515],\n",
      "        [0.2528],\n",
      "        [0.2541],\n",
      "        [0.2556],\n",
      "        [0.2572],\n",
      "        [0.2589],\n",
      "        [0.2611],\n",
      "        [0.2634],\n",
      "        [0.2658],\n",
      "        [0.2672]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.781008720397949, dv_loss = tensor([2.5224], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.6135456562042236, iters = 23641\n",
      "Epoch = 87\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.15239360928535461\n",
      "Prob Vector = tensor([[0.1600],\n",
      "        [0.1584],\n",
      "        [0.1571],\n",
      "        [0.1558],\n",
      "        [0.1543],\n",
      "        [0.1534],\n",
      "        [0.1523],\n",
      "        [0.1512],\n",
      "        [0.1504],\n",
      "        [0.1495],\n",
      "        [0.1489],\n",
      "        [0.1485],\n",
      "        [0.1484],\n",
      "        [0.1486],\n",
      "        [0.1492]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9133844375610352, dv_loss = tensor([0.2149], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2558310031890869, iters = 23691\n",
      "Epoch = 87\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.22266101837158203\n",
      "Prob Vector = tensor([[0.2119],\n",
      "        [0.2132],\n",
      "        [0.2150],\n",
      "        [0.2170],\n",
      "        [0.2189],\n",
      "        [0.2206],\n",
      "        [0.2225],\n",
      "        [0.2242],\n",
      "        [0.2257],\n",
      "        [0.2272],\n",
      "        [0.2285],\n",
      "        [0.2288],\n",
      "        [0.2290],\n",
      "        [0.2290],\n",
      "        [0.2284]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9577265977859497, dv_loss = tensor([0.4931], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2109893560409546, iters = 23741\n",
      "###################################\n",
      "Epoch = 88\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.16640879213809967\n",
      "Prob Vector = tensor([[0.1772],\n",
      "        [0.1753],\n",
      "        [0.1735],\n",
      "        [0.1718],\n",
      "        [0.1701],\n",
      "        [0.1685],\n",
      "        [0.1671],\n",
      "        [0.1659],\n",
      "        [0.1651],\n",
      "        [0.1637],\n",
      "        [0.1622],\n",
      "        [0.1608],\n",
      "        [0.1595],\n",
      "        [0.1583],\n",
      "        [0.1572]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.282893180847168, dv_loss = tensor([0.0393], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.11427974700927734, iters = 23761\n",
      "Epoch = 88\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.21782436966896057\n",
      "Prob Vector = tensor([[0.2084],\n",
      "        [0.2099],\n",
      "        [0.2112],\n",
      "        [0.2126],\n",
      "        [0.2141],\n",
      "        [0.2156],\n",
      "        [0.2170],\n",
      "        [0.2185],\n",
      "        [0.2198],\n",
      "        [0.2209],\n",
      "        [0.2221],\n",
      "        [0.2230],\n",
      "        [0.2239],\n",
      "        [0.2247],\n",
      "        [0.2256]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.14837646484375, dv_loss = tensor([0.0629], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.01999950408935547, iters = 23811\n",
      "Epoch = 88\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.16193942725658417\n",
      "Prob Vector = tensor([[0.1701],\n",
      "        [0.1688],\n",
      "        [0.1676],\n",
      "        [0.1665],\n",
      "        [0.1656],\n",
      "        [0.1644],\n",
      "        [0.1627],\n",
      "        [0.1616],\n",
      "        [0.1604],\n",
      "        [0.1594],\n",
      "        [0.1583],\n",
      "        [0.1573],\n",
      "        [0.1563],\n",
      "        [0.1554],\n",
      "        [0.1547]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4691686630249023, dv_loss = tensor([1.1641], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6983985900878906, iters = 23861\n",
      "Epoch = 88\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.19456489384174347\n",
      "Prob Vector = tensor([[0.1279],\n",
      "        [0.1341],\n",
      "        [0.1431],\n",
      "        [0.1650],\n",
      "        [0.1834],\n",
      "        [0.2101],\n",
      "        [0.2114],\n",
      "        [0.2126],\n",
      "        [0.2140],\n",
      "        [0.2155],\n",
      "        [0.2169],\n",
      "        [0.2187],\n",
      "        [0.2204],\n",
      "        [0.2221],\n",
      "        [0.2232]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3589876890182495, dv_loss = tensor([0.6367], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8101168870925903, iters = 23911\n",
      "Epoch = 88\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.15233051776885986\n",
      "Prob Vector = tensor([[0.1604],\n",
      "        [0.1587],\n",
      "        [0.1574],\n",
      "        [0.1560],\n",
      "        [0.1545],\n",
      "        [0.1535],\n",
      "        [0.1524],\n",
      "        [0.1512],\n",
      "        [0.1503],\n",
      "        [0.1494],\n",
      "        [0.1486],\n",
      "        [0.1481],\n",
      "        [0.1479],\n",
      "        [0.1481],\n",
      "        [0.1486]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.126918077468872, dv_loss = tensor([0.8813], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0397090911865234, iters = 23961\n",
      "Epoch = 88\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2384829968214035\n",
      "Prob Vector = tensor([[0.2274],\n",
      "        [0.2288],\n",
      "        [0.2306],\n",
      "        [0.2326],\n",
      "        [0.2345],\n",
      "        [0.2361],\n",
      "        [0.2381],\n",
      "        [0.2398],\n",
      "        [0.2414],\n",
      "        [0.2431],\n",
      "        [0.2445],\n",
      "        [0.2449],\n",
      "        [0.2453],\n",
      "        [0.2454],\n",
      "        [0.2449]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.893476128578186, dv_loss = tensor([2.9025], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2705217599868774, iters = 24011\n",
      "###################################\n",
      "Epoch = 89\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.19040687382221222\n",
      "Prob Vector = tensor([[0.1985],\n",
      "        [0.1974],\n",
      "        [0.1963],\n",
      "        [0.1951],\n",
      "        [0.1939],\n",
      "        [0.1927],\n",
      "        [0.1917],\n",
      "        [0.1907],\n",
      "        [0.1902],\n",
      "        [0.1890],\n",
      "        [0.1873],\n",
      "        [0.1858],\n",
      "        [0.1840],\n",
      "        [0.1826],\n",
      "        [0.1809]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6671727895736694, dv_loss = tensor([1.2111], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.4955145120620728, iters = 24031\n",
      "Epoch = 89\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.2709752917289734\n",
      "Prob Vector = tensor([[0.2612],\n",
      "        [0.2628],\n",
      "        [0.2640],\n",
      "        [0.2655],\n",
      "        [0.2670],\n",
      "        [0.2686],\n",
      "        [0.2702],\n",
      "        [0.2718],\n",
      "        [0.2731],\n",
      "        [0.2742],\n",
      "        [0.2755],\n",
      "        [0.2763],\n",
      "        [0.2773],\n",
      "        [0.2781],\n",
      "        [0.2790]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.5416277647018433, dv_loss = tensor([2.3783], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6177042722702026, iters = 24081\n",
      "Epoch = 89\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.2647567391395569\n",
      "Prob Vector = tensor([[0.2699],\n",
      "        [0.2695],\n",
      "        [0.2692],\n",
      "        [0.2691],\n",
      "        [0.2689],\n",
      "        [0.2689],\n",
      "        [0.2675],\n",
      "        [0.2660],\n",
      "        [0.2644],\n",
      "        [0.2632],\n",
      "        [0.2619],\n",
      "        [0.2608],\n",
      "        [0.2592],\n",
      "        [0.2575],\n",
      "        [0.2554]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.4690760672092438, dv_loss = tensor([6.2014], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.6867800951004028, iters = 24131\n",
      "Epoch = 89\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.2756901979446411\n",
      "Prob Vector = tensor([[0.1704],\n",
      "        [0.1857],\n",
      "        [0.2058],\n",
      "        [0.2354],\n",
      "        [0.2563],\n",
      "        [0.3005],\n",
      "        [0.3017],\n",
      "        [0.3030],\n",
      "        [0.3046],\n",
      "        [0.3063],\n",
      "        [0.3081],\n",
      "        [0.3107],\n",
      "        [0.3133],\n",
      "        [0.3159],\n",
      "        [0.3176]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.6835386753082275, dv_loss = tensor([0.5200], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.5258142948150635, iters = 24181\n",
      "Epoch = 89\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.1907244175672531\n",
      "Prob Vector = tensor([[0.2018],\n",
      "        [0.2000],\n",
      "        [0.1984],\n",
      "        [0.1968],\n",
      "        [0.1950],\n",
      "        [0.1935],\n",
      "        [0.1919],\n",
      "        [0.1902],\n",
      "        [0.1884],\n",
      "        [0.1867],\n",
      "        [0.1852],\n",
      "        [0.1839],\n",
      "        [0.1832],\n",
      "        [0.1830],\n",
      "        [0.1831]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9184980392456055, dv_loss = tensor([0.9764], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.240769624710083, iters = 24231\n",
      "Epoch = 89\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2623502314090729\n",
      "Prob Vector = tensor([[0.2498],\n",
      "        [0.2511],\n",
      "        [0.2531],\n",
      "        [0.2552],\n",
      "        [0.2573],\n",
      "        [0.2592],\n",
      "        [0.2615],\n",
      "        [0.2637],\n",
      "        [0.2656],\n",
      "        [0.2678],\n",
      "        [0.2694],\n",
      "        [0.2702],\n",
      "        [0.2707],\n",
      "        [0.2707],\n",
      "        [0.2701]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9331070184707642, dv_loss = tensor([0.8311], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.22554409503936768, iters = 24281\n",
      "###################################\n",
      "Epoch = 90\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.2114061415195465\n",
      "Prob Vector = tensor([[0.2183],\n",
      "        [0.2174],\n",
      "        [0.2166],\n",
      "        [0.2157],\n",
      "        [0.2147],\n",
      "        [0.2136],\n",
      "        [0.2128],\n",
      "        [0.2120],\n",
      "        [0.2116],\n",
      "        [0.2108],\n",
      "        [0.2091],\n",
      "        [0.2073],\n",
      "        [0.2054],\n",
      "        [0.2039],\n",
      "        [0.2020]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5941200256347656, dv_loss = tensor([1.7794], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5641427040100098, iters = 24301\n",
      "Epoch = 90\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.27484774589538574\n",
      "Prob Vector = tensor([[0.2648],\n",
      "        [0.2664],\n",
      "        [0.2677],\n",
      "        [0.2691],\n",
      "        [0.2706],\n",
      "        [0.2723],\n",
      "        [0.2739],\n",
      "        [0.2756],\n",
      "        [0.2770],\n",
      "        [0.2782],\n",
      "        [0.2796],\n",
      "        [0.2804],\n",
      "        [0.2815],\n",
      "        [0.2824],\n",
      "        [0.2834]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5182493925094604, dv_loss = tensor([4.1794], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.638511061668396, iters = 24351\n",
      "Epoch = 90\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.24540244042873383\n",
      "Prob Vector = tensor([[0.2527],\n",
      "        [0.2522],\n",
      "        [0.2516],\n",
      "        [0.2512],\n",
      "        [0.2508],\n",
      "        [0.2506],\n",
      "        [0.2487],\n",
      "        [0.2469],\n",
      "        [0.2450],\n",
      "        [0.2434],\n",
      "        [0.2416],\n",
      "        [0.2399],\n",
      "        [0.2378],\n",
      "        [0.2356],\n",
      "        [0.2331]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9541006684303284, dv_loss = tensor([5.4589], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2011077404022217, iters = 24401\n",
      "Epoch = 90\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.2409878522157669\n",
      "Prob Vector = tensor([[0.1469],\n",
      "        [0.1565],\n",
      "        [0.1747],\n",
      "        [0.2037],\n",
      "        [0.2236],\n",
      "        [0.2632],\n",
      "        [0.2645],\n",
      "        [0.2659],\n",
      "        [0.2675],\n",
      "        [0.2692],\n",
      "        [0.2710],\n",
      "        [0.2735],\n",
      "        [0.2760],\n",
      "        [0.2785],\n",
      "        [0.2801]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.173760175704956, dv_loss = tensor([1.6179], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.0155012607574463, iters = 24451\n",
      "Epoch = 90\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.1653727889060974\n",
      "Prob Vector = tensor([[0.1758],\n",
      "        [0.1740],\n",
      "        [0.1724],\n",
      "        [0.1707],\n",
      "        [0.1688],\n",
      "        [0.1674],\n",
      "        [0.1659],\n",
      "        [0.1642],\n",
      "        [0.1627],\n",
      "        [0.1615],\n",
      "        [0.1605],\n",
      "        [0.1596],\n",
      "        [0.1590],\n",
      "        [0.1589],\n",
      "        [0.1591]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1091744899749756, dv_loss = tensor([1.7573], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0499906539916992, iters = 24501\n",
      "Epoch = 90\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.25086551904678345\n",
      "Prob Vector = tensor([[0.2386],\n",
      "        [0.2400],\n",
      "        [0.2418],\n",
      "        [0.2439],\n",
      "        [0.2460],\n",
      "        [0.2479],\n",
      "        [0.2502],\n",
      "        [0.2524],\n",
      "        [0.2543],\n",
      "        [0.2564],\n",
      "        [0.2578],\n",
      "        [0.2584],\n",
      "        [0.2587],\n",
      "        [0.2585],\n",
      "        [0.2578]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5366284847259521, dv_loss = tensor([0.9435], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6209206581115723, iters = 24551\n",
      "###################################\n",
      "Epoch = 91\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.20229165256023407\n",
      "Prob Vector = tensor([[0.2088],\n",
      "        [0.2079],\n",
      "        [0.2071],\n",
      "        [0.2062],\n",
      "        [0.2051],\n",
      "        [0.2041],\n",
      "        [0.2033],\n",
      "        [0.2027],\n",
      "        [0.2024],\n",
      "        [0.2019],\n",
      "        [0.2004],\n",
      "        [0.1987],\n",
      "        [0.1968],\n",
      "        [0.1954],\n",
      "        [0.1935]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4544144868850708, dv_loss = tensor([1.1194], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7025445699691772, iters = 24571\n",
      "Epoch = 91\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.272220253944397\n",
      "Prob Vector = tensor([[0.2620],\n",
      "        [0.2636],\n",
      "        [0.2650],\n",
      "        [0.2665],\n",
      "        [0.2680],\n",
      "        [0.2697],\n",
      "        [0.2713],\n",
      "        [0.2730],\n",
      "        [0.2744],\n",
      "        [0.2756],\n",
      "        [0.2770],\n",
      "        [0.2779],\n",
      "        [0.2789],\n",
      "        [0.2797],\n",
      "        [0.2808]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1944334506988525, dv_loss = tensor([2.7948], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9605734348297119, iters = 24621\n",
      "Epoch = 91\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.2515236437320709\n",
      "Prob Vector = tensor([[0.2581],\n",
      "        [0.2575],\n",
      "        [0.2571],\n",
      "        [0.2567],\n",
      "        [0.2566],\n",
      "        [0.2566],\n",
      "        [0.2556],\n",
      "        [0.2536],\n",
      "        [0.2514],\n",
      "        [0.2497],\n",
      "        [0.2480],\n",
      "        [0.2463],\n",
      "        [0.2443],\n",
      "        [0.2419],\n",
      "        [0.2393]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9443780779838562, dv_loss = tensor([2.7262], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2084400653839111, iters = 24671\n",
      "Epoch = 91\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.24879854917526245\n",
      "Prob Vector = tensor([[0.1474],\n",
      "        [0.1591],\n",
      "        [0.1785],\n",
      "        [0.2079],\n",
      "        [0.2291],\n",
      "        [0.2731],\n",
      "        [0.2744],\n",
      "        [0.2757],\n",
      "        [0.2773],\n",
      "        [0.2790],\n",
      "        [0.2810],\n",
      "        [0.2836],\n",
      "        [0.2862],\n",
      "        [0.2890],\n",
      "        [0.2907]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.523340702056885, dv_loss = tensor([4.0329], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.3678555488586426, iters = 24721\n",
      "Epoch = 91\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.13172589242458344\n",
      "Prob Vector = tensor([[0.1403],\n",
      "        [0.1385],\n",
      "        [0.1372],\n",
      "        [0.1358],\n",
      "        [0.1342],\n",
      "        [0.1330],\n",
      "        [0.1317],\n",
      "        [0.1305],\n",
      "        [0.1295],\n",
      "        [0.1286],\n",
      "        [0.1278],\n",
      "        [0.1273],\n",
      "        [0.1270],\n",
      "        [0.1270],\n",
      "        [0.1274]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4885503053665161, dv_loss = tensor([0.5849], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6700621843338013, iters = 24771\n",
      "Epoch = 91\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.20685473084449768\n",
      "Prob Vector = tensor([[0.1962],\n",
      "        [0.1977],\n",
      "        [0.1995],\n",
      "        [0.2015],\n",
      "        [0.2033],\n",
      "        [0.2050],\n",
      "        [0.2068],\n",
      "        [0.2084],\n",
      "        [0.2098],\n",
      "        [0.2113],\n",
      "        [0.2124],\n",
      "        [0.2128],\n",
      "        [0.2130],\n",
      "        [0.2129],\n",
      "        [0.2123]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1830766201019287, dv_loss = tensor([1.5607], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.9737067222595215, iters = 24821\n",
      "###################################\n",
      "Epoch = 92\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.15558578073978424\n",
      "Prob Vector = tensor([[0.1657],\n",
      "        [0.1640],\n",
      "        [0.1624],\n",
      "        [0.1608],\n",
      "        [0.1593],\n",
      "        [0.1578],\n",
      "        [0.1565],\n",
      "        [0.1554],\n",
      "        [0.1545],\n",
      "        [0.1533],\n",
      "        [0.1517],\n",
      "        [0.1502],\n",
      "        [0.1487],\n",
      "        [0.1472],\n",
      "        [0.1461]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.0846803188323975, dv_loss = tensor([2.6975], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0712099075317383, iters = 24841\n",
      "Epoch = 92\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.21797330677509308\n",
      "Prob Vector = tensor([[0.2087],\n",
      "        [0.2101],\n",
      "        [0.2115],\n",
      "        [0.2129],\n",
      "        [0.2142],\n",
      "        [0.2157],\n",
      "        [0.2171],\n",
      "        [0.2186],\n",
      "        [0.2199],\n",
      "        [0.2210],\n",
      "        [0.2222],\n",
      "        [0.2231],\n",
      "        [0.2241],\n",
      "        [0.2249],\n",
      "        [0.2257]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.396644115447998, dv_loss = tensor([1.7708], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7573347091674805, iters = 24891\n",
      "Epoch = 92\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.17485135793685913\n",
      "Prob Vector = tensor([[0.1822],\n",
      "        [0.1813],\n",
      "        [0.1805],\n",
      "        [0.1796],\n",
      "        [0.1790],\n",
      "        [0.1786],\n",
      "        [0.1767],\n",
      "        [0.1755],\n",
      "        [0.1740],\n",
      "        [0.1728],\n",
      "        [0.1714],\n",
      "        [0.1702],\n",
      "        [0.1686],\n",
      "        [0.1669],\n",
      "        [0.1654]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9382654428482056, dv_loss = tensor([2.9970], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2139817476272583, iters = 24941\n",
      "Epoch = 92\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.19364437460899353\n",
      "Prob Vector = tensor([[0.1201],\n",
      "        [0.1279],\n",
      "        [0.1372],\n",
      "        [0.1615],\n",
      "        [0.1799],\n",
      "        [0.2114],\n",
      "        [0.2126],\n",
      "        [0.2139],\n",
      "        [0.2153],\n",
      "        [0.2168],\n",
      "        [0.2183],\n",
      "        [0.2200],\n",
      "        [0.2218],\n",
      "        [0.2236],\n",
      "        [0.2245]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.0076613426208496, dv_loss = tensor([0.6893], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.8523354530334473, iters = 24991\n",
      "Epoch = 92\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.12884806096553802\n",
      "Prob Vector = tensor([[0.1372],\n",
      "        [0.1355],\n",
      "        [0.1341],\n",
      "        [0.1327],\n",
      "        [0.1312],\n",
      "        [0.1300],\n",
      "        [0.1289],\n",
      "        [0.1277],\n",
      "        [0.1267],\n",
      "        [0.1258],\n",
      "        [0.1251],\n",
      "        [0.1246],\n",
      "        [0.1243],\n",
      "        [0.1243],\n",
      "        [0.1247]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9601467847824097, dv_loss = tensor([2.0758], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.19595468044281, iters = 25041\n",
      "Epoch = 92\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.21316224336624146\n",
      "Prob Vector = tensor([[0.2027],\n",
      "        [0.2041],\n",
      "        [0.2059],\n",
      "        [0.2079],\n",
      "        [0.2098],\n",
      "        [0.2114],\n",
      "        [0.2132],\n",
      "        [0.2148],\n",
      "        [0.2163],\n",
      "        [0.2179],\n",
      "        [0.2187],\n",
      "        [0.2190],\n",
      "        [0.2191],\n",
      "        [0.2187],\n",
      "        [0.2180]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9241514205932617, dv_loss = tensor([3.8536], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2291245460510254, iters = 25091\n",
      "###################################\n",
      "Epoch = 93\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.16512227058410645\n",
      "Prob Vector = tensor([[0.1739],\n",
      "        [0.1725],\n",
      "        [0.1710],\n",
      "        [0.1697],\n",
      "        [0.1683],\n",
      "        [0.1669],\n",
      "        [0.1657],\n",
      "        [0.1648],\n",
      "        [0.1642],\n",
      "        [0.1635],\n",
      "        [0.1622],\n",
      "        [0.1607],\n",
      "        [0.1592],\n",
      "        [0.1578],\n",
      "        [0.1565]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1221940517425537, dv_loss = tensor([3.4434], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0301218032836914, iters = 25111\n",
      "Epoch = 93\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.23602207005023956\n",
      "Prob Vector = tensor([[0.2262],\n",
      "        [0.2277],\n",
      "        [0.2291],\n",
      "        [0.2305],\n",
      "        [0.2320],\n",
      "        [0.2336],\n",
      "        [0.2351],\n",
      "        [0.2367],\n",
      "        [0.2380],\n",
      "        [0.2392],\n",
      "        [0.2405],\n",
      "        [0.2415],\n",
      "        [0.2425],\n",
      "        [0.2434],\n",
      "        [0.2443]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6582034826278687, dv_loss = tensor([2.3012], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.49115788936615, iters = 25161\n",
      "Epoch = 93\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.2353639155626297\n",
      "Prob Vector = tensor([[0.2415],\n",
      "        [0.2410],\n",
      "        [0.2405],\n",
      "        [0.2401],\n",
      "        [0.2402],\n",
      "        [0.2401],\n",
      "        [0.2392],\n",
      "        [0.2377],\n",
      "        [0.2358],\n",
      "        [0.2342],\n",
      "        [0.2324],\n",
      "        [0.2306],\n",
      "        [0.2284],\n",
      "        [0.2258],\n",
      "        [0.2229]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.6581143736839294, dv_loss = tensor([3.4013], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.488182544708252, iters = 25211\n",
      "Epoch = 93\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.21800869703292847\n",
      "Prob Vector = tensor([[0.1301],\n",
      "        [0.1390],\n",
      "        [0.1525],\n",
      "        [0.1795],\n",
      "        [0.1996],\n",
      "        [0.2385],\n",
      "        [0.2399],\n",
      "        [0.2413],\n",
      "        [0.2431],\n",
      "        [0.2450],\n",
      "        [0.2470],\n",
      "        [0.2498],\n",
      "        [0.2526],\n",
      "        [0.2554],\n",
      "        [0.2568]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 6.950317859649658, dv_loss = tensor([7.1319], device='cuda:0', grad_fn=<AddBackward0>), reward = -4.798904895782471, iters = 25261\n",
      "Epoch = 93\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.10887158662080765\n",
      "Prob Vector = tensor([[0.1170],\n",
      "        [0.1154],\n",
      "        [0.1141],\n",
      "        [0.1127],\n",
      "        [0.1110],\n",
      "        [0.1097],\n",
      "        [0.1083],\n",
      "        [0.1072],\n",
      "        [0.1063],\n",
      "        [0.1056],\n",
      "        [0.1051],\n",
      "        [0.1049],\n",
      "        [0.1049],\n",
      "        [0.1052],\n",
      "        [0.1057]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.950936198234558, dv_loss = tensor([0.1852], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.20704901218414307, iters = 25311\n",
      "Epoch = 93\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.19186033308506012\n",
      "Prob Vector = tensor([[0.1812],\n",
      "        [0.1827],\n",
      "        [0.1845],\n",
      "        [0.1865],\n",
      "        [0.1884],\n",
      "        [0.1900],\n",
      "        [0.1918],\n",
      "        [0.1934],\n",
      "        [0.1948],\n",
      "        [0.1963],\n",
      "        [0.1973],\n",
      "        [0.1977],\n",
      "        [0.1979],\n",
      "        [0.1979],\n",
      "        [0.1974]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9441075325012207, dv_loss = tensor([0.3483], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2138369083404541, iters = 25361\n",
      "###################################\n",
      "Epoch = 94\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.13880638778209686\n",
      "Prob Vector = tensor([[0.1500],\n",
      "        [0.1481],\n",
      "        [0.1463],\n",
      "        [0.1446],\n",
      "        [0.1429],\n",
      "        [0.1414],\n",
      "        [0.1400],\n",
      "        [0.1388],\n",
      "        [0.1378],\n",
      "        [0.1362],\n",
      "        [0.1344],\n",
      "        [0.1328],\n",
      "        [0.1312],\n",
      "        [0.1295],\n",
      "        [0.1281]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.726438045501709, dv_loss = tensor([0.3709], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.4312567710876465, iters = 25381\n",
      "Epoch = 94\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.18861651420593262\n",
      "Prob Vector = tensor([[0.1791],\n",
      "        [0.1806],\n",
      "        [0.1820],\n",
      "        [0.1834],\n",
      "        [0.1848],\n",
      "        [0.1863],\n",
      "        [0.1877],\n",
      "        [0.1892],\n",
      "        [0.1905],\n",
      "        [0.1916],\n",
      "        [0.1929],\n",
      "        [0.1939],\n",
      "        [0.1949],\n",
      "        [0.1957],\n",
      "        [0.1967]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.8826476335525513, dv_loss = tensor([0.2221], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.2739468812942505, iters = 25431\n",
      "Epoch = 94\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.13501520454883575\n",
      "Prob Vector = tensor([[0.1443],\n",
      "        [0.1430],\n",
      "        [0.1419],\n",
      "        [0.1407],\n",
      "        [0.1396],\n",
      "        [0.1384],\n",
      "        [0.1364],\n",
      "        [0.1349],\n",
      "        [0.1335],\n",
      "        [0.1321],\n",
      "        [0.1306],\n",
      "        [0.1293],\n",
      "        [0.1280],\n",
      "        [0.1268],\n",
      "        [0.1259]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.2852022647857666, dv_loss = tensor([0.1056], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.12926554679870605, iters = 25481\n",
      "Epoch = 94\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.1684034764766693\n",
      "Prob Vector = tensor([[0.0997],\n",
      "        [0.1073],\n",
      "        [0.1172],\n",
      "        [0.1372],\n",
      "        [0.1553],\n",
      "        [0.1846],\n",
      "        [0.1858],\n",
      "        [0.1871],\n",
      "        [0.1886],\n",
      "        [0.1900],\n",
      "        [0.1914],\n",
      "        [0.1931],\n",
      "        [0.1948],\n",
      "        [0.1965],\n",
      "        [0.1975]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 3.0152201652526855, dv_loss = tensor([0.9899], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.8565309047698975, iters = 25531\n",
      "Epoch = 94\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.1148773655295372\n",
      "Prob Vector = tensor([[0.1242],\n",
      "        [0.1224],\n",
      "        [0.1210],\n",
      "        [0.1195],\n",
      "        [0.1175],\n",
      "        [0.1160],\n",
      "        [0.1145],\n",
      "        [0.1132],\n",
      "        [0.1122],\n",
      "        [0.1112],\n",
      "        [0.1105],\n",
      "        [0.1102],\n",
      "        [0.1101],\n",
      "        [0.1102],\n",
      "        [0.1106]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.80464506149292, dv_loss = tensor([0.6291], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.3546726703643799, iters = 25581\n",
      "Epoch = 94\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.18240198493003845\n",
      "Prob Vector = tensor([[0.1719],\n",
      "        [0.1734],\n",
      "        [0.1752],\n",
      "        [0.1771],\n",
      "        [0.1789],\n",
      "        [0.1805],\n",
      "        [0.1822],\n",
      "        [0.1838],\n",
      "        [0.1852],\n",
      "        [0.1867],\n",
      "        [0.1878],\n",
      "        [0.1881],\n",
      "        [0.1885],\n",
      "        [0.1886],\n",
      "        [0.1881]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.586815118789673, dv_loss = tensor([0.1612], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.4274628162384033, iters = 25631\n",
      "###################################\n",
      "Epoch = 95\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.12882426381111145\n",
      "Prob Vector = tensor([[0.1407],\n",
      "        [0.1387],\n",
      "        [0.1368],\n",
      "        [0.1351],\n",
      "        [0.1333],\n",
      "        [0.1316],\n",
      "        [0.1301],\n",
      "        [0.1287],\n",
      "        [0.1275],\n",
      "        [0.1258],\n",
      "        [0.1240],\n",
      "        [0.1225],\n",
      "        [0.1208],\n",
      "        [0.1191],\n",
      "        [0.1176]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6157066822052002, dv_loss = tensor([0.9413], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5436127185821533, iters = 25651\n",
      "Epoch = 95\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.17640267312526703\n",
      "Prob Vector = tensor([[0.1669],\n",
      "        [0.1684],\n",
      "        [0.1698],\n",
      "        [0.1712],\n",
      "        [0.1726],\n",
      "        [0.1741],\n",
      "        [0.1755],\n",
      "        [0.1769],\n",
      "        [0.1783],\n",
      "        [0.1794],\n",
      "        [0.1807],\n",
      "        [0.1817],\n",
      "        [0.1827],\n",
      "        [0.1835],\n",
      "        [0.1845]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.2388875484466553, dv_loss = tensor([0.2274], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.0801093578338623, iters = 25701\n",
      "Epoch = 95\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.12248758226633072\n",
      "Prob Vector = tensor([[0.1323],\n",
      "        [0.1309],\n",
      "        [0.1296],\n",
      "        [0.1282],\n",
      "        [0.1271],\n",
      "        [0.1256],\n",
      "        [0.1237],\n",
      "        [0.1224],\n",
      "        [0.1209],\n",
      "        [0.1194],\n",
      "        [0.1178],\n",
      "        [0.1165],\n",
      "        [0.1153],\n",
      "        [0.1142],\n",
      "        [0.1134]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5676863193511963, dv_loss = tensor([0.5189], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5903217792510986, iters = 25751\n",
      "Epoch = 95\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.1968381404876709\n",
      "Prob Vector = tensor([[0.1193],\n",
      "        [0.1275],\n",
      "        [0.1374],\n",
      "        [0.1629],\n",
      "        [0.1823],\n",
      "        [0.2157],\n",
      "        [0.2170],\n",
      "        [0.2183],\n",
      "        [0.2198],\n",
      "        [0.2212],\n",
      "        [0.2227],\n",
      "        [0.2246],\n",
      "        [0.2265],\n",
      "        [0.2282],\n",
      "        [0.2292]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5868197679519653, dv_loss = tensor([0.8953], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5722724199295044, iters = 25801\n",
      "Epoch = 95\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.1605970412492752\n",
      "Prob Vector = tensor([[0.1744],\n",
      "        [0.1723],\n",
      "        [0.1702],\n",
      "        [0.1680],\n",
      "        [0.1656],\n",
      "        [0.1635],\n",
      "        [0.1610],\n",
      "        [0.1587],\n",
      "        [0.1567],\n",
      "        [0.1551],\n",
      "        [0.1539],\n",
      "        [0.1530],\n",
      "        [0.1523],\n",
      "        [0.1521],\n",
      "        [0.1522]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.9107775092124939, dv_loss = tensor([1.0428], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.2464981079101562, iters = 25851\n",
      "Epoch = 95\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2365546077489853\n",
      "Prob Vector = tensor([[0.2240],\n",
      "        [0.2255],\n",
      "        [0.2275],\n",
      "        [0.2298],\n",
      "        [0.2320],\n",
      "        [0.2339],\n",
      "        [0.2362],\n",
      "        [0.2383],\n",
      "        [0.2402],\n",
      "        [0.2422],\n",
      "        [0.2433],\n",
      "        [0.2438],\n",
      "        [0.2442],\n",
      "        [0.2441],\n",
      "        [0.2434]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.2636499404907227, dv_loss = tensor([2.7232], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.891486644744873, iters = 25901\n",
      "###################################\n",
      "Epoch = 96\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.1917477697134018\n",
      "Prob Vector = tensor([[0.2007],\n",
      "        [0.1995],\n",
      "        [0.1983],\n",
      "        [0.1973],\n",
      "        [0.1959],\n",
      "        [0.1946],\n",
      "        [0.1934],\n",
      "        [0.1924],\n",
      "        [0.1918],\n",
      "        [0.1908],\n",
      "        [0.1889],\n",
      "        [0.1867],\n",
      "        [0.1842],\n",
      "        [0.1819],\n",
      "        [0.1796]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.8494593501091003, dv_loss = tensor([4.2132], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3047950267791748, iters = 25921\n",
      "Epoch = 96\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.24804864823818207\n",
      "Prob Vector = tensor([[0.2374],\n",
      "        [0.2390],\n",
      "        [0.2404],\n",
      "        [0.2420],\n",
      "        [0.2436],\n",
      "        [0.2454],\n",
      "        [0.2470],\n",
      "        [0.2488],\n",
      "        [0.2502],\n",
      "        [0.2515],\n",
      "        [0.2530],\n",
      "        [0.2540],\n",
      "        [0.2552],\n",
      "        [0.2561],\n",
      "        [0.2573]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1342673301696777, dv_loss = tensor([3.0477], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0176351070404053, iters = 25971\n",
      "Epoch = 96\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.2174200415611267\n",
      "Prob Vector = tensor([[0.2268],\n",
      "        [0.2259],\n",
      "        [0.2250],\n",
      "        [0.2240],\n",
      "        [0.2233],\n",
      "        [0.2229],\n",
      "        [0.2215],\n",
      "        [0.2195],\n",
      "        [0.2173],\n",
      "        [0.2151],\n",
      "        [0.2129],\n",
      "        [0.2106],\n",
      "        [0.2081],\n",
      "        [0.2055],\n",
      "        [0.2028]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 0.7531159520149231, dv_loss = tensor([4.3354], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.3963642120361328, iters = 26021\n",
      "Epoch = 96\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.23112870752811432\n",
      "Prob Vector = tensor([[0.1312],\n",
      "        [0.1408],\n",
      "        [0.1571],\n",
      "        [0.1855],\n",
      "        [0.2083],\n",
      "        [0.2567],\n",
      "        [0.2580],\n",
      "        [0.2594],\n",
      "        [0.2610],\n",
      "        [0.2628],\n",
      "        [0.2647],\n",
      "        [0.2672],\n",
      "        [0.2695],\n",
      "        [0.2716],\n",
      "        [0.2730]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.007285118103027, dv_loss = tensor([1.5224], device='cuda:0', grad_fn=<AddBackward0>), reward = -1.8550889492034912, iters = 26071\n",
      "Epoch = 96\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.18024283647537231\n",
      "Prob Vector = tensor([[0.1959],\n",
      "        [0.1941],\n",
      "        [0.1920],\n",
      "        [0.1895],\n",
      "        [0.1868],\n",
      "        [0.1843],\n",
      "        [0.1816],\n",
      "        [0.1790],\n",
      "        [0.1767],\n",
      "        [0.1745],\n",
      "        [0.1726],\n",
      "        [0.1708],\n",
      "        [0.1693],\n",
      "        [0.1685],\n",
      "        [0.1679]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.574107050895691, dv_loss = tensor([1.9070], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5783630609512329, iters = 26121\n",
      "Epoch = 96\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2518431842327118\n",
      "Prob Vector = tensor([[0.2390],\n",
      "        [0.2404],\n",
      "        [0.2425],\n",
      "        [0.2448],\n",
      "        [0.2470],\n",
      "        [0.2490],\n",
      "        [0.2514],\n",
      "        [0.2537],\n",
      "        [0.2557],\n",
      "        [0.2578],\n",
      "        [0.2589],\n",
      "        [0.2594],\n",
      "        [0.2597],\n",
      "        [0.2596],\n",
      "        [0.2588]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5595896244049072, dv_loss = tensor([2.2155], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5920355319976807, iters = 26171\n",
      "###################################\n",
      "Epoch = 97\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.20967215299606323\n",
      "Prob Vector = tensor([[0.2180],\n",
      "        [0.2170],\n",
      "        [0.2160],\n",
      "        [0.2152],\n",
      "        [0.2139],\n",
      "        [0.2126],\n",
      "        [0.2115],\n",
      "        [0.2105],\n",
      "        [0.2099],\n",
      "        [0.2090],\n",
      "        [0.2073],\n",
      "        [0.2050],\n",
      "        [0.2023],\n",
      "        [0.1998],\n",
      "        [0.1971]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6098527908325195, dv_loss = tensor([0.4262], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5412161350250244, iters = 26191\n",
      "Epoch = 97\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.2587563097476959\n",
      "Prob Vector = tensor([[0.2479],\n",
      "        [0.2496],\n",
      "        [0.2511],\n",
      "        [0.2527],\n",
      "        [0.2542],\n",
      "        [0.2561],\n",
      "        [0.2577],\n",
      "        [0.2595],\n",
      "        [0.2609],\n",
      "        [0.2622],\n",
      "        [0.2637],\n",
      "        [0.2647],\n",
      "        [0.2659],\n",
      "        [0.2669],\n",
      "        [0.2681]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.9870729446411133, dv_loss = tensor([0.6025], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.16296792030334473, iters = 26241\n",
      "Epoch = 97\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.21984383463859558\n",
      "Prob Vector = tensor([[0.2303],\n",
      "        [0.2293],\n",
      "        [0.2283],\n",
      "        [0.2272],\n",
      "        [0.2265],\n",
      "        [0.2258],\n",
      "        [0.2241],\n",
      "        [0.2219],\n",
      "        [0.2196],\n",
      "        [0.2173],\n",
      "        [0.2148],\n",
      "        [0.2122],\n",
      "        [0.2096],\n",
      "        [0.2068],\n",
      "        [0.2040]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.444191813468933, dv_loss = tensor([2.1919], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.704666018486023, iters = 26291\n",
      "Epoch = 97\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.2386789470911026\n",
      "Prob Vector = tensor([[0.1323],\n",
      "        [0.1429],\n",
      "        [0.1604],\n",
      "        [0.1897],\n",
      "        [0.2136],\n",
      "        [0.2664],\n",
      "        [0.2677],\n",
      "        [0.2691],\n",
      "        [0.2707],\n",
      "        [0.2725],\n",
      "        [0.2745],\n",
      "        [0.2770],\n",
      "        [0.2793],\n",
      "        [0.2815],\n",
      "        [0.2828]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 2.46907114982605, dv_loss = tensor([0.6957], device='cuda:0', grad_fn=<AddBackward0>), reward = -0.3196995258331299, iters = 26341\n",
      "Epoch = 97\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.21759845316410065\n",
      "Prob Vector = tensor([[0.2349],\n",
      "        [0.2339],\n",
      "        [0.2317],\n",
      "        [0.2289],\n",
      "        [0.2258],\n",
      "        [0.2230],\n",
      "        [0.2198],\n",
      "        [0.2170],\n",
      "        [0.2142],\n",
      "        [0.2114],\n",
      "        [0.2087],\n",
      "        [0.2062],\n",
      "        [0.2042],\n",
      "        [0.2027],\n",
      "        [0.2016]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.045227289199829, dv_loss = tensor([3.4271], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.1027584075927734, iters = 26391\n",
      "Epoch = 97\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.29872921109199524\n",
      "Prob Vector = tensor([[0.2857],\n",
      "        [0.2872],\n",
      "        [0.2892],\n",
      "        [0.2915],\n",
      "        [0.2937],\n",
      "        [0.2957],\n",
      "        [0.2982],\n",
      "        [0.3007],\n",
      "        [0.3030],\n",
      "        [0.3051],\n",
      "        [0.3063],\n",
      "        [0.3064],\n",
      "        [0.3064],\n",
      "        [0.3061],\n",
      "        [0.3056]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.328223705291748, dv_loss = tensor([3.4436], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.817939043045044, iters = 26441\n",
      "###################################\n",
      "Epoch = 98\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.275622695684433\n",
      "Prob Vector = tensor([[0.2782],\n",
      "        [0.2783],\n",
      "        [0.2785],\n",
      "        [0.2788],\n",
      "        [0.2785],\n",
      "        [0.2777],\n",
      "        [0.2770],\n",
      "        [0.2762],\n",
      "        [0.2763],\n",
      "        [0.2769],\n",
      "        [0.2769],\n",
      "        [0.2750],\n",
      "        [0.2719],\n",
      "        [0.2692],\n",
      "        [0.2650]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.124110221862793, dv_loss = tensor([2.9585], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.021190881729126, iters = 26461\n",
      "Epoch = 98\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.38961732387542725\n",
      "Prob Vector = tensor([[0.3755],\n",
      "        [0.3778],\n",
      "        [0.3793],\n",
      "        [0.3816],\n",
      "        [0.3835],\n",
      "        [0.3858],\n",
      "        [0.3879],\n",
      "        [0.3904],\n",
      "        [0.3925],\n",
      "        [0.3941],\n",
      "        [0.3963],\n",
      "        [0.3976],\n",
      "        [0.3996],\n",
      "        [0.4006],\n",
      "        [0.4019]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.4318476915359497, dv_loss = tensor([2.6107], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.7115150690078735, iters = 26511\n",
      "Epoch = 98\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.6991595029830933\n",
      "Prob Vector = tensor([[0.6934],\n",
      "        [0.6979],\n",
      "        [0.7014],\n",
      "        [0.7030],\n",
      "        [0.7044],\n",
      "        [0.7067],\n",
      "        [0.7082],\n",
      "        [0.7095],\n",
      "        [0.7082],\n",
      "        [0.7047],\n",
      "        [0.7018],\n",
      "        [0.6974],\n",
      "        [0.6924],\n",
      "        [0.6846],\n",
      "        [0.6740]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.07168447971344, dv_loss = tensor([2.5760], device='cuda:0', grad_fn=<AddBackward0>), reward = 1.0696855783462524, iters = 26561\n",
      "Epoch = 98\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.3016575872898102\n",
      "Prob Vector = tensor([[0.1440],\n",
      "        [0.1597],\n",
      "        [0.1876],\n",
      "        [0.2268],\n",
      "        [0.2592],\n",
      "        [0.3427],\n",
      "        [0.3442],\n",
      "        [0.3460],\n",
      "        [0.3483],\n",
      "        [0.3510],\n",
      "        [0.3540],\n",
      "        [0.3581],\n",
      "        [0.3626],\n",
      "        [0.3685],\n",
      "        [0.3723]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.224989891052246, dv_loss = tensor([5.9043], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.080343723297119, iters = 26611\n",
      "Epoch = 98\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.2096243053674698\n",
      "Prob Vector = tensor([[0.2378],\n",
      "        [0.2336],\n",
      "        [0.2298],\n",
      "        [0.2252],\n",
      "        [0.2195],\n",
      "        [0.2151],\n",
      "        [0.2110],\n",
      "        [0.2071],\n",
      "        [0.2036],\n",
      "        [0.2004],\n",
      "        [0.1971],\n",
      "        [0.1943],\n",
      "        [0.1918],\n",
      "        [0.1898],\n",
      "        [0.1883]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6027921438217163, dv_loss = tensor([2.5874], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.542261004447937, iters = 26661\n",
      "Epoch = 98\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.27889639139175415\n",
      "Prob Vector = tensor([[0.2636],\n",
      "        [0.2653],\n",
      "        [0.2674],\n",
      "        [0.2697],\n",
      "        [0.2721],\n",
      "        [0.2740],\n",
      "        [0.2765],\n",
      "        [0.2790],\n",
      "        [0.2816],\n",
      "        [0.2847],\n",
      "        [0.2874],\n",
      "        [0.2885],\n",
      "        [0.2900],\n",
      "        [0.2915],\n",
      "        [0.2922]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.5246902704238892, dv_loss = tensor([2.2140], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6194494962692261, iters = 26711\n",
      "###################################\n",
      "Epoch = 99\n",
      "Iteration = 0\n",
      "Mean Of Prob Vector = 0.25921720266342163\n",
      "Prob Vector = tensor([[0.2696],\n",
      "        [0.2694],\n",
      "        [0.2691],\n",
      "        [0.2689],\n",
      "        [0.2679],\n",
      "        [0.2667],\n",
      "        [0.2656],\n",
      "        [0.2643],\n",
      "        [0.2628],\n",
      "        [0.2596],\n",
      "        [0.2551],\n",
      "        [0.2506],\n",
      "        [0.2454],\n",
      "        [0.2395],\n",
      "        [0.2338]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.527848720550537, dv_loss = tensor([2.2715], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6157059669494629, iters = 26731\n",
      "Epoch = 99\n",
      "Iteration = 50\n",
      "Mean Of Prob Vector = 0.300869345664978\n",
      "Prob Vector = tensor([[0.2867],\n",
      "        [0.2890],\n",
      "        [0.2908],\n",
      "        [0.2930],\n",
      "        [0.2949],\n",
      "        [0.2972],\n",
      "        [0.2991],\n",
      "        [0.3015],\n",
      "        [0.3035],\n",
      "        [0.3052],\n",
      "        [0.3073],\n",
      "        [0.3087],\n",
      "        [0.3104],\n",
      "        [0.3119],\n",
      "        [0.3139]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.6058349609375, dv_loss = tensor([1.8685], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.5363373756408691, iters = 26781\n",
      "Epoch = 99\n",
      "Iteration = 100\n",
      "Mean Of Prob Vector = 0.32108378410339355\n",
      "Prob Vector = tensor([[0.3441],\n",
      "        [0.3439],\n",
      "        [0.3441],\n",
      "        [0.3432],\n",
      "        [0.3416],\n",
      "        [0.3395],\n",
      "        [0.3339],\n",
      "        [0.3278],\n",
      "        [0.3209],\n",
      "        [0.3130],\n",
      "        [0.3047],\n",
      "        [0.2991],\n",
      "        [0.2928],\n",
      "        [0.2871],\n",
      "        [0.2806]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.1897661685943604, dv_loss = tensor([3.8723], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.950767993927002, iters = 26831\n",
      "Epoch = 99\n",
      "Iteration = 150\n",
      "Mean Of Prob Vector = 0.24783512949943542\n",
      "Prob Vector = tensor([[0.1267],\n",
      "        [0.1352],\n",
      "        [0.1542],\n",
      "        [0.1878],\n",
      "        [0.2168],\n",
      "        [0.2787],\n",
      "        [0.2803],\n",
      "        [0.2821],\n",
      "        [0.2843],\n",
      "        [0.2866],\n",
      "        [0.2893],\n",
      "        [0.2930],\n",
      "        [0.2970],\n",
      "        [0.3011],\n",
      "        [0.3045]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 4.3838419914245605, dv_loss = tensor([5.2401], device='cuda:0', grad_fn=<AddBackward0>), reward = -2.2389867305755615, iters = 26881\n",
      "Epoch = 99\n",
      "Iteration = 200\n",
      "Mean Of Prob Vector = 0.18974696099758148\n",
      "Prob Vector = tensor([[0.2197],\n",
      "        [0.2150],\n",
      "        [0.2106],\n",
      "        [0.2049],\n",
      "        [0.1994],\n",
      "        [0.1950],\n",
      "        [0.1906],\n",
      "        [0.1866],\n",
      "        [0.1833],\n",
      "        [0.1801],\n",
      "        [0.1769],\n",
      "        [0.1742],\n",
      "        [0.1717],\n",
      "        [0.1698],\n",
      "        [0.1684]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.507627010345459, dv_loss = tensor([1.0097], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.6372380256652832, iters = 26931\n",
      "Epoch = 99\n",
      "Iteration = 250\n",
      "Mean Of Prob Vector = 0.2626841962337494\n",
      "Prob Vector = tensor([[0.2475],\n",
      "        [0.2491],\n",
      "        [0.2513],\n",
      "        [0.2537],\n",
      "        [0.2559],\n",
      "        [0.2579],\n",
      "        [0.2603],\n",
      "        [0.2628],\n",
      "        [0.2653],\n",
      "        [0.2679],\n",
      "        [0.2705],\n",
      "        [0.2721],\n",
      "        [0.2736],\n",
      "        [0.2755],\n",
      "        [0.2769]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "val_curr_loss = 1.3108464479446411, dv_loss = tensor([1.2342], device='cuda:0', grad_fn=<AddBackward0>), reward = 0.8327690362930298, iters = 26981\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_of_epochs):\n",
    "    print(\"###################################\")\n",
    "    for T in range(270):\n",
    "        \n",
    "        #Make Time Window Batches\n",
    "        x_batch, y_batch = funtions_for_dvrl.MovingBatch(x_train, y_train, time_window_size, T)\n",
    "        #Pass Throught Data Valuator MLP\n",
    "        inputs = torch.cat((x_batch,y_batch), 1).to(device)\n",
    "        #inputs = PositionalEncoding(inputs)\n",
    "        prob_vector, hid = model_1.forward(inputs)\n",
    "        #if i == 0:\n",
    "            #prob_vector = torch.ones(x_batch.shape[0],1)\n",
    "        select = funtions_for_dvrl.SelectionFromProb_2(prob_vector)\n",
    "        select_for_lstm = select.clone().detach().to(device)\n",
    "        if torch.all(select_for_lstm == torch.zeros_like(select_for_lstm)):\n",
    "            continue\n",
    "        x_selected_batch, y_selected_batch = funtions_for_dvrl.SelectBatches(x_batch, y_batch, select_for_lstm)\n",
    "        mean = torch.mean(prob_vector).clone().detach()\n",
    "        # if torch.all(select==0).item():\n",
    "        #     continue\n",
    "        if T % 50== 0:\n",
    "            print(f'Epoch = {i}')\n",
    "            print(f'Iteration = {T}')\n",
    "            print(f'Mean Of Prob Vector = {mean}')\n",
    "            print(f'Prob Vector = {prob_vector}')\n",
    "            # print(f'Mean Of Hidden Vector = {mean_hid}')\n",
    "            # print(f'Hidden State Just Before Sigmoid = {hid}')\n",
    "        #Reshape For LSTM\n",
    "        x_selected_batch = torch.unsqueeze(x_selected_batch,2)\n",
    "        x_selected_batch = x_selected_batch.transpose(1,0).float().detach()\n",
    "        y_selected_batch = torch.unsqueeze(y_selected_batch,2)\n",
    "        y_selected_batch = y_selected_batch.transpose(1,0).float().detach()\n",
    "        #Pass Through LSTM\n",
    "        loss = model_4.train_model(input_tensor=x_selected_batch, target_tensor=y_selected_batch, optimizer = optim_for_lstm, \n",
    "                                                 training_prediction = 'teacher_forcing', dynamic_tf = False)\n",
    "        y_hat_valid = model_4.predict(x_valid, lookahead)\n",
    "        val_loss = criterion_for_lstm(y_hat_valid,y_valid)\n",
    "        #Update The Moving Average\n",
    "        if iters > 1000:\n",
    "            moving_avg_loss = funtions_for_dvrl.MAL(val_loss, iters+1+1-800, moving_avg_loss)\n",
    "        #Determine The Log_Pi Loss And Reward Scale\n",
    "        reward = moving_avg_loss - val_loss\n",
    "        data_valuator_loss = funtions_for_dvrl.DataValuator_LogPi_2(select_for_lstm, prob_vector, epsilon, threshold, reward, explore_parameter=1e3)\n",
    "        #Plot Everything\n",
    "        # lstm_predict_plot.append(lstm_predict)\n",
    "        train_loss_plot.append(loss)\n",
    "        mov_avg_plot.append(moving_avg_loss)\n",
    "        reward_plot.append(reward)\n",
    "        val_loss_plot.append(val_loss)\n",
    "        iteration.append(iters)\n",
    "        iters+=1\n",
    "        if T % 50 == 0:\n",
    "            print(f\"val_curr_loss = {val_loss}, dv_loss = {data_valuator_loss}, reward = {reward}, iters = {iters}\")\n",
    "\n",
    "        if iters < 12500:\n",
    "            continue\n",
    "        optim_for_dve.zero_grad()\n",
    "        data_valuator_loss.backward()\n",
    "        optim_for_dve.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mean_of_hidden)):\n",
    "    mean_of_hidden[i] = mean_of_hidden[i].to(\"cpu\")\n",
    "for i in range(len(val_loss_plot)):\n",
    "    val_loss_plot[i] = val_loss_plot[i].to(\"cpu\")\n",
    "for i in range(len(reward_plot)):\n",
    "    reward_plot[i] = reward_plot[i].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_plot_list = [tensor.cpu().detach() for tensor in reward_plot]\n",
    "mov_avg_plot_list = [tensor.cpu().detach() for tensor in mov_avg_plot]\n",
    "val_plot_list = [tensor.cpu().detach() for tensor in val_loss_plot]\n",
    "iteration_plot_list = [tensor for tensor in iteration]\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "axes[0].plot(iteration_plot_list[12500:20000], reward_plot_list[12500:20000], label=\"Reward Loss Plot\")\n",
    "axes[1].plot(iteration_plot_list[12500:20000], mov_avg_plot_list[12500:20000], label=\"Moving Avg Plot\")\n",
    "axes[2].plot(iteration_plot_list[12500:20000], val_plot_list[12500:20000], label=\"Val Loss Plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2600],\n",
      "        [0.2596],\n",
      "        [0.2592],\n",
      "        [0.2585],\n",
      "        [0.2572],\n",
      "        [0.2553],\n",
      "        [0.2537],\n",
      "        [0.2513],\n",
      "        [0.2488],\n",
      "        [0.2442],\n",
      "        [0.2392],\n",
      "        [0.2343],\n",
      "        [0.2281],\n",
      "        [0.2222],\n",
      "        [0.2163],\n",
      "        [0.2110],\n",
      "        [0.2067],\n",
      "        [0.2030],\n",
      "        [0.1989],\n",
      "        [0.1956],\n",
      "        [0.1933],\n",
      "        [0.1917],\n",
      "        [0.1899],\n",
      "        [0.1880],\n",
      "        [0.1867],\n",
      "        [0.1854],\n",
      "        [0.1851],\n",
      "        [0.1853],\n",
      "        [0.1862],\n",
      "        [0.1869],\n",
      "        [0.1886],\n",
      "        [0.1905],\n",
      "        [0.1932],\n",
      "        [0.1966],\n",
      "        [0.2003],\n",
      "        [0.2045],\n",
      "        [0.2090],\n",
      "        [0.2140],\n",
      "        [0.2189],\n",
      "        [0.2236],\n",
      "        [0.2277],\n",
      "        [0.2314],\n",
      "        [0.2346],\n",
      "        [0.2373],\n",
      "        [0.2395],\n",
      "        [0.2414],\n",
      "        [0.2430],\n",
      "        [0.2447],\n",
      "        [0.2462],\n",
      "        [0.2479],\n",
      "        [0.2496],\n",
      "        [0.2515],\n",
      "        [0.2532],\n",
      "        [0.2551],\n",
      "        [0.2568],\n",
      "        [0.2588],\n",
      "        [0.2605],\n",
      "        [0.2625],\n",
      "        [0.2643],\n",
      "        [0.2658],\n",
      "        [0.2679],\n",
      "        [0.2694],\n",
      "        [0.2712],\n",
      "        [0.2728],\n",
      "        [0.2749],\n",
      "        [0.2775],\n",
      "        [0.2810],\n",
      "        [0.2843],\n",
      "        [0.2874],\n",
      "        [0.2899],\n",
      "        [0.2918],\n",
      "        [0.2935],\n",
      "        [0.2946],\n",
      "        [0.2945],\n",
      "        [0.2936],\n",
      "        [0.2926],\n",
      "        [0.2915],\n",
      "        [0.2901],\n",
      "        [0.2882],\n",
      "        [0.2858],\n",
      "        [0.2839],\n",
      "        [0.2820],\n",
      "        [0.2802],\n",
      "        [0.2783],\n",
      "        [0.2759],\n",
      "        [0.2735],\n",
      "        [0.2711],\n",
      "        [0.2685],\n",
      "        [0.2664],\n",
      "        [0.2652],\n",
      "        [0.2645],\n",
      "        [0.2644],\n",
      "        [0.2636],\n",
      "        [0.2627],\n",
      "        [0.2619],\n",
      "        [0.2609],\n",
      "        [0.2597],\n",
      "        [0.2585],\n",
      "        [0.2571],\n",
      "        [0.2561],\n",
      "        [0.2546],\n",
      "        [0.2530],\n",
      "        [0.2510],\n",
      "        [0.2484],\n",
      "        [0.2452],\n",
      "        [0.2410],\n",
      "        [0.2357],\n",
      "        [0.2311],\n",
      "        [0.2256],\n",
      "        [0.2204],\n",
      "        [0.2150],\n",
      "        [0.2099],\n",
      "        [0.2054],\n",
      "        [0.2014],\n",
      "        [0.1975],\n",
      "        [0.1947],\n",
      "        [0.1924],\n",
      "        [0.1908],\n",
      "        [0.1942],\n",
      "        [0.1970],\n",
      "        [0.1893],\n",
      "        [0.1766],\n",
      "        [0.1802],\n",
      "        [0.1618],\n",
      "        [0.1490],\n",
      "        [0.1462],\n",
      "        [0.1362],\n",
      "        [0.1346],\n",
      "        [0.1588],\n",
      "        [0.1560],\n",
      "        [0.1554],\n",
      "        [0.1459],\n",
      "        [0.1540],\n",
      "        [0.1474],\n",
      "        [0.1383],\n",
      "        [0.1515],\n",
      "        [0.1685],\n",
      "        [0.1464],\n",
      "        [0.1431],\n",
      "        [0.1481],\n",
      "        [0.1467],\n",
      "        [0.1556],\n",
      "        [0.1702],\n",
      "        [0.1729],\n",
      "        [0.1549],\n",
      "        [0.1559],\n",
      "        [0.1494],\n",
      "        [0.1445],\n",
      "        [0.1306],\n",
      "        [0.1298],\n",
      "        [0.1220],\n",
      "        [0.1302],\n",
      "        [0.1467],\n",
      "        [0.1784],\n",
      "        [0.2053],\n",
      "        [0.2609],\n",
      "        [0.2623],\n",
      "        [0.2639],\n",
      "        [0.2657],\n",
      "        [0.2677],\n",
      "        [0.2699],\n",
      "        [0.2730],\n",
      "        [0.2768],\n",
      "        [0.2809],\n",
      "        [0.2845],\n",
      "        [0.2872],\n",
      "        [0.2898],\n",
      "        [0.2914],\n",
      "        [0.2923],\n",
      "        [0.2921],\n",
      "        [0.2923],\n",
      "        [0.2919],\n",
      "        [0.2911],\n",
      "        [0.2900],\n",
      "        [0.2878],\n",
      "        [0.2858],\n",
      "        [0.2838],\n",
      "        [0.2819],\n",
      "        [0.2793],\n",
      "        [0.2764],\n",
      "        [0.2733],\n",
      "        [0.2705],\n",
      "        [0.2680],\n",
      "        [0.2659],\n",
      "        [0.2640],\n",
      "        [0.2625],\n",
      "        [0.2620],\n",
      "        [0.2611],\n",
      "        [0.2595],\n",
      "        [0.2582],\n",
      "        [0.2563],\n",
      "        [0.2557],\n",
      "        [0.2554],\n",
      "        [0.2544],\n",
      "        [0.2538],\n",
      "        [0.2529],\n",
      "        [0.2514],\n",
      "        [0.2510],\n",
      "        [0.2487],\n",
      "        [0.2469],\n",
      "        [0.2432],\n",
      "        [0.2384],\n",
      "        [0.2342],\n",
      "        [0.2283],\n",
      "        [0.2220],\n",
      "        [0.2166],\n",
      "        [0.2111],\n",
      "        [0.2059],\n",
      "        [0.2020],\n",
      "        [0.1985],\n",
      "        [0.1951],\n",
      "        [0.1920],\n",
      "        [0.1892],\n",
      "        [0.1870],\n",
      "        [0.1852],\n",
      "        [0.1842],\n",
      "        [0.1838],\n",
      "        [0.1838],\n",
      "        [0.1847],\n",
      "        [0.1857],\n",
      "        [0.1870],\n",
      "        [0.1882],\n",
      "        [0.1897],\n",
      "        [0.1910],\n",
      "        [0.1933],\n",
      "        [0.1960],\n",
      "        [0.1992],\n",
      "        [0.2027],\n",
      "        [0.2066],\n",
      "        [0.2104],\n",
      "        [0.2143],\n",
      "        [0.2181],\n",
      "        [0.2213],\n",
      "        [0.2244],\n",
      "        [0.2270],\n",
      "        [0.2291],\n",
      "        [0.2311],\n",
      "        [0.2326],\n",
      "        [0.2343],\n",
      "        [0.2361],\n",
      "        [0.2383],\n",
      "        [0.2402],\n",
      "        [0.2422],\n",
      "        [0.2442],\n",
      "        [0.2456],\n",
      "        [0.2468],\n",
      "        [0.2478],\n",
      "        [0.2489],\n",
      "        [0.2503],\n",
      "        [0.2517],\n",
      "        [0.2538],\n",
      "        [0.2554],\n",
      "        [0.2576],\n",
      "        [0.2599],\n",
      "        [0.2622],\n",
      "        [0.2641],\n",
      "        [0.2666],\n",
      "        [0.2691],\n",
      "        [0.2721],\n",
      "        [0.2754],\n",
      "        [0.2784],\n",
      "        [0.2800],\n",
      "        [0.2816],\n",
      "        [0.2836],\n",
      "        [0.2850],\n",
      "        [0.2856],\n",
      "        [0.2866],\n",
      "        [0.2872],\n",
      "        [0.2868],\n",
      "        [0.2860],\n",
      "        [0.2846],\n",
      "        [0.2828],\n",
      "        [0.2809],\n",
      "        [0.2789],\n",
      "        [0.2759],\n",
      "        [0.2729],\n",
      "        [0.2703],\n",
      "        [0.2681],\n",
      "        [0.2662],\n",
      "        [0.2645]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputt = torch.cat((x_train[:,:] ,y_train[:,:]), 1).to(device)\n",
    "prob_vector, hid = model_1.forward(inputt)\n",
    "print(prob_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0 has prob tensor([0.2600], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 1 has prob tensor([0.2596], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 2 has prob tensor([0.2592], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 3 has prob tensor([0.2585], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 4 has prob tensor([0.2572], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 5 has prob tensor([0.2553], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 6 has prob tensor([0.2537], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 7 has prob tensor([0.2513], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 8 has prob tensor([0.2488], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 9 has prob tensor([0.2442], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 10 has prob tensor([0.2392], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 11 has prob tensor([0.2343], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 12 has prob tensor([0.2281], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 13 has prob tensor([0.2222], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 14 has prob tensor([0.2163], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 15 has prob tensor([0.2110], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 16 has prob tensor([0.2067], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 17 has prob tensor([0.2030], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 18 has prob tensor([0.1989], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 19 has prob tensor([0.1956], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 20 has prob tensor([0.1933], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 21 has prob tensor([0.1917], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 22 has prob tensor([0.1899], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 23 has prob tensor([0.1880], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 24 has prob tensor([0.1867], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 25 has prob tensor([0.1854], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 26 has prob tensor([0.1851], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 27 has prob tensor([0.1853], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 28 has prob tensor([0.1862], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 29 has prob tensor([0.1869], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 30 has prob tensor([0.1886], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 31 has prob tensor([0.1905], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 32 has prob tensor([0.1932], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 33 has prob tensor([0.1966], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 34 has prob tensor([0.2003], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 35 has prob tensor([0.2045], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 36 has prob tensor([0.2090], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 37 has prob tensor([0.2140], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 38 has prob tensor([0.2189], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 39 has prob tensor([0.2236], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 40 has prob tensor([0.2277], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 41 has prob tensor([0.2314], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 42 has prob tensor([0.2346], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 43 has prob tensor([0.2373], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 44 has prob tensor([0.2395], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 45 has prob tensor([0.2414], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 46 has prob tensor([0.2430], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 47 has prob tensor([0.2447], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 48 has prob tensor([0.2462], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 49 has prob tensor([0.2479], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 50 has prob tensor([0.2496], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 51 has prob tensor([0.2515], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 52 has prob tensor([0.2532], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 53 has prob tensor([0.2551], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 54 has prob tensor([0.2568], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 55 has prob tensor([0.2588], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 56 has prob tensor([0.2605], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 57 has prob tensor([0.2625], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 58 has prob tensor([0.2643], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 59 has prob tensor([0.2658], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 60 has prob tensor([0.2679], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 61 has prob tensor([0.2694], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 62 has prob tensor([0.2712], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 63 has prob tensor([0.2728], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 64 has prob tensor([0.2749], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 65 has prob tensor([0.2775], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 66 has prob tensor([0.2810], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 67 has prob tensor([0.2843], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 68 has prob tensor([0.2874], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 69 has prob tensor([0.2899], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 70 has prob tensor([0.2918], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 71 has prob tensor([0.2935], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 72 has prob tensor([0.2946], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 73 has prob tensor([0.2945], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 74 has prob tensor([0.2936], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 75 has prob tensor([0.2926], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 76 has prob tensor([0.2915], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 77 has prob tensor([0.2901], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 78 has prob tensor([0.2882], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 79 has prob tensor([0.2858], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 80 has prob tensor([0.2839], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 81 has prob tensor([0.2820], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 82 has prob tensor([0.2802], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 83 has prob tensor([0.2783], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 84 has prob tensor([0.2759], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 85 has prob tensor([0.2735], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 86 has prob tensor([0.2711], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 87 has prob tensor([0.2685], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 88 has prob tensor([0.2664], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 89 has prob tensor([0.2652], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 90 has prob tensor([0.2645], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 91 has prob tensor([0.2644], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 92 has prob tensor([0.2636], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 93 has prob tensor([0.2627], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 94 has prob tensor([0.2619], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 95 has prob tensor([0.2609], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 96 has prob tensor([0.2597], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 97 has prob tensor([0.2585], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 98 has prob tensor([0.2571], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 99 has prob tensor([0.2561], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 100 has prob tensor([0.2546], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 101 has prob tensor([0.2530], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 102 has prob tensor([0.2510], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 103 has prob tensor([0.2484], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 104 has prob tensor([0.2452], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 105 has prob tensor([0.2410], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 106 has prob tensor([0.2357], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 107 has prob tensor([0.2311], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 108 has prob tensor([0.2256], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 109 has prob tensor([0.2204], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 110 has prob tensor([0.2150], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 111 has prob tensor([0.2099], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 112 has prob tensor([0.2054], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 113 has prob tensor([0.2014], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 114 has prob tensor([0.1975], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 115 has prob tensor([0.1947], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 116 has prob tensor([0.1924], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 117 has prob tensor([0.1908], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 118 has prob tensor([0.1942], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 119 has prob tensor([0.1970], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 120 has prob tensor([0.1893], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 121 has prob tensor([0.1766], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 122 has prob tensor([0.1802], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 123 has prob tensor([0.1618], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 124 has prob tensor([0.1490], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 125 has prob tensor([0.1462], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 126 has prob tensor([0.1362], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 127 has prob tensor([0.1346], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 128 has prob tensor([0.1588], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 129 has prob tensor([0.1560], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 130 has prob tensor([0.1554], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 131 has prob tensor([0.1459], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 132 has prob tensor([0.1540], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 133 has prob tensor([0.1474], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 134 has prob tensor([0.1383], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 135 has prob tensor([0.1515], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 136 has prob tensor([0.1685], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 137 has prob tensor([0.1464], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 138 has prob tensor([0.1431], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 139 has prob tensor([0.1481], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 140 has prob tensor([0.1467], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 141 has prob tensor([0.1556], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 142 has prob tensor([0.1702], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 143 has prob tensor([0.1729], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 144 has prob tensor([0.1549], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 145 has prob tensor([0.1559], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 146 has prob tensor([0.1494], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 147 has prob tensor([0.1445], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 148 has prob tensor([0.1306], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 149 has prob tensor([0.1298], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 150 has prob tensor([0.1220], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 151 has prob tensor([0.1302], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 152 has prob tensor([0.1467], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 153 has prob tensor([0.1784], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 154 has prob tensor([0.2053], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 155 has prob tensor([0.2609], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 156 has prob tensor([0.2623], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 157 has prob tensor([0.2639], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 158 has prob tensor([0.2657], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 159 has prob tensor([0.2677], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 160 has prob tensor([0.2699], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 161 has prob tensor([0.2730], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 162 has prob tensor([0.2768], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 163 has prob tensor([0.2809], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 164 has prob tensor([0.2845], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 165 has prob tensor([0.2872], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 166 has prob tensor([0.2898], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 167 has prob tensor([0.2914], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 168 has prob tensor([0.2923], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 169 has prob tensor([0.2921], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 170 has prob tensor([0.2923], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 171 has prob tensor([0.2919], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 172 has prob tensor([0.2911], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 173 has prob tensor([0.2900], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 174 has prob tensor([0.2878], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 175 has prob tensor([0.2858], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 176 has prob tensor([0.2838], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 177 has prob tensor([0.2819], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 178 has prob tensor([0.2793], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 179 has prob tensor([0.2764], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 180 has prob tensor([0.2733], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 181 has prob tensor([0.2705], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 182 has prob tensor([0.2680], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 183 has prob tensor([0.2659], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 184 has prob tensor([0.2640], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 185 has prob tensor([0.2625], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 186 has prob tensor([0.2620], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 187 has prob tensor([0.2611], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 188 has prob tensor([0.2595], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 189 has prob tensor([0.2582], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 190 has prob tensor([0.2563], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 191 has prob tensor([0.2557], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 192 has prob tensor([0.2554], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 193 has prob tensor([0.2544], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 194 has prob tensor([0.2538], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 195 has prob tensor([0.2529], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 196 has prob tensor([0.2514], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 197 has prob tensor([0.2510], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 198 has prob tensor([0.2487], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 199 has prob tensor([0.2469], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 200 has prob tensor([0.2432], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 201 has prob tensor([0.2384], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 202 has prob tensor([0.2342], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 203 has prob tensor([0.2283], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 204 has prob tensor([0.2220], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 205 has prob tensor([0.2166], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 206 has prob tensor([0.2111], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 207 has prob tensor([0.2059], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 208 has prob tensor([0.2020], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 209 has prob tensor([0.1985], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 210 has prob tensor([0.1951], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 211 has prob tensor([0.1920], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 212 has prob tensor([0.1892], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 213 has prob tensor([0.1870], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 214 has prob tensor([0.1852], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 215 has prob tensor([0.1842], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 216 has prob tensor([0.1838], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 217 has prob tensor([0.1838], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 218 has prob tensor([0.1847], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 219 has prob tensor([0.1857], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 220 has prob tensor([0.1870], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 221 has prob tensor([0.1882], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 222 has prob tensor([0.1897], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 223 has prob tensor([0.1910], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 224 has prob tensor([0.1933], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 225 has prob tensor([0.1960], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 226 has prob tensor([0.1992], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 227 has prob tensor([0.2027], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 228 has prob tensor([0.2066], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 229 has prob tensor([0.2104], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 230 has prob tensor([0.2143], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 231 has prob tensor([0.2181], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 232 has prob tensor([0.2213], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 233 has prob tensor([0.2244], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 234 has prob tensor([0.2270], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 235 has prob tensor([0.2291], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 236 has prob tensor([0.2311], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 237 has prob tensor([0.2326], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 238 has prob tensor([0.2343], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 239 has prob tensor([0.2361], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 240 has prob tensor([0.2383], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 241 has prob tensor([0.2402], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 242 has prob tensor([0.2422], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 243 has prob tensor([0.2442], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 244 has prob tensor([0.2456], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 245 has prob tensor([0.2468], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 246 has prob tensor([0.2478], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 247 has prob tensor([0.2489], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 248 has prob tensor([0.2503], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 249 has prob tensor([0.2517], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 250 has prob tensor([0.2538], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 251 has prob tensor([0.2554], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 252 has prob tensor([0.2576], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 253 has prob tensor([0.2599], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 254 has prob tensor([0.2622], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 255 has prob tensor([0.2641], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 256 has prob tensor([0.2666], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 257 has prob tensor([0.2691], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 258 has prob tensor([0.2721], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 259 has prob tensor([0.2754], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 260 has prob tensor([0.2784], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 261 has prob tensor([0.2800], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 262 has prob tensor([0.2816], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 263 has prob tensor([0.2836], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 264 has prob tensor([0.2850], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 265 has prob tensor([0.2856], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 266 has prob tensor([0.2866], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 267 has prob tensor([0.2872], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 268 has prob tensor([0.2868], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 269 has prob tensor([0.2860], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 270 has prob tensor([0.2846], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 271 has prob tensor([0.2828], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 272 has prob tensor([0.2809], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 273 has prob tensor([0.2789], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 274 has prob tensor([0.2759], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 275 has prob tensor([0.2729], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 276 has prob tensor([0.2703], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 277 has prob tensor([0.2681], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 278 has prob tensor([0.2662], device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Index 279 has prob tensor([0.2645], device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i,prob in enumerate(prob_vector):\n",
    "    print(f\"Index {i} has prob {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2769b653090>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_vector_cpu = prob_vector.cpu().detach().numpy()\n",
    "plt.plot(prob_vector_cpu/max(prob_vector_cpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOIEvent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
